# 数据结构与算法完整学习指南

[toc]

------

## 第一部分：基础数据结构

### 1. 数组与字符串

#### 动态数组实现

```python
class DynamicArray:
    """
    动态数组实现，支持自动扩容和缩容
    时间复杂度：
    - 访问 O(1)
    - 插入末尾 O(1) 摊还
    - 插入任意位置 O(n)
    - 删除 O(n)
    """
    def __init__(self, initial_capacity=10):
        self.capacity = initial_capacity  # 数组容量
        self.size = 0  # 当前元素个数
        self.data = [None] * self.capacity  # 底层数组
    
    def __len__(self):
        """返回数组长度"""
        return self.size
    
    def __getitem__(self, index):
        """支持下标访问"""
        if not 0 <= index < self.size:
            raise IndexError(f"Index {index} out of range [0, {self.size})")
        return self.data[index]
    
    def __setitem__(self, index, value):
        """支持下标赋值"""
        if not 0 <= index < self.size:
            raise IndexError(f"Index {index} out of range [0, {self.size})")
        self.data[index] = value
    
    def append(self, value):
        """在末尾添加元素"""
        # 如果容量满了，扩容为原来的2倍
        if self.size == self.capacity:
            self._resize(2 * self.capacity)
        
        self.data[self.size] = value
        self.size += 1
    
    def insert(self, index, value):
        """在指定位置插入元素"""
        if not 0 <= index <= self.size:
            raise IndexError(f"Index {index} out of range [0, {self.size}]")
        
        # 容量检查
        if self.size == self.capacity:
            self._resize(2 * self.capacity)
        
        # 将index及之后的元素后移一位
        for i in range(self.size, index, -1):
            self.data[i] = self.data[i-1]
        
        self.data[index] = value
        self.size += 1
    
    def remove(self, index):
        """删除指定位置的元素"""
        if not 0 <= index < self.size:
            raise IndexError(f"Index {index} out of range [0, {self.size})")
        
        removed_value = self.data[index]
        
        # 将index之后的元素前移一位
        for i in range(index, self.size - 1):
            self.data[i] = self.data[i + 1]
        
        self.size -= 1
        self.data[self.size] = None  # 避免内存泄漏
        
        # 如果元素个数小于容量的1/4，缩容为原来的1/2
        if self.size > 0 and self.size < self.capacity // 4:
            self._resize(self.capacity // 2)
        
        return removed_value
    
    def _resize(self, new_capacity):
        """调整数组容量"""
        new_data = [None] * new_capacity
        # 复制原有数据
        for i in range(self.size):
            new_data[i] = self.data[i]
        self.data = new_data
        self.capacity = new_capacity
    
    def __str__(self):
        """字符串表示"""
        return str([self.data[i] for i in range(self.size)])
```

#### 字符串算法基础

```python
class StringAlgorithms:
    """字符串基础算法集合"""
    
    @staticmethod
    def reverse_string(s):
        """
        反转字符串 - 多种实现方式
        时间复杂度：O(n)
        空间复杂度：O(n)
        """
        # 方法1：切片
        # return s[::-1]
        
        # 方法2：双指针原地反转（如果是字符数组）
        chars = list(s)
        left, right = 0, len(chars) - 1
        while left < right:
            chars[left], chars[right] = chars[right], chars[left]
            left += 1
            right -= 1
        return ''.join(chars)
    
    @staticmethod
    def is_palindrome(s):
        """
        判断是否为回文串
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        # 预处理：只保留字母和数字，转为小写
        cleaned = ''.join(c.lower() for c in s if c.isalnum())
        
        # 双指针判断
        left, right = 0, len(cleaned) - 1
        while left < right:
            if cleaned[left] != cleaned[right]:
                return False
            left += 1
            right -= 1
        return True
    
    @staticmethod
    def longest_common_prefix(strs):
        """
        最长公共前缀
        时间复杂度：O(n*m) n为字符串数量，m为最短字符串长度
        空间复杂度：O(1)
        """
        if not strs:
            return ""
        
        # 纵向扫描法
        for i in range(len(strs[0])):
            char = strs[0][i]
            for j in range(1, len(strs)):
                # 如果超出长度或字符不匹配
                if i >= len(strs[j]) or strs[j][i] != char:
                    return strs[0][:i]
        
        return strs[0]
    
    @staticmethod
    def group_anagrams(strs):
        """
        字母异位词分组
        时间复杂度：O(n*k*log(k)) n为字符串数量，k为字符串平均长度
        空间复杂度：O(n*k)
        """
        from collections import defaultdict
        
        # 使用排序后的字符串作为key
        anagram_map = defaultdict(list)
        
        for s in strs:
            # 将字符串排序作为key
            key = ''.join(sorted(s))
            anagram_map[key].append(s)
        
        return list(anagram_map.values())
```

### 2. 链表

#### 单链表实现

```python
class ListNode:
    """链表节点"""
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next

class LinkedList:
    """
    单链表实现
    支持头部/尾部插入删除，反转，环检测等操作
    """
    def __init__(self):
        self.head = None
        self.size = 0
    
    def add_first(self, val):
        """
        在链表头部添加节点
        时间复杂度：O(1)
        """
        new_node = ListNode(val)
        new_node.next = self.head
        self.head = new_node
        self.size += 1
    
    def add_last(self, val):
        """
        在链表尾部添加节点
        时间复杂度：O(n)
        """
        new_node = ListNode(val)
        if not self.head:
            self.head = new_node
        else:
            # 遍历到最后一个节点
            current = self.head
            while current.next:
                current = current.next
            current.next = new_node
        self.size += 1
    
    def add_at_index(self, index, val):
        """
        在指定位置插入节点
        时间复杂度：O(n)
        """
        if index < 0 or index > self.size:
            raise IndexError("Index out of range")
        
        if index == 0:
            self.add_first(val)
            return
        
        # 找到插入位置的前一个节点
        prev = self.head
        for _ in range(index - 1):
            prev = prev.next
        
        new_node = ListNode(val)
        new_node.next = prev.next
        prev.next = new_node
        self.size += 1
    
    def remove_first(self):
        """
        删除头节点
        时间复杂度：O(1)
        """
        if not self.head:
            raise IndexError("Remove from empty list")
        
        val = self.head.val
        self.head = self.head.next
        self.size -= 1
        return val
    
    def remove_last(self):
        """
        删除尾节点
        时间复杂度：O(n)
        """
        if not self.head:
            raise IndexError("Remove from empty list")
        
        if not self.head.next:
            return self.remove_first()
        
        # 找到倒数第二个节点
        current = self.head
        while current.next.next:
            current = current.next
        
        val = current.next.val
        current.next = None
        self.size -= 1
        return val
    
    def reverse(self):
        """
        反转链表 - 迭代法
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        prev = None
        current = self.head
        
        while current:
            # 保存下一个节点
            next_temp = current.next
            # 反转当前节点的指向
            current.next = prev
            # 移动指针
            prev = current
            current = next_temp
        
        self.head = prev
    
    def reverse_recursive(self):
        """
        反转链表 - 递归法
        时间复杂度：O(n)
        空间复杂度：O(n) 递归调用栈
        """
        def reverse_helper(node):
            # 基础情况：空链表或只有一个节点
            if not node or not node.next:
                return node
            
            # 递归反转后续链表
            new_head = reverse_helper(node.next)
            
            # 反转当前节点与下一个节点的指向
            node.next.next = node
            node.next = None
            
            return new_head
        
        self.head = reverse_helper(self.head)
    
    def find_middle(self):
        """
        找到链表的中点 - 快慢指针法
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if not self.head:
            return None
        
        slow = fast = self.head
        
        # 快指针每次走两步，慢指针每次走一步
        while fast and fast.next:
            slow = slow.next
            fast = fast.next.next
        
        return slow
    
    def has_cycle(self):
        """
        检测链表是否有环 - Floyd判圈算法
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if not self.head:
            return False
        
        slow = fast = self.head
        
        while fast and fast.next:
            slow = slow.next
            fast = fast.next.next
            
            # 快慢指针相遇，说明有环
            if slow == fast:
                return True
        
        return False
    
    def find_cycle_start(self):
        """
        找到环的起始节点
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if not self.head:
            return None
        
        slow = fast = self.head
        
        # 第一步：判断是否有环
        while fast and fast.next:
            slow = slow.next
            fast = fast.next.next
            if slow == fast:
                break
        else:
            return None  # 无环
        
        # 第二步：找到环的起始点
        # 将slow重置到头部，两个指针同速前进
        slow = self.head
        while slow != fast:
            slow = slow.next
            fast = fast.next
        
        return slow
    
    def merge_sorted(self, other):
        """
        合并两个有序链表
        时间复杂度：O(m + n)
        空间复杂度：O(1)
        """
        dummy = ListNode(0)  # 哨兵节点
        tail = dummy
        
        p1, p2 = self.head, other.head
        
        while p1 and p2:
            if p1.val <= p2.val:
                tail.next = p1
                p1 = p1.next
            else:
                tail.next = p2
                p2 = p2.next
            tail = tail.next
        
        # 连接剩余节点
        tail.next = p1 if p1 else p2
        
        self.head = dummy.next
        self.size += other.size
```

#### 双向链表实现

```python
class DoublyListNode:
    """双向链表节点"""
    def __init__(self, val=0, prev=None, next=None):
        self.val = val
        self.prev = prev
        self.next = next

class DoublyLinkedList:
    """
    双向链表实现
    相比单链表，可以O(1)时间删除给定节点
    """
    def __init__(self):
        # 使用哨兵节点简化边界处理
        self.head = DoublyListNode()  # 头哨兵
        self.tail = DoublyListNode()  # 尾哨兵
        self.head.next = self.tail
        self.tail.prev = self.head
        self.size = 0
    
    def add_first(self, val):
        """在头部添加节点"""
        self._add_between(val, self.head, self.head.next)
    
    def add_last(self, val):
        """在尾部添加节点"""
        self._add_between(val, self.tail.prev, self.tail)
    
    def _add_between(self, val, pred, succ):
        """在pred和succ之间插入新节点"""
        new_node = DoublyListNode(val, pred, succ)
        pred.next = new_node
        succ.prev = new_node
        self.size += 1
        return new_node
    
    def remove_node(self, node):
        """
        删除给定节点
        时间复杂度：O(1)
        """
        if node == self.head or node == self.tail:
            raise ValueError("Cannot remove sentinel nodes")
        
        pred = node.prev
        succ = node.next
        pred.next = succ
        succ.prev = pred
        self.size -= 1
        return node.val
    
    def remove_first(self):
        """删除第一个节点"""
        if self.size == 0:
            raise IndexError("Remove from empty list")
        return self.remove_node(self.head.next)
    
    def remove_last(self):
        """删除最后一个节点"""
        if self.size == 0:
            raise IndexError("Remove from empty list")
        return self.remove_node(self.tail.prev)
    
    def __str__(self):
        """字符串表示"""
        values = []
        current = self.head.next
        while current != self.tail:
            values.append(str(current.val))
            current = current.next
        return ' <-> '.join(values)
```

### 3. 栈与队列

#### 栈的多种实现

```python
class ArrayStack:
    """
    基于动态数组的栈实现
    所有操作时间复杂度：O(1) 摊还
    """
    def __init__(self):
        self.items = []
    
    def push(self, item):
        """入栈"""
        self.items.append(item)
    
    def pop(self):
        """出栈"""
        if self.is_empty():
            raise IndexError("Pop from empty stack")
        return self.items.pop()
    
    def peek(self):
        """查看栈顶元素"""
        if self.is_empty():
            raise IndexError("Peek from empty stack")
        return self.items[-1]
    
    def is_empty(self):
        """判断栈是否为空"""
        return len(self.items) == 0
    
    def size(self):
        """返回栈的大小"""
        return len(self.items)


class LinkedStack:
    """
    基于链表的栈实现
    所有操作时间复杂度：O(1)
    """
    class Node:
        def __init__(self, val, next=None):
            self.val = val
            self.next = next
    
    def __init__(self):
        self.top = None
        self._size = 0
    
    def push(self, item):
        """入栈 - 在链表头部插入"""
        self.top = self.Node(item, self.top)
        self._size += 1
    
    def pop(self):
        """出栈 - 删除链表头部节点"""
        if self.is_empty():
            raise IndexError("Pop from empty stack")
        
        item = self.top.val
        self.top = self.top.next
        self._size -= 1
        return item
    
    def peek(self):
        """查看栈顶元素"""
        if self.is_empty():
            raise IndexError("Peek from empty stack")
        return self.top.val
    
    def is_empty(self):
        """判断栈是否为空"""
        return self.top is None
    
    def size(self):
        """返回栈的大小"""
        return self._size


class MinStack:
    """
    支持O(1)时间获取最小值的栈
    思路：使用辅助栈存储每个状态的最小值
    """
    def __init__(self):
        self.stack = []      # 主栈
        self.min_stack = []  # 辅助栈，存储最小值
    
    def push(self, val):
        """入栈"""
        self.stack.append(val)
        
        # 更新最小值栈
        if not self.min_stack or val <= self.min_stack[-1]:
            self.min_stack.append(val)
        else:
            self.min_stack.append(self.min_stack[-1])
    
    def pop(self):
        """出栈"""
        if not self.stack:
            raise IndexError("Pop from empty stack")
        
        self.min_stack.pop()
        return self.stack.pop()
    
    def top(self):
        """获取栈顶元素"""
        if not self.stack:
            raise IndexError("Peek from empty stack")
        return self.stack[-1]
    
    def get_min(self):
        """
        获取栈中最小值
        时间复杂度：O(1)
        """
        if not self.min_stack:
            raise ValueError("Stack is empty")
        return self.min_stack[-1]
```

#### 队列的多种实现

```python
class ArrayQueue:
    """
    基于循环数组的队列实现
    避免了普通数组实现中的元素移动
    """
    def __init__(self, capacity=10):
        self.capacity = capacity
        self.items = [None] * capacity
        self.front = 0  # 队首指针
        self.rear = 0   # 队尾指针
        self.size = 0
    
    def enqueue(self, item):
        """
        入队
        时间复杂度：O(1) 摊还
        """
        if self.size == self.capacity:
            self._resize(2 * self.capacity)
        
        self.items[self.rear] = item
        self.rear = (self.rear + 1) % self.capacity
        self.size += 1
    
    def dequeue(self):
        """
        出队
        时间复杂度：O(1)
        """
        if self.is_empty():
            raise IndexError("Dequeue from empty queue")
        
        item = self.items[self.front]
        self.items[self.front] = None  # 避免内存泄漏
        self.front = (self.front + 1) % self.capacity
        self.size -= 1
        
        # 缩容
        if 0 < self.size < self.capacity // 4:
            self._resize(self.capacity // 2)
        
        return item
    
    def peek(self):
        """查看队首元素"""
        if self.is_empty():
            raise IndexError("Peek from empty queue")
        return self.items[self.front]
    
    def is_empty(self):
        """判断队列是否为空"""
        return self.size == 0
    
    def _resize(self, new_capacity):
        """调整队列容量"""
        new_items = [None] * new_capacity
        
        # 复制元素到新数组
        for i in range(self.size):
            new_items[i] = self.items[(self.front + i) % self.capacity]
        
        self.items = new_items
        self.capacity = new_capacity
        self.front = 0
        self.rear = self.size


class LinkedQueue:
    """
    基于链表的队列实现
    使用头尾指针优化
    """
    class Node:
        def __init__(self, val, next=None):
            self.val = val
            self.next = next
    
    def __init__(self):
        self.front = None  # 队首
        self.rear = None   # 队尾
        self.size = 0
    
    def enqueue(self, item):
        """
        入队 - 在链表尾部添加
        时间复杂度：O(1)
        """
        new_node = self.Node(item)
        
        if self.rear:
            self.rear.next = new_node
        else:
            self.front = new_node
        
        self.rear = new_node
        self.size += 1
    
    def dequeue(self):
        """
        出队 - 删除链表头部
        时间复杂度：O(1)
        """
        if self.is_empty():
            raise IndexError("Dequeue from empty queue")
        
        item = self.front.val
        self.front = self.front.next
        
        if not self.front:
            self.rear = None
        
        self.size -= 1
        return item
    
    def peek(self):
        """查看队首元素"""
        if self.is_empty():
            raise IndexError("Peek from empty queue")
        return self.front.val
    
    def is_empty(self):
        """判断队列是否为空"""
        return self.front is None


class Deque:
    """
    双端队列实现
    支持两端的插入和删除操作
    """
    def __init__(self):
        self.items = []
    
    def add_first(self, item):
        """在队首添加元素"""
        self.items.insert(0, item)
    
    def add_last(self, item):
        """在队尾添加元素"""
        self.items.append(item)
    
    def remove_first(self):
        """删除队首元素"""
        if self.is_empty():
            raise IndexError("Remove from empty deque")
        return self.items.pop(0)
    
    def remove_last(self):
        """删除队尾元素"""
        if self.is_empty():
            raise IndexError("Remove from empty deque")
        return self.items.pop()
    
    def peek_first(self):
        """查看队首元素"""
        if self.is_empty():
            raise IndexError("Peek from empty deque")
        return self.items[0]
    
    def peek_last(self):
        """查看队尾元素"""
        if self.is_empty():
            raise IndexError("Peek from empty deque")
        return self.items[-1]
    
    def is_empty(self):
        """判断双端队列是否为空"""
        return len(self.items) == 0
    
    def size(self):
        """返回双端队列的大小"""
        return len(self.items)
```

#### 单调栈与单调队列

```python
class MonotonicStack:
    """
    单调栈：栈内元素保持单调递增或递减
    常用于解决"下一个更大/更小元素"类问题
    """
    
    @staticmethod
    def next_greater_element(nums):
        """
        找到每个元素的下一个更大元素
        时间复杂度：O(n)
        空间复杂度：O(n)
        
        示例：nums = [2,1,2,4,3] -> [4,2,4,-1,-1]
        """
        n = len(nums)
        result = [-1] * n  # 初始化为-1，表示没有更大元素
        stack = []  # 存储索引
        
        for i in range(n):
            # 当前元素比栈顶元素大时，栈顶元素的下一个更大元素就是当前元素
            while stack and nums[stack[-1]] < nums[i]:
                idx = stack.pop()
                result[idx] = nums[i]
            
            stack.append(i)
        
        return result
    
    @staticmethod
    def next_greater_element_circular(nums):
        """
        循环数组中找到每个元素的下一个更大元素
        时间复杂度：O(n)
        空间复杂度：O(n)
        
        示例：nums = [1,2,1] -> [2,-1,2]
        """
        n = len(nums)
        result = [-1] * n
        stack = []
        
        # 遍历两倍长度，模拟循环
        for i in range(2 * n):
            while stack and nums[stack[-1]] < nums[i % n]:
                idx = stack.pop()
                result[idx] = nums[i % n]
            
            # 只在第一轮将索引入栈
            if i < n:
                stack.append(i)
        
        return result
    
    @staticmethod
    def daily_temperatures(temperatures):
        """
        每日温度问题：找到每天需要等待几天才能遇到更高温度
        时间复杂度：O(n)
        空间复杂度：O(n)
        
        示例：T = [73,74,75,71,69,72,76,73] -> [1,1,4,2,1,1,0,0]
        """
        n = len(temperatures)
        result = [0] * n
        stack = []  # 存储索引
        
        for i in range(n):
            while stack and temperatures[stack[-1]] < temperatures[i]:
                idx = stack.pop()
                result[idx] = i - idx  # 计算天数差
            
            stack.append(i)
        
        return result
    
    @staticmethod
    def largest_rectangle_area(heights):
        """
        柱状图中最大的矩形面积
        时间复杂度：O(n)
        空间复杂度：O(n)
        
        示例：heights = [2,1,5,6,2,3] -> 10
        """
        stack = []
        max_area = 0
        
        for i, h in enumerate(heights):
            # 当前高度小于栈顶高度时，计算以栈顶为高度的矩形面积
            while stack and heights[stack[-1]] > h:
                height_idx = stack.pop()
                height = heights[height_idx]
                
                # 计算宽度
                if stack:
                    width = i - stack[-1] - 1
                else:
                    width = i
                
                max_area = max(max_area, height * width)
            
            stack.append(i)
        
        # 处理剩余元素
        while stack:
            height_idx = stack.pop()
            height = heights[height_idx]
            
            if stack:
                width = len(heights) - stack[-1] - 1
            else:
                width = len(heights)
            
            max_area = max(max_area, height * width)
        
        return max_area


class MonotonicQueue:
    """
    单调队列：队列内元素保持单调性
    常用于滑动窗口最大/最小值问题
    """
    
    @staticmethod
    def sliding_window_maximum(nums, k):
        """
        滑动窗口最大值
        时间复杂度：O(n)
        空间复杂度：O(k)
        
        示例：nums = [1,3,-1,-3,5,3,6,7], k = 3
        返回：[3,3,5,5,6,7]
        """
        from collections import deque
        
        dq = deque()  # 存储索引，保持单调递减
        result = []
        
        for i in range(len(nums)):
            # 移除超出窗口的元素
            while dq and dq[0] <= i - k:
                dq.popleft()
            
            # 维护单调递减队列
            while dq and nums[dq[-1]] < nums[i]:
                dq.pop()
            
            dq.append(i)
            
            # 窗口形成后，记录最大值
            if i >= k - 1:
                result.append(nums[dq[0]])
        
        return result
    
    @staticmethod
    def sliding_window_minimum(nums, k):
        """
        滑动窗口最小值
        时间复杂度：O(n)
        空间复杂度：O(k)
        """
        from collections import deque
        
        dq = deque()  # 存储索引，保持单调递增
        result = []
        
        for i in range(len(nums)):
            # 移除超出窗口的元素
            while dq and dq[0] <= i - k:
                dq.popleft()
            
            # 维护单调递增队列
            while dq and nums[dq[-1]] > nums[i]:
                dq.pop()
            
            dq.append(i)
            
            # 窗口形成后，记录最小值
            if i >= k - 1:
                result.append(nums[dq[0]])
        
        return result
```

### 4. 哈希表

#### 链地址法实现

```python
class HashNode:
    """哈希表节点"""
    def __init__(self, key, value, next=None):
        self.key = key
        self.value = value
        self.next = next

class ChainingHashMap:
    """
    链地址法哈希表实现
    使用链表解决哈希冲突
    """
    def __init__(self, initial_capacity=16, load_factor=0.75):
        self.capacity = initial_capacity
        self.size = 0
        self.buckets = [None] * self.capacity
        self.load_factor = load_factor
    
    def _hash(self, key):
        """
        哈希函数：使用Python内置hash函数
        确保结果在[0, capacity)范围内
        """
        return hash(key) % self.capacity
    
    def put(self, key, value):
        """
        插入或更新键值对
        时间复杂度：平均O(1)，最坏O(n)
        """
        index = self._hash(key)
        
        if not self.buckets[index]:
            # 桶为空，直接插入
            self.buckets[index] = HashNode(key, value)
            self.size += 1
        else:
            # 遍历链表
            current = self.buckets[index]
            while current:
                if current.key == key:
                    # 更新已存在的键
                    current.value = value
                    return
                if not current.next:
                    break
                current = current.next
            
            # 在链表末尾添加新节点
            current.next = HashNode(key, value)
            self.size += 1
        
        # 检查是否需要扩容
        if self.size > self.capacity * self.load_factor:
            self._resize()
    
    def get(self, key):
        """
        获取键对应的值
        时间复杂度：平均O(1)，最坏O(n)
        """
        index = self._hash(key)
        current = self.buckets[index]
        
        while current:
            if current.key == key:
                return current.value
            current = current.next
        
        raise KeyError(f"Key '{key}' not found")
    
    def remove(self, key):
        """
        删除键值对
        时间复杂度：平均O(1)，最坏O(n)
        """
        index = self._hash(key)
        current = self.buckets[index]
        prev = None
        
        while current:
            if current.key == key:
                if prev:
                    prev.next = current.next
                else:
                    self.buckets[index] = current.next
                self.size -= 1
                return current.value
            prev = current
            current = current.next
        
        raise KeyError(f"Key '{key}' not found")
    
    def _resize(self):
        """
        动态扩容，重新哈希所有键值对
        时间复杂度：O(n)
        """
        old_buckets = self.buckets
        self.capacity *= 2
        self.size = 0
        self.buckets = [None] * self.capacity
        
        # 重新插入所有键值对
        for head in old_buckets:
            while head:
                self.put(head.key, head.value)
                head = head.next
    
    def keys(self):
        """返回所有键"""
        keys = []
        for head in self.buckets:
            current = head
            while current:
                keys.append(current.key)
                current = current.next
        return keys
    
    def values(self):
        """返回所有值"""
        values = []
        for head in self.buckets:
            current = head
            while current:
                values.append(current.value)
                current = current.next
        return values
    
    def __contains__(self, key):
        """支持 in 操作符"""
        try:
            self.get(key)
            return True
        except KeyError:
            return False
    
    def __str__(self):
        """字符串表示"""
        items = []
        for head in self.buckets:
            current = head
            while current:
                items.append(f"{current.key}: {current.value}")
                current = current.next
        return "{" + ", ".join(items) + "}"
```

#### 开放地址法实现

```python
class OpenAddressingHashMap:
    """
    开放地址法哈希表实现
    使用线性探测解决冲突
    """
    class _Deleted:
        """标记已删除的槽位"""
        pass
    
    def __init__(self, initial_capacity=16, load_factor=0.5):
        self.capacity = initial_capacity
        self.size = 0
        self.keys = [None] * self.capacity
        self.values = [None] * self.capacity
        self.load_factor = load_factor
        self.deleted = OpenAddressingHashMap._Deleted()
    
    def _hash(self, key):
        """主哈希函数"""
        return hash(key) % self.capacity
    
    def _probe(self, key):
        """
        线性探测序列生成器
        返回可能的槽位索引
        """
        index = self._hash(key)
        
        while True:
            yield index
            index = (index + 1) % self.capacity
    
    def put(self, key, value):
        """
        插入或更新键值对
        时间复杂度：平均O(1)
        """
        for index in self._probe(key):
            if self.keys[index] is None or self.keys[index] is self.deleted:
                # 找到空槽位，插入
                self.keys[index] = key
                self.values[index] = value
                self.size += 1
                
                # 检查是否需要扩容
                if self.size > self.capacity * self.load_factor:
                    self._resize()
                return
            
            elif self.keys[index] == key:
                # 更新已存在的键
                self.values[index] = value
                return
    
    def get(self, key):
        """
        获取键对应的值
        时间复杂度：平均O(1)
        """
        for index in self._probe(key):
            if self.keys[index] is None:
                # 遇到空槽位，键不存在
                raise KeyError(f"Key '{key}' not found")
            
            if self.keys[index] == key:
                return self.values[index]
    
    def remove(self, key):
        """
        删除键值对
        时间复杂度：平均O(1)
        """
        for index in self._probe(key):
            if self.keys[index] is None:
                raise KeyError(f"Key '{key}' not found")
            
            if self.keys[index] == key:
                value = self.values[index]
                # 标记为已删除，而不是设为None
                self.keys[index] = self.deleted
                self.values[index] = None
                self.size -= 1
                return value
    
    def _resize(self):
        """
        动态扩容
        时间复杂度：O(n)
        """
        old_keys = self.keys
        old_values = self.values
        
        self.capacity *= 2
        self.size = 0
        self.keys = [None] * self.capacity
        self.values = [None] * self.capacity
        
        # 重新插入所有键值对
        for i in range(len(old_keys)):
            if old_keys[i] is not None and old_keys[i] is not self.deleted:
                self.put(old_keys[i], old_values[i])
```

#### 一致性哈希

```python
class ConsistentHash:
    """
    一致性哈希实现
    用于分布式系统中的负载均衡
    """
    def __init__(self, nodes=None, virtual_nodes=150):
        """
        nodes: 物理节点列表
        virtual_nodes: 每个物理节点对应的虚拟节点数
        """
        self.virtual_nodes = virtual_nodes
        self.ring = {}  # 哈希环
        self.sorted_keys = []  # 排序的哈希值
        
        if nodes:
            for node in nodes:
                self.add_node(node)
    
    def _hash(self, key):
        """
        使用MD5哈希函数
        返回一个大整数
        """
        import hashlib
        md5 = hashlib.md5()
        md5.update(key.encode('utf-8'))
        return int(md5.hexdigest(), 16)
    
    def add_node(self, node):
        """
        添加节点到哈希环
        时间复杂度：O(v * log(n))，v是虚拟节点数，n是节点总数
        """
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node
            self.sorted_keys.append(hash_value)
        
        self.sorted_keys.sort()
    
    def remove_node(self, node):
        """
        从哈希环移除节点
        时间复杂度：O(v * log(n))
        """
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            
            if hash_value in self.ring:
                del self.ring[hash_value]
                self.sorted_keys.remove(hash_value)
    
    def get_node(self, key):
        """
        获取key应该映射到的节点
        时间复杂度：O(log(n))
        """
        if not self.ring:
            return None
        
        hash_value = self._hash(key)
        
        # 二分查找第一个大于等于hash_value的位置
        idx = self._binary_search(hash_value)
        
        # 如果没有找到更大的值，则绕回到第一个节点
        if idx == len(self.sorted_keys):
            idx = 0
        
        return self.ring[self.sorted_keys[idx]]
    
    def _binary_search(self, target):
        """
        二分查找第一个大于等于target的位置
        """
        left, right = 0, len(self.sorted_keys)
        
        while left < right:
            mid = (left + right) // 2
            if self.sorted_keys[mid] < target:
                left = mid + 1
            else:
                right = mid
        
        return left
    
    def get_node_count(self):
        """获取物理节点数量"""
        return len(set(self.ring.values()))
```

### 5. 跳表

```python
import random

class SkipListNode:
    """跳表节点"""
    def __init__(self, key=None, value=None, level=0):
        self.key = key
        self.value = value
        # forward[i]指向第i层的下一个节点
        self.forward = [None] * (level + 1)

class SkipList:
    """
    跳表实现
    平均时间复杂度：查找、插入、删除都是O(log n)
    空间复杂度：O(n)
    """
    def __init__(self, max_level=16, p=0.5):
        self.max_level = max_level  # 最大层数
        self.p = p  # 节点晋升到上一层的概率
        self.level = 0  # 当前最高层数
        # 创建头节点，key为负无穷
        self.header = SkipListNode(level=max_level)
    
    def random_level(self):
        """
        随机生成节点层数
        以概率p晋升到更高层
        """
        level = 0
        while random.random() < self.p and level < self.max_level:
            level += 1
        return level
    
    def search(self, key):
        """
        查找键对应的值
        时间复杂度：O(log n)
        """
        current = self.header
        
        # 从最高层开始查找
        for i in range(self.level, -1, -1):
            # 在当前层向右移动，直到下一个节点的key大于等于目标key
            while current.forward[i] and current.forward[i].key < key:
                current = current.forward[i]
        
        # 移动到最底层的下一个节点
        current = current.forward[0]
        
        # 检查是否找到目标key
        if current and current.key == key:
            return current.value
        return None
    
    def insert(self, key, value):
        """
        插入键值对
        时间复杂度：O(log n)
        """
        # 记录每层需要更新的前驱节点
        update = [None] * (self.max_level + 1)
        current = self.header
        
        # 查找插入位置
        for i in range(self.level, -1, -1):
            while current.forward[i] and current.forward[i].key < key:
                current = current.forward[i]
            update[i] = current
        
        current = current.forward[0]
        
        # 如果key已存在，更新value
        if current and current.key == key:
            current.value = value
            return
        
        # 创建新节点
        new_level = self.random_level()
        new_node = SkipListNode(key, value, new_level)
        
        # 如果新节点的层数超过当前最高层
        if new_level > self.level:
            for i in range(self.level + 1, new_level + 1):
                update[i] = self.header
            self.level = new_level
        
        # 更新各层的指针
        for i in range(new_level + 1):
            new_node.forward[i] = update[i].forward[i]
            update[i].forward[i] = new_node
    
    def delete(self, key):
        """
        删除键值对
        时间复杂度：O(log n)
        """
        update = [None] * (self.max_level + 1)
        current = self.header
        
        # 查找删除位置
        for i in range(self.level, -1, -1):
            while current.forward[i] and current.forward[i].key < key:
                current = current.forward[i]
            update[i] = current
        
        current = current.forward[0]
        
        # 如果找到目标节点
        if current and current.key == key:
            # 更新各层的指针
            for i in range(self.level + 1):
                if update[i].forward[i] != current:
                    break
                update[i].forward[i] = current.forward[i]
            
            # 更新最高层数
            while self.level > 0 and self.header.forward[self.level] is None:
                self.level -= 1
            
            return True
        
        return False
    
    def display(self):
        """打印跳表结构"""
        print("SkipList:")
        for i in range(self.level, -1, -1):
            print(f"Level {i}: ", end="")
            node = self.header.forward[i]
            while node:
                print(f"{node.key}:{node.value}", end=" -> ")
                node = node.forward[i]
            print("None")
```

## 第二部分：树形结构

### 1. 二叉树基础

```python
class TreeNode:
    """二叉树节点"""
    def __init__(self, val=0, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right

class BinaryTree:
    """
    二叉树基本操作实现
    包含各种遍历方法和基本操作
    """
    def __init__(self, root=None):
        self.root = root
    
    # 递归遍历
    def preorder_recursive(self, root):
        """
        前序遍历（递归）
        顺序：根 -> 左 -> 右
        时间复杂度：O(n)
        空间复杂度：O(h)，h为树高
        """
        if not root:
            return []
        
        result = [root.val]
        result.extend(self.preorder_recursive(root.left))
        result.extend(self.preorder_recursive(root.right))
        return result
    
    def inorder_recursive(self, root):
        """
        中序遍历（递归）
        顺序：左 -> 根 -> 右
        对于BST，中序遍历得到有序序列
        """
        if not root:
            return []
        
        result = []
        result.extend(self.inorder_recursive(root.left))
        result.append(root.val)
        result.extend(self.inorder_recursive(root.right))
        return result
    
    def postorder_recursive(self, root):
        """
        后序遍历（递归）
        顺序：左 -> 右 -> 根
        常用于计算子树信息
        """
        if not root:
            return []
        
        result = []
        result.extend(self.postorder_recursive(root.left))
        result.extend(self.postorder_recursive(root.right))
        result.append(root.val)
        return result
    
    # 迭代遍历
    def preorder_iterative(self, root):
        """
        前序遍历（迭代）
        使用栈模拟递归过程
        """
        if not root:
            return []
        
        result = []
        stack = [root]
        
        while stack:
            node = stack.pop()
            result.append(node.val)
            
            # 先压右子节点，再压左子节点
            if node.right:
                stack.append(node.right)
            if node.left:
                stack.append(node.left)
        
        return result
    
    def inorder_iterative(self, root):
        """
        中序遍历（迭代）
        使用栈和指针
        """
        result = []
        stack = []
        current = root
        
        while stack or current:
            # 一直向左走到底
            while current:
                stack.append(current)
                current = current.left
            
            # 处理节点
            current = stack.pop()
            result.append(current.val)
            
            # 转向右子树
            current = current.right
        
        return result
    
    def postorder_iterative(self, root):
        """
        后序遍历（迭代）
        使用两个栈或标记法
        """
        if not root:
            return []
        
        result = []
        stack = [(root, False)]
        
        while stack:
            node, visited = stack.pop()
            
            if visited:
                # 第二次访问，处理节点
                result.append(node.val)
            else:
                # 第一次访问，按照根-右-左的顺序入栈
                stack.append((node, True))
                if node.right:
                    stack.append((node.right, False))
                if node.left:
                    stack.append((node.left, False))
        
        return result
    
    def level_order(self, root):
        """
        层序遍历
        使用队列实现BFS
        时间复杂度：O(n)
        空间复杂度：O(w)，w为最大宽度
        """
        if not root:
            return []
        
        result = []
        queue = [root]
        
        while queue:
            level_size = len(queue)
            level = []
            
            for _ in range(level_size):
                node = queue.pop(0)
                level.append(node.val)
                
                if node.left:
                    queue.append(node.left)
                if node.right:
                    queue.append(node.right)
            
            result.append(level)
        
        return result
    
    def zigzag_level_order(self, root):
        """
        锯齿形层序遍历
        奇数层从左到右，偶数层从右到左
        """
        if not root:
            return []
        
        result = []
        queue = [root]
        left_to_right = True
        
        while queue:
            level_size = len(queue)
            level = []
            
            for _ in range(level_size):
                node = queue.pop(0)
                level.append(node.val)
                
                if node.left:
                    queue.append(node.left)
                if node.right:
                    queue.append(node.right)
            
            if not left_to_right:
                level.reverse()
            
            result.append(level)
            left_to_right = not left_to_right
        
        return result
    
    # Morris遍历（空间O(1)）
    def morris_inorder(self, root):
        """
        Morris中序遍历
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        result = []
        current = root
        
        while current:
            if not current.left:
                # 左子树为空，处理当前节点
                result.append(current.val)
                current = current.right
            else:
                # 找到左子树的最右节点
                predecessor = current.left
                while predecessor.right and predecessor.right != current:
                    predecessor = predecessor.right
                
                if not predecessor.right:
                    # 建立线索
                    predecessor.right = current
                    current = current.left
                else:
                    # 恢复树结构
                    predecessor.right = None
                    result.append(current.val)
                    current = current.right
        
        return result
    
    # 树的基本操作
    def height(self, root):
        """
        计算树的高度
        时间复杂度：O(n)
        """
        if not root:
            return 0
        
        return 1 + max(self.height(root.left), self.height(root.right))
    
    def is_balanced(self, root):
        """
        判断是否为平衡二叉树
        平衡二叉树：左右子树高度差不超过1
        时间复杂度：O(n)
        """
        def check_balance(node):
            if not node:
                return True, 0
            
            left_balanced, left_height = check_balance(node.left)
            if not left_balanced:
                return False, 0
            
            right_balanced, right_height = check_balance(node.right)
            if not right_balanced:
                return False, 0
            
            # 检查当前节点是否平衡
            is_balanced = abs(left_height - right_height) <= 1
            height = 1 + max(left_height, right_height)
            
            return is_balanced, height
        
        balanced, _ = check_balance(root)
        return balanced
    
    def diameter(self, root):
        """
        计算二叉树的直径（最长路径）
        时间复杂度：O(n)
        """
        self.max_diameter = 0
        
        def depth(node):
            if not node:
                return 0
            
            left_depth = depth(node.left)
            right_depth = depth(node.right)
            
            # 更新直径
            self.max_diameter = max(self.max_diameter, left_depth + right_depth)
            
            return 1 + max(left_depth, right_depth)
        
        depth(root)
        return self.max_diameter
    
    def lowest_common_ancestor(self, root, p, q):
        """
        寻找最近公共祖先
        时间复杂度：O(n)
        """
        if not root or root == p or root == q:
            return root
        
        left = self.lowest_common_ancestor(root.left, p, q)
        right = self.lowest_common_ancestor(root.right, p, q)
        
        if left and right:
            # p和q分别在左右子树
            return root
        
        return left if left else right
    
    def serialize(self, root):
        """
        序列化二叉树（前序遍历）
        时间复杂度：O(n)
        """
        def preorder(node):
            if not node:
                vals.append("null")
                return
            
            vals.append(str(node.val))
            preorder(node.left)
            preorder(node.right)
        
        vals = []
        preorder(root)
        return ','.join(vals)
    
    def deserialize(self, data):
        """
        反序列化二叉树
        时间复杂度：O(n)
        """
        def build():
            val = next(vals)
            if val == "null":
                return None
            
            node = TreeNode(int(val))
            node.left = build()
            node.right = build()
            return node
        
        vals = iter(data.split(','))
        return build()
```

### 2. 二叉搜索树（BST）

```python
class BSTNode:
    """BST节点"""
    def __init__(self, val, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right

class BinarySearchTree:
    """
    二叉搜索树实现
    性质：左子树所有节点 < 根节点 < 右子树所有节点
    """
    def __init__(self):
        self.root = None
    
    def insert(self, val):
        """
        插入节点
        时间复杂度：平均O(log n)，最坏O(n)
        """
        self.root = self._insert_recursive(self.root, val)
    
    def _insert_recursive(self, node, val):
        """递归插入"""
        if not node:
            return BSTNode(val)
        
        if val < node.val:
            node.left = self._insert_recursive(node.left, val)
        elif val > node.val:
            node.right = self._insert_recursive(node.right, val)
        # 如果值相等，不插入（BST通常不允许重复值）
        
        return node
    
    def insert_iterative(self, val):
        """
        迭代插入
        避免递归调用栈
        """
        if not self.root:
            self.root = BSTNode(val)
            return
        
        current = self.root
        while True:
            if val < current.val:
                if current.left:
                    current = current.left
                else:
                    current.left = BSTNode(val)
                    break
            elif val > current.val:
                if current.right:
                    current = current.right
                else:
                    current.right = BSTNode(val)
                    break
            else:
                # 值已存在
                break
    
    def search(self, val):
        """
        查找节点
        时间复杂度：平均O(log n)，最坏O(n)
        """
        return self._search_recursive(self.root, val)
    
    def _search_recursive(self, node, val):
        """递归查找"""
        if not node:
            return False
        
        if val == node.val:
            return True
        elif val < node.val:
            return self._search_recursive(node.left, val)
        else:
            return self._search_recursive(node.right, val)
    
    def search_iterative(self, val):
        """迭代查找"""
        current = self.root
        
        while current:
            if val == current.val:
                return True
            elif val < current.val:
                current = current.left
            else:
                current = current.right
        
        return False
    
    def find_min(self, node=None):
        """
        找到最小值节点
        最左边的节点
        """
        if node is None:
            node = self.root
        
        if not node:
            return None
        
        while node.left:
            node = node.left
        
        return node
    
    def find_max(self, node=None):
        """
        找到最大值节点
        最右边的节点
        """
        if node is None:
            node = self.root
        
        if not node:
            return None
        
        while node.right:
            node = node.right
        
        return node
    
    def delete(self, val):
        """
        删除节点
        时间复杂度：平均O(log n)，最坏O(n)
        """
        self.root = self._delete_recursive(self.root, val)
    
    def _delete_recursive(self, node, val):
        """递归删除"""
        if not node:
            return None
        
        if val < node.val:
            node.left = self._delete_recursive(node.left, val)
        elif val > node.val:
            node.right = self._delete_recursive(node.right, val)
        else:
            # 找到要删除的节点
            
            # 情况1：叶子节点
            if not node.left and not node.right:
                return None
            
            # 情况2：只有一个子节点
            if not node.left:
                return node.right
            if not node.right:
                return node.left
            
            # 情况3：有两个子节点
            # 找到右子树的最小节点（后继节点）
            successor = self.find_min(node.right)
            node.val = successor.val
            # 删除后继节点
            node.right = self._delete_recursive(node.right, successor.val)
        
        return node
    
    def inorder_successor(self, node):
        """
        找到中序遍历的后继节点
        """
        # 如果有右子树，后继是右子树的最小节点
        if node.right:
            return self.find_min(node.right)
        
        # 否则，需要向上查找
        # 这里需要父节点指针，简化起见返回None
        return None
    
    def inorder_predecessor(self, node):
        """
        找到中序遍历的前驱节点
        """
        # 如果有左子树，前驱是左子树的最大节点
        if node.left:
            return self.find_max(node.left)
        
        # 否则，需要向上查找
        return None
    
    def is_valid_bst(self, root=None):
        """
        验证是否为有效的BST
        时间复杂度：O(n)
        """
        if root is None:
            root = self.root
        
        def validate(node, min_val, max_val):
            if not node:
                return True
            
            if node.val <= min_val or node.val >= max_val:
                return False
            
            return (validate(node.left, min_val, node.val) and 
                   validate(node.right, node.val, max_val))
        
        return validate(root, float('-inf'), float('inf'))
    
    def kth_smallest(self, k):
        """
        找到第k小的元素
        中序遍历的第k个元素
        时间复杂度：O(k)
        """
        count = 0
        result = None
        
        def inorder(node):
            nonlocal count, result
            if not node or result is not None:
                return
            
            inorder(node.left)
            
            count += 1
            if count == k:
                result = node.val
                return
            
            inorder(node.right)
        
        inorder(self.root)
        return result
    
    def range_sum(self, low, high):
        """
        计算范围内所有节点值的和
        时间复杂度：O(n)
        """
        def range_sum_bst(node):
            if not node:
                return 0
            
            total = 0
            
            # 剪枝优化
            if low <= node.val <= high:
                total += node.val
            
            if node.val > low:
                total += range_sum_bst(node.left)
            
            if node.val < high:
                total += range_sum_bst(node.right)
            
            return total
        
        return range_sum_bst(self.root)
```

### 3. AVL树

```python
class AVLNode:
    """AVL树节点"""
    def __init__(self, val):
        self.val = val
        self.left = None
        self.right = None
        self.height = 1  # 新节点初始高度为1

class AVLTree:
    """
    AVL树实现
    自平衡二叉搜索树，任何节点的左右子树高度差不超过1
    """
    def __init__(self):
        self.root = None
    
    def height(self, node):
        """获取节点高度"""
        return node.height if node else 0
    
    def balance_factor(self, node):
        """
        计算平衡因子
        平衡因子 = 左子树高度 - 右子树高度
        """
        return self.height(node.left) - self.height(node.right) if node else 0
    
    def update_height(self, node):
        """更新节点高度"""
        if node:
            node.height = 1 + max(self.height(node.left), self.height(node.right))
    
    def rotate_right(self, y):
        """
        右旋转（LL型）
           y                x
          / \              / \
         x   C    -->     A   y
        / \                  / \
       A   B                B   C
        """
        x = y.left
        B = x.right
        
        # 执行旋转
        x.right = y
        y.left = B
        
        # 更新高度
        self.update_height(y)
        self.update_height(x)
        
        return x
    
    def rotate_left(self, x):
        """
        左旋转（RR型）
         x                    y
        / \                  / \
       A   y       -->      x   C
          / \              / \
         B   C            A   B
        """
        y = x.right
        B = y.left
        
        # 执行旋转
        y.left = x
        x.right = B
        
        # 更新高度
        self.update_height(x)
        self.update_height(y)
        
        return y
    
    def insert(self, val):
        """
        插入节点
        时间复杂度：O(log n)
        """
        self.root = self._insert_recursive(self.root, val)
    
    def _insert_recursive(self, node, val):
        """递归插入并维护平衡"""
        # 1. 执行标准BST插入
        if not node:
            return AVLNode(val)
        
        if val < node.val:
            node.left = self._insert_recursive(node.left, val)
        elif val > node.val:
            node.right = self._insert_recursive(node.right, val)
        else:
            # 不允许重复值
            return node
        
        # 2. 更新节点高度
        self.update_height(node)
        
        # 3. 获取平衡因子，检查是否失衡
        balance = self.balance_factor(node)
        
        # 4. 如果失衡，有四种情况
        
        # LL型：左子树的左子树导致失衡
        if balance > 1 and val < node.left.val:
            return self.rotate_right(node)
        
        # RR型：右子树的右子树导致失衡
        if balance < -1 and val > node.right.val:
            return self.rotate_left(node)
        
        # LR型：左子树的右子树导致失衡
        if balance > 1 and val > node.left.val:
            node.left = self.rotate_left(node.left)
            return self.rotate_right(node)
        
        # RL型：右子树的左子树导致失衡
        if balance < -1 and val < node.right.val:
            node.right = self.rotate_right(node.right)
            return self.rotate_left(node)
        
        return node
    
    def delete(self, val):
        """
        删除节点
        时间复杂度：O(log n)
        """
        self.root = self._delete_recursive(self.root, val)
    
    def _delete_recursive(self, node, val):
        """递归删除并维护平衡"""
        # 1. 执行标准BST删除
        if not node:
            return node
        
        if val < node.val:
            node.left = self._delete_recursive(node.left, val)
        elif val > node.val:
            node.right = self._delete_recursive(node.right, val)
        else:
            # 找到要删除的节点
            if not node.left:
                return node.right
            elif not node.right:
                return node.left
            else:
                # 有两个子节点，找到右子树最小节点
                min_node = self._find_min(node.right)
                node.val = min_node.val
                node.right = self._delete_recursive(node.right, min_node.val)
        
        # 2. 更新高度
        self.update_height(node)
        
        # 3. 获取平衡因子
        balance = self.balance_factor(node)
        
        # 4. 如果失衡，进行旋转
        
        # LL型
        if balance > 1 and self.balance_factor(node.left) >= 0:
            return self.rotate_right(node)
        
        # LR型
        if balance > 1 and self.balance_factor(node.left) < 0:
            node.left = self.rotate_left(node.left)
            return self.rotate_right(node)
        
        # RR型
        if balance < -1 and self.balance_factor(node.right) <= 0:
            return self.rotate_left(node)
        
        # RL型
        if balance < -1 and self.balance_factor(node.right) > 0:
            node.right = self.rotate_right(node.right)
            return self.rotate_left(node)
        
        return node
    
    def _find_min(self, node):
        """找到最小值节点"""
        while node.left:
            node = node.left
        return node
    
    def search(self, val):
        """
        查找节点
        时间复杂度：O(log n)
        """
        current = self.root
        while current:
            if val == current.val:
                return True
            elif val < current.val:
                current = current.left
            else:
                current = current.right
        return False
```

### 4. 红黑树

```python
class RBNode:
    """红黑树节点"""
    def __init__(self, val, color="RED"):
        self.val = val
        self.color = color  # "RED" or "BLACK"
        self.left = None
        self.right = None
        self.parent = None

class RedBlackTree:
    """
    红黑树实现
    性质：
    1. 每个节点要么是红色，要么是黑色
    2. 根节点是黑色
    3. 所有叶子节点（NIL）是黑色
    4. 红色节点的两个子节点都是黑色（不能有连续的红节点）
    5. 从任一节点到其叶子节点的所有路径都包含相同数目的黑节点
    """
    def __init__(self):
        self.NIL = RBNode(None, "BLACK")  # 哨兵节点
        self.root = self.NIL
    
    def rotate_left(self, x):
        """
        左旋转
        时间复杂度：O(1)
        """
        y = x.right
        x.right = y.left
        
        if y.left != self.NIL:
            y.left.parent = x
        
        y.parent = x.parent
        
        if x.parent == None:
            self.root = y
        elif x == x.parent.left:
            x.parent.left = y
        else:
            x.parent.right = y
        
        y.left = x
        x.parent = y
    
    def rotate_right(self, x):
        """
        右旋转
        时间复杂度：O(1)
        """
        y = x.left
        x.left = y.right
        
        if y.right != self.NIL:
            y.right.parent = x
        
        y.parent = x.parent
        
        if x.parent == None:
            self.root = y
        elif x == x.parent.right:
            x.parent.right = y
        else:
            x.parent.left = y
        
        y.right = x
        x.parent = y
    
    def insert(self, val):
        """
        插入节点
        时间复杂度：O(log n)
        """
        # 创建新节点
        new_node = RBNode(val)
        new_node.left = self.NIL
        new_node.right = self.NIL
        
        # BST标准插入
        parent = None
        current = self.root
        
        while current != self.NIL:
            parent = current
            if new_node.val < current.val:
                current = current.left
            else:
                current = current.right
        
        new_node.parent = parent
        
        if parent == None:
            self.root = new_node
        elif new_node.val < parent.val:
            parent.left = new_node
        else:
            parent.right = new_node
        
        # 新节点默认为红色
        new_node.color = "RED"
        
        # 修复红黑树性质
        self._insert_fixup(new_node)
    
    def _insert_fixup(self, node):
        """
        插入后修复红黑树性质
        """
        while node.parent and node.parent.color == "RED":
            if node.parent == node.parent.parent.left:
                # 父节点是祖父节点的左子节点
                uncle = node.parent.parent.right
                
                if uncle.color == "RED":
                    # 情况1：叔叔节点是红色
                    node.parent.color = "BLACK"
                    uncle.color = "BLACK"
                    node.parent.parent.color = "RED"
                    node = node.parent.parent
                else:
                    if node == node.parent.right:
                        # 情况2：叔叔是黑色，且当前节点是右子节点
                        node = node.parent
                        self.rotate_left(node)
                    
                    # 情况3：叔叔是黑色，且当前节点是左子节点
                    node.parent.color = "BLACK"
                    node.parent.parent.color = "RED"
                    self.rotate_right(node.parent.parent)
            else:
                # 父节点是祖父节点的右子节点（对称情况）
                uncle = node.parent.parent.left
                
                if uncle.color == "RED":
                    node.parent.color = "BLACK"
                    uncle.color = "BLACK"
                    node.parent.parent.color = "RED"
                    node = node.parent.parent
                else:
                    if node == node.parent.left:
                        node = node.parent
                        self.rotate_right(node)
                    
                    node.parent.color = "BLACK"
                    node.parent.parent.color = "RED"
                    self.rotate_left(node.parent.parent)
        
        # 确保根节点是黑色
        self.root.color = "BLACK"
    
    def delete(self, val):
        """
        删除节点
        时间复杂度：O(log n)
        """
        # 查找要删除的节点
        node = self._search_node(val)
        if node == self.NIL:
            return
        
        self._delete_node(node)
    
    def _delete_node(self, z):
        """执行删除操作"""
        y = z
        y_original_color = y.color
        
        if z.left == self.NIL:
            x = z.right
            self._transplant(z, z.right)
        elif z.right == self.NIL:
            x = z.left
            self._transplant(z, z.left)
        else:
            # 找到后继节点
            y = self._minimum(z.right)
            y_original_color = y.color
            x = y.right
            
            if y.parent == z:
                x.parent = y
            else:
                self._transplant(y, y.right)
                y.right = z.right
                y.right.parent = y
            
            self._transplant(z, y)
            y.left = z.left
            y.left.parent = y
            y.color = z.color
        
        if y_original_color == "BLACK":
            self._delete_fixup(x)
    
    def _delete_fixup(self, x):
        """删除后修复红黑树性质"""
        while x != self.root and x.color == "BLACK":
            if x == x.parent.left:
                w = x.parent.right
                
                if w.color == "RED":
                    w.color = "BLACK"
                    x.parent.color = "RED"
                    self.rotate_left(x.parent)
                    w = x.parent.right
                
                if w.left.color == "BLACK" and w.right.color == "BLACK":
                    w.color = "RED"
                    x = x.parent
                else:
                    if w.right.color == "BLACK":
                        w.left.color = "BLACK"
                        w.color = "RED"
                        self.rotate_right(w)
                        w = x.parent.right
                    
                    w.color = x.parent.color
                    x.parent.color = "BLACK"
                    w.right.color = "BLACK"
                    self.rotate_left(x.parent)
                    x = self.root
            else:
                # 对称情况
                w = x.parent.left
                
                if w.color == "RED":
                    w.color = "BLACK"
                    x.parent.color = "RED"
                    self.rotate_right(x.parent)
                    w = x.parent.left
                
                if w.right.color == "BLACK" and w.left.color == "BLACK":
                    w.color = "RED"
                    x = x.parent
                else:
                    if w.left.color == "BLACK":
                        w.right.color = "BLACK"
                        w.color = "RED"
                        self.rotate_left(w)
                        w = x.parent.left
                    
                    w.color = x.parent.color
                    x.parent.color = "BLACK"
                    w.left.color = "BLACK"
                    self.rotate_right(x.parent)
                    x = self.root
        
        x.color = "BLACK"
    
    def _transplant(self, u, v):
        """用v替换u"""
        if u.parent == None:
            self.root = v
        elif u == u.parent.left:
            u.parent.left = v
        else:
            u.parent.right = v
        v.parent = u.parent
    
    def _minimum(self, node):
        """找到最小节点"""
        while node.left != self.NIL:
            node = node.left
        return node
    
    def _search_node(self, val):
        """查找节点"""
        current = self.root
        while current != self.NIL and val != current.val:
            if val < current.val:
                current = current.left
            else:
                current = current.right
        return current
```

### 5. B树与B+树

```python
class BTreeNode:
    """B树节点"""
    def __init__(self, t, leaf=False):
        self.t = t  # 最小度数
        self.keys = []  # 键列表
        self.children = []  # 子节点列表
        self.leaf = leaf  # 是否为叶子节点
        self.n = 0  # 当前键的数量

class BTree:
    """
    B树实现
    一个度数为t的B树满足：
    1. 每个节点最多有2t-1个键
    2. 每个节点最少有t-1个键（根节点除外）
    3. 所有叶子节点在同一层
    """
    def __init__(self, t):
        self.root = BTreeNode(t, True)
        self.t = t  # 最小度数
    
    def search(self, k, node=None):
        """
        搜索键k
        时间复杂度：O(log n)
        """
        if node is None:
            node = self.root
        
        # 在当前节点中查找
        i = 0
        while i < node.n and k > node.keys[i]:
            i += 1
        
        # 找到键
        if i < node.n and k == node.keys[i]:
            return True
        
        # 如果是叶子节点，键不存在
        if node.leaf:
            return False
        
        # 递归搜索子节点
        return self.search(k, node.children[i])
    
    def insert(self, k):
        """
        插入键k
        时间复杂度：O(log n)
        """
        root = self.root
        
        # 如果根节点满了，需要分裂
        if root.n == 2 * self.t - 1:
            new_root = BTreeNode(self.t, False)
            new_root.children.append(self.root)
            self._split_child(new_root, 0)
            self.root = new_root
            self._insert_non_full(new_root, k)
        else:
            self._insert_non_full(root, k)
    
    def _insert_non_full(self, node, k):
        """在未满的节点中插入键"""
        i = node.n - 1
        
        if node.leaf:
            # 在叶子节点中插入
            node.keys.append(None)
            while i >= 0 and k < node.keys[i]:
                node.keys[i + 1] = node.keys[i]
                i -= 1
            node.keys[i + 1] = k
            node.n += 1
        else:
            # 在内部节点中找到合适的子节点
            while i >= 0 and k < node.keys[i]:
                i -= 1
            i += 1
            
            # 如果子节点满了，先分裂
            if node.children[i].n == 2 * self.t - 1:
                self._split_child(node, i)
                if k > node.keys[i]:
                    i += 1
            
            self._insert_non_full(node.children[i], k)
    
    def _split_child(self, parent, i):
        """
        分裂parent的第i个子节点
        """
        t = self.t
        full_child = parent.children[i]
        new_child = BTreeNode(t, full_child.leaf)
        
        # 中间键上移到父节点
        mid_key = full_child.keys[t - 1]
        
        # 分配键
        new_child.keys = full_child.keys[t:]
        full_child.keys = full_child.keys[:t-1]
        
        # 分配子节点（如果不是叶子节点）
        if not full_child.leaf:
            new_child.children = full_child.children[t:]
            full_child.children = full_child.children[:t]
        
        # 更新键数量
        new_child.n = t - 1
        full_child.n = t - 1
        
        # 在父节点中插入中间键
        parent.keys.insert(i, mid_key)
        parent.children.insert(i + 1, new_child)
        parent.n += 1
    
    def delete(self, k):
        """
        删除键k
        时间复杂度：O(log n)
        """
        self._delete_key(self.root, k)
        
        # 如果根节点变空，更新根
        if self.root.n == 0:
            if not self.root.leaf and len(self.root.children) > 0:
                self.root = self.root.children[0]
    
    def _delete_key(self, node, k):
        """从节点中删除键k"""
        i = 0
        while i < node.n and k > node.keys[i]:
            i += 1
        
        if i < node.n and k == node.keys[i]:
            # 找到键k
            if node.leaf:
                # 情况1：k在叶子节点中
                node.keys.pop(i)
                node.n -= 1
            else:
                # 情况2：k在内部节点中
                self._delete_internal_node(node, k, i)
        elif not node.leaf:
            # 情况3：k不在当前节点中
            is_in_subtree = (i < node.n)
            
            # 如果子节点只有t-1个键，需要先处理
            if node.children[i].n == self.t - 1:
                self._fill_child(node, i)
            
            # 重新定位
            if is_in_subtree and i > node.n:
                i -= 1
            
            self._delete_key(node.children[i], k)
    
    def _delete_internal_node(self, node, k, i):
        """从内部节点删除键"""
        if node.children[i].n >= self.t:
            # 从左子树找前驱
            predecessor = self._get_predecessor(node, i)
            node.keys[i] = predecessor
            self._delete_key(node.children[i], predecessor)
        elif node.children[i + 1].n >= self.t:
            # 从右子树找后继
            successor = self._get_successor(node, i)
            node.keys[i] = successor
            self._delete_key(node.children[i + 1], successor)
        else:
            # 合并k和右子节点
            self._merge(node, i)
            self._delete_key(node.children[i], k)
    
    def _get_predecessor(self, node, i):
        """获取前驱键"""
        current = node.children[i]
        while not current.leaf:
            current = current.children[current.n]
        return current.keys[current.n - 1]
    
    def _get_successor(self, node, i):
        """获取后继键"""
        current = node.children[i + 1]
        while not current.leaf:
            current = current.children[0]
        return current.keys[0]
    
    def _fill_child(self, node, i):
        """填充子节点"""
        # 如果前一个兄弟有足够的键，借一个
        if i != 0 and node.children[i - 1].n >= self.t:
            self._borrow_from_prev(node, i)
        # 如果后一个兄弟有足够的键，借一个
        elif i != node.n and node.children[i + 1].n >= self.t:
            self._borrow_from_next(node, i)
        # 否则，与兄弟合并
        else:
            if i != node.n:
                self._merge(node, i)
            else:
                self._merge(node, i - 1)
    
    def _borrow_from_prev(self, node, child_index):
        """从前一个兄弟借键"""
        child = node.children[child_index]
        sibling = node.children[child_index - 1]
        
        # 将父节点的键下移到child
        child.keys.insert(0, node.keys[child_index - 1])
        
        # 将兄弟的最后一个键上移到父节点
        node.keys[child_index - 1] = sibling.keys[sibling.n - 1]
        
        # 移动子节点指针
        if not child.leaf:
            child.children.insert(0, sibling.children[sibling.n])
            sibling.children.pop()
        
        # 更新键数量
        sibling.keys.pop()
        child.n += 1
        sibling.n -= 1
    
    def _borrow_from_next(self, node, child_index):
        """从后一个兄弟借键"""
        child = node.children[child_index]
        sibling = node.children[child_index + 1]
        
        # 将父节点的键下移到child
        child.keys.append(node.keys[child_index])
        
        # 将兄弟的第一个键上移到父节点
        node.keys[child_index] = sibling.keys[0]
        
        # 移动子节点指针
        if not child.leaf:
            child.children.append(sibling.children[0])
            sibling.children.pop(0)
        
        # 更新键数量
        sibling.keys.pop(0)
        child.n += 1
        sibling.n -= 1
    
    def _merge(self, node, i):
        """合并子节点"""
        child = node.children[i]
        sibling = node.children[i + 1]
        
        # 将父节点的键和兄弟的所有键合并到child
        child.keys.append(node.keys[i])
        child.keys.extend(sibling.keys)
        
        # 复制子节点指针
        if not child.leaf:
            child.children.extend(sibling.children)
        
        # 更新父节点
        node.keys.pop(i)
        node.children.pop(i + 1)
        
        # 更新键数量
        child.n = 2 * self.t - 1
        node.n -= 1


class BPlusTreeNode:
    """B+树节点"""
    def __init__(self, leaf=False):
        self.keys = []
        self.values = []  # 只在叶子节点存储值
        self.children = []
        self.leaf = leaf
        self.next = None  # 叶子节点的链表指针

class BPlusTree:
    """
    B+树实现
    与B树的区别：
    1. 所有数据都存储在叶子节点
    2. 叶子节点形成有序链表
    3. 内部节点只存储索引
    """
    def __init__(self, order):
        self.root = BPlusTreeNode(leaf=True)
        self.order = order  # 阶数
    
    def search(self, key):
        """
        搜索键
        时间复杂度：O(log n)
        """
        node = self.root
        
        while not node.leaf:
            i = 0
            while i < len(node.keys) and key >= node.keys[i]:
                i += 1
            node = node.children[i]
        
        # 在叶子节点中查找
        try:
            idx = node.keys.index(key)
            return node.values[idx]
        except ValueError:
            return None
    
    def insert(self, key, value):
        """
        插入键值对
        时间复杂度：O(log n)
        """
        root = self.root
        
        # 如果根节点满了
        if len(root.keys) >= self.order - 1:
            new_root = BPlusTreeNode()
            new_root.children.append(self.root)
            self._split_child(new_root, 0)
            self.root = new_root
        
        self._insert_non_full(self.root, key, value)
    
    def _insert_non_full(self, node, key, value):
        """在未满的节点中插入"""
        if node.leaf:
            # 在叶子节点中插入
            i = 0
            while i < len(node.keys) and key > node.keys[i]:
                i += 1
            
            node.keys.insert(i, key)
            node.values.insert(i, value)
        else:
            # 找到合适的子节点
            i = 0
            while i < len(node.keys) and key >= node.keys[i]:
                i += 1
            
            # 如果子节点满了，先分裂
            if len(node.children[i].keys) >= self.order - 1:
                self._split_child(node, i)
                if key >= node.keys[i]:
                    i += 1
            
            self._insert_non_full(node.children[i], key, value)
    
    def _split_child(self, parent, index):
        """分裂子节点"""
        full_node = parent.children[index]
        new_node = BPlusTreeNode(leaf=full_node.leaf)
        
        mid = len(full_node.keys) // 2
        
        if full_node.leaf:
            # 分裂叶子节点
            new_node.keys = full_node.keys[mid:]
            new_node.values = full_node.values[mid:]
            full_node.keys = full_node.keys[:mid]
            full_node.values = full_node.values[:mid]
            
            # 维护叶子节点链表
            new_node.next = full_node.next
            full_node.next = new_node
            
            # 提升中间键到父节点
            parent.keys.insert(index, new_node.keys[0])
        else:
            # 分裂内部节点
            new_node.keys = full_node.keys[mid+1:]
            new_node.children = full_node.children[mid+1:]
            
            # 提升中间键
            mid_key = full_node.keys[mid]
            full_node.keys = full_node.keys[:mid]
            full_node.children = full_node.children[:mid+1]
            
            parent.keys.insert(index, mid_key)
        
        parent.children.insert(index + 1, new_node)
    
    def range_query(self, start_key, end_key):
        """
        范围查询
        时间复杂度：O(log n + m)，m为结果数量
        """
        # 找到起始叶子节点
        node = self.root
        while not node.leaf:
            i = 0
            while i < len(node.keys) and start_key >= node.keys[i]:
                i += 1
            node = node.children[i]
        
        # 收集范围内的所有值
        result = []
        while node:
            for i, key in enumerate(node.keys):
                if key > end_key:
                    return result
                if key >= start_key:
                    result.append((key, node.values[i]))
            node = node.next
        
        return result
```

### 6. 堆

```python
class MinHeap:
    """
    最小堆实现
    父节点的值小于等于子节点的值
    """
    def __init__(self):
        self.heap = []
    
    def parent(self, i):
        """获取父节点索引"""
        return (i - 1) // 2
    
    def left_child(self, i):
        """获取左子节点索引"""
        return 2 * i + 1
    
    def right_child(self, i):
        """获取右子节点索引"""
        return 2 * i + 2
    
    def insert(self, key):
        """
        插入元素
        时间复杂度：O(log n)
        """
        # 将新元素添加到末尾
        self.heap.append(key)
        
        # 向上调整（上浮）
        self._heapify_up(len(self.heap) - 1)
    
    def _heapify_up(self, i):
        """向上调整"""
        parent = self.parent(i)
        
        if i > 0 and self.heap[i] < self.heap[parent]:
            # 交换
            self.heap[i], self.heap[parent] = self.heap[parent], self.heap[i]
            # 递归向上调整
            self._heapify_up(parent)
    
    def extract_min(self):
        """
        提取最小元素
        时间复杂度：O(log n)
        """
        if not self.heap:
            raise IndexError("Heap is empty")
        
        if len(self.heap) == 1:
            return self.heap.pop()
        
        # 保存最小值
        min_val = self.heap[0]
        
        # 将最后一个元素移到根
        self.heap[0] = self.heap.pop()
        
        # 向下调整（下沉）
        self._heapify_down(0)
        
        return min_val
    
    def _heapify_down(self, i):
        """向下调整"""
        smallest = i
        left = self.left_child(i)
        right = self.right_child(i)
        
        # 找到最小的节点
        if left < len(self.heap) and self.heap[left] < self.heap[smallest]:
            smallest = left
        
        if right < len(self.heap) and self.heap[right] < self.heap[smallest]:
            smallest = right
        
        # 如果最小的不是当前节点，交换并继续调整
        if smallest != i:
            self.heap[i], self.heap[smallest] = self.heap[smallest], self.heap[i]
            self._heapify_down(smallest)
    
    def peek(self):
        """查看最小元素"""
        if not self.heap:
            raise IndexError("Heap is empty")
        return self.heap[0]
    
    def build_heap(self, arr):
        """
        从数组构建堆
        时间复杂度：O(n)
        """
        self.heap = arr[:]
        
        # 从最后一个非叶子节点开始向下调整
        for i in range(len(self.heap) // 2 - 1, -1, -1):
            self._heapify_down(i)
    
    def heap_sort(self, arr):
        """
        堆排序
        时间复杂度：O(n log n)
        空间复杂度：O(1)
        """
        self.build_heap(arr)
        sorted_arr = []
        
        while self.heap:
            sorted_arr.append(self.extract_min())
        
        return sorted_arr
    
    def decrease_key(self, i, new_val):
        """
        减小某个位置的值
        时间复杂度：O(log n)
        """
        if new_val > self.heap[i]:
            raise ValueError("New value is greater than current value")
        
        self.heap[i] = new_val
        self._heapify_up(i)
    
    def delete(self, i):
        """
        删除指定位置的元素
        时间复杂度：O(log n)
        """
        # 将要删除的元素减小到负无穷
        self.decrease_key(i, float('-inf'))
        # 提取最小值（即要删除的元素）
        self.extract_min()


class MaxHeap:
    """最大堆实现"""
    def __init__(self):
        self.heap = []
    
    def insert(self, key):
        """插入元素"""
        self.heap.append(key)
        self._heapify_up(len(self.heap) - 1)
    
    def _heapify_up(self, i):
        """向上调整"""
        parent = (i - 1) // 2
        
        if i > 0 and self.heap[i] > self.heap[parent]:
            self.heap[i], self.heap[parent] = self.heap[parent], self.heap[i]
            self._heapify_up(parent)
    
    def extract_max(self):
        """提取最大元素"""
        if not self.heap:
            raise IndexError("Heap is empty")
        
        if len(self.heap) == 1:
            return self.heap.pop()
        
        max_val = self.heap[0]
        self.heap[0] = self.heap.pop()
        self._heapify_down(0)
        
        return max_val
    
    def _heapify_down(self, i):
        """向下调整"""
        largest = i
        left = 2 * i + 1
        right = 2 * i + 2
        
        if left < len(self.heap) and self.heap[left] > self.heap[largest]:
            largest = left
        
        if right < len(self.heap) and self.heap[right] > self.heap[largest]:
            largest = right
        
        if largest != i:
            self.heap[i], self.heap[largest] = self.heap[largest], self.heap[i]
            self._heapify_down(largest)


class IndexedMinHeap:
    """
    索引最小堆
    支持通过索引快速访问和修改元素
    """
    def __init__(self, capacity):
        self.capacity = capacity
        self.size = 0
        self.keys = [None] * capacity  # 键值
        self.pq = []  # 优先队列，存储索引
        self.qp = [-1] * capacity  # 索引在pq中的位置
    
    def insert(self, i, key):
        """
        插入键值对
        i: 索引
        key: 键值
        """
        if i < 0 or i >= self.capacity:
            raise IndexError("Index out of range")
        
        if self.contains(i):
            raise ValueError(f"Index {i} already exists")
        
        self.size += 1
        self.qp[i] = len(self.pq)
        self.pq.append(i)
        self.keys[i] = key
        
        self._swim(self.qp[i])
    
    def contains(self, i):
        """检查索引是否存在"""
        return 0 <= i < self.capacity and self.qp[i] != -1
    
    def min_key(self):
        """获取最小键值"""
        if self.size == 0:
            raise IndexError("Heap is empty")
        return self.keys[self.pq[0]]
    
    def min_index(self):
        """获取最小键值的索引"""
        if self.size == 0:
            raise IndexError("Heap is empty")
        return self.pq[0]
    
    def del_min(self):
        """删除最小元素"""
        if self.size == 0:
            raise IndexError("Heap is empty")
        
        min_idx = self.pq[0]
        self._exchange(0, len(self.pq) - 1)
        self.pq.pop()
        self.size -= 1
        
        self.qp[min_idx] = -1
        self.keys[min_idx] = None
        
        if self.size > 0:
            self._sink(0)
        
        return min_idx
    
    def decrease_key(self, i, key):
        """减小键值"""
        if not self.contains(i):
            raise ValueError(f"Index {i} not in heap")
        
        if self.keys[i] <= key:
            raise ValueError("New key not smaller")
        
        self.keys[i] = key
        self._swim(self.qp[i])
    
    def _swim(self, k):
        """上浮"""
        while k > 0 and self._greater((k - 1) // 2, k):
            self._exchange((k - 1) // 2, k)
            k = (k - 1) // 2
    
    def _sink(self, k):
        """下沉"""
        while 2 * k + 1 < len(self.pq):
            j = 2 * k + 1
            
            if j + 1 < len(self.pq) and self._greater(j, j + 1):
                j += 1
            
            if not self._greater(k, j):
                break
            
            self._exchange(k, j)
            k = j
    
    def _greater(self, i, j):
        """比较两个位置的键值"""
        return self.keys[self.pq[i]] > self.keys[self.pq[j]]
    
    def _exchange(self, i, j):
        """交换两个位置"""
        self.pq[i], self.pq[j] = self.pq[j], self.pq[i]
        self.qp[self.pq[i]] = i
        self.qp[self.pq[j]] = j
```

### 7. 字典树（Trie）

```python
class TrieNode:
    """Trie节点"""
    def __init__(self):
        self.children = {}  # 使用字典存储子节点
        self.is_end = False  # 标记是否为单词结尾
        self.count = 0  # 记录以此节点结尾的单词数量
        self.prefix_count = 0  # 记录经过此节点的前缀数量

class Trie:
    """
    字典树实现
    用于高效存储和检索字符串
    """
    def __init__(self):
        self.root = TrieNode()
    
    def insert(self, word):
        """
        插入单词
        时间复杂度：O(m)，m为单词长度
        """
        node = self.root
        
        for char in word:
            node.prefix_count += 1
            
            if char not in node.children:
                node.children[char] = TrieNode()
            
            node = node.children[char]
        
        node.is_end = True
        node.count += 1
        node.prefix_count += 1
    
    def search(self, word):
        """
        搜索单词是否存在
        时间复杂度：O(m)
        """
        node = self.root
        
        for char in word:
            if char not in node.children:
                return False
            node = node.children[char]
        
        return node.is_end
    
    def starts_with(self, prefix):
        """
        检查是否存在以prefix开头的单词
        时间复杂度：O(m)
        """
        node = self.root
        
        for char in prefix:
            if char not in node.children:
                return False
            node = node.children[char]
        
        return True
    
    def count_prefix(self, prefix):
        """
        统计以prefix为前缀的单词数量
        时间复杂度：O(m)
        """
        node = self.root
        
        for char in prefix:
            if char not in node.children:
                return 0
            node = node.children[char]
        
        return node.prefix_count
    
    def delete(self, word):
        """
        删除单词
        时间复杂度：O(m)
        """
        def _delete(node, word, index):
            if index == len(word):
                # 到达单词末尾
                if node.is_end:
                    node.count -= 1
                    if node.count == 0:
                        node.is_end = False
                    return True
                return False
            
            char = word[index]
            if char not in node.children:
                return False
            
            child = node.children[char]
            if _delete(child, word, index + 1):
                child.prefix_count -= 1
                
                # 如果子节点没有任何单词经过，删除该子节点
                if child.prefix_count == 0:
                    del node.children[char]
                
                return True
            
            return False
        
        if _delete(self.root, word, 0):
            self.root.prefix_count -= 1
    
    def get_all_words(self):
        """
        获取所有单词
        时间复杂度：O(n)，n为所有单词的总字符数
        """
        words = []
        
        def dfs(node, path):
            if node.is_end:
                words.extend([path] * node.count)
            
            for char, child in node.children.items():
                dfs(child, path + char)
        
        dfs(self.root, "")
        return words
    
    def auto_complete(self, prefix, limit=10):
        """
        自动补全功能
        返回以prefix开头的单词列表
        """
        node = self.root
        
        # 找到前缀的终点
        for char in prefix:
            if char not in node.children:
                return []
            node = node.children[char]
        
        # 收集所有以prefix开头的单词
        words = []
        
        def dfs(node, path):
            if len(words) >= limit:
                return
            
            if node.is_end:
                words.extend([prefix + path] * min(node.count, limit - len(words)))
            
            # 按字典序遍历
            for char in sorted(node.children.keys()):
                if len(words) < limit:
                    dfs(node.children[char], path + char)
        
        dfs(node, "")
        return words[:limit]


class CompressedTrie:
    """
    压缩字典树（Patricia Trie）
    将只有一个子节点的路径压缩成一条边
    """
    class Node:
        def __init__(self, edge_label=""):
            self.edge_label = edge_label  # 边上的字符串
            self.children = {}
            self.is_end = False
    
    def __init__(self):
        self.root = self.Node()
    
    def insert(self, word):
        """插入单词"""
        if not word:
            self.root.is_end = True
            return
        
        node = self.root
        i = 0
        
        while i < len(word):
            found = False
            
            for char, child in node.children.items():
                # 找到共同前缀
                j = 0
                while (j < len(child.edge_label) and 
                       i + j < len(word) and 
                       child.edge_label[j] == word[i + j]):
                    j += 1
                
                if j > 0:
                    found = True
                    
                    if j == len(child.edge_label):
                        # 完全匹配边标签
                        node = child
                        i += j
                    else:
                        # 部分匹配，需要分裂
                        # 创建新的中间节点
                        mid_node = self.Node(child.edge_label[:j])
                        
                        # 调整原节点
                        child.edge_label = child.edge_label[j:]
                        
                        # 重新连接
                        node.children[char] = mid_node
                        mid_node.children[child.edge_label[0]] = child
                        
                        if i + j == len(word):
                            mid_node.is_end = True
                        else:
                            # 创建新的叶子节点
                            new_node = self.Node(word[i + j:])
                            new_node.is_end = True
                            mid_node.children[word[i + j]] = new_node
                        
                        return
                    
                    break
            
            if not found:
                # 没有匹配的边，创建新节点
                new_node = self.Node(word[i:])
                new_node.is_end = True
                node.children[word[i]] = new_node
                return
        
        node.is_end = True
    
    def search(self, word):
        """搜索单词"""
        node = self.root
        i = 0
        
        while i < len(word):
            found = False
            
            for char, child in node.children.items():
                if char == word[i]:
                    # 检查边标签是否匹配
                    edge = child.edge_label
                    if word[i:i+len(edge)] == edge:
                        node = child
                        i += len(edge)
                        found = True
                        break
            
            if not found:
                return False
        
        return node.is_end
```

### 8. 后缀树与后缀数组

```python
class SuffixArray:
    """
    后缀数组实现
    用于字符串匹配和处理
    """
    def __init__(self, text):
        self.text = text
        self.n = len(text)
        self.suffix_array = self._build_suffix_array()
        self.lcp_array = self._build_lcp_array()
    
    def _build_suffix_array(self):
        """
        构建后缀数组
        时间复杂度：O(n log n)
        """
        # 创建后缀列表
        suffixes = []
        for i in range(self.n):
            suffixes.append((self.text[i:], i))
        
        # 按字典序排序
        suffixes.sort()
        
        # 提取索引
        return [suffix[1] for suffix in suffixes]
    
    def _build_suffix_array_optimized(self):
        """
        优化的后缀数组构建（使用倍增算法）
        时间复杂度：O(n log n)
        """
        n = self.n
        # 初始排名
        rank = [ord(c) for c in self.text]
        sa = list(range(n))
        
        k = 1
        while k < n:
            # 按照(rank[i], rank[i+k])排序
            sa.sort(key=lambda i: (rank[i], rank[i + k] if i + k < n else -1))
            
            # 更新排名
            new_rank = [0] * n
            for i in range(1, n):
                prev = sa[i - 1]
                curr = sa[i]
                
                if (rank[prev] == rank[curr] and 
                    (prev + k >= n and curr + k >= n or 
                     prev + k < n and curr + k < n and 
                     rank[prev + k] == rank[curr + k])):
                    new_rank[curr] = new_rank[prev]
                else:
                    new_rank[curr] = new_rank[prev] + 1
            
            rank = new_rank
            k *= 2
        
        return sa
    
    def _build_lcp_array(self):
        """
        构建最长公共前缀数组
        LCP[i] = 后缀SA[i]和SA[i+1]的最长公共前缀长度
        时间复杂度：O(n)
        """
        n = self.n
        lcp = [0] * (n - 1)
        rank = [0] * n
        
        # 计算排名数组
        for i in range(n):
            rank[self.suffix_array[i]] = i
        
        h = 0
        for i in range(n):
            if rank[i] > 0:
                j = self.suffix_array[rank[i] - 1]
                
                # 计算LCP
                while i + h < n and j + h < n and self.text[i + h] == self.text[j + h]:
                    h += 1
                
                lcp[rank[i] - 1] = h
                
                if h > 0:
                    h -= 1
        
        return lcp
    
    def search(self, pattern):
        """
        搜索模式串出现的所有位置
        时间复杂度：O(m log n + k)，m为模式串长度，k为出现次数
        """
        m = len(pattern)
        left, right = 0, self.n - 1
        
        # 二分查找左边界
        while left < right:
            mid = (left + right) // 2
            suffix_start = self.suffix_array[mid]
            
            if self.text[suffix_start:suffix_start + m] < pattern:
                left = mid + 1
            else:
                right = mid
        
        # 检查是否找到
        if self.text[self.suffix_array[left]:self.suffix_array[left] + m] != pattern:
            return []
        
        # 找到右边界
        start = left
        right = self.n - 1
        
        while left < right:
            mid = (left + right + 1) // 2
            suffix_start = self.suffix_array[mid]
            
            if self.text[suffix_start:suffix_start + m] <= pattern:
                left = mid
            else:
                right = mid - 1
        
        # 收集所有出现位置
        positions = []
        for i in range(start, left + 1):
            positions.append(self.suffix_array[i])
        
        return sorted(positions)
    
    def longest_repeated_substring(self):
        """
        找到最长重复子串
        时间复杂度：O(n)
        """
        if not self.lcp_array:
            return ""
        
        max_lcp = max(self.lcp_array)
        max_idx = self.lcp_array.index(max_lcp)
        
        start = self.suffix_array[max_idx]
        return self.text[start:start + max_lcp]
    
    def count_distinct_substrings(self):
        """
        计算不同子串的数量
        时间复杂度：O(n)
        """
        # 总子串数 - 重复的子串数
        total = self.n * (self.n + 1) // 2
        repeated = sum(self.lcp_array)
        
        return total - repeated


class SuffixTree:
    """
    后缀树实现（使用Ukkonen算法）
    """
    class Node:
        def __init__(self, start=-1, end=None):
            self.start = start
            self.end = end  # None表示叶子节点（延伸到字符串末尾）
            self.children = {}
            self.suffix_link = None
            self.suffix_index = -1
    
    def __init__(self, text):
        self.text = text + '$'  # 添加终止符
        self.n = len(self.text)
        self.root = self.Node()
        self.root.suffix_link = self.root
        self._build_suffix_tree()
    
    def _build_suffix_tree(self):
        """
        使用Ukkonen算法构建后缀树
        时间复杂度：O(n)
        """
        # 活动点
        active_node = self.root
        active_edge = -1
        active_length = 0
        
        # 剩余后缀计数
        remaining = 0
        
        # 叶子节点的结束位置（全局）
        leaf_end = [-1]
        
        for i in range(self.n):
            leaf_end[0] = i
            remaining += 1
            last_created = None
            
            while remaining > 0:
                if active_length == 0:
                    active_edge = i
                
                if self.text[active_edge] not in active_node.children:
                    # 创建新叶子
                    leaf = self.Node(i, leaf_end)
                    active_node.children[self.text[active_edge]] = leaf
                    
                    # 创建后缀链接
                    if last_created:
                        last_created.suffix_link = active_node
                    last_created = active_node
                else:
                    # 沿着边走
                    next_node = active_node.children[self.text[active_edge]]
                    edge_length = self._edge_length(next_node, i)
                    
                    if active_length >= edge_length:
                        # 继续向下走
                        active_edge += edge_length
                        active_length -= edge_length
                        active_node = next_node
                        continue
                    
                    # 当前字符已经在边上
                    if self.text[next_node.start + active_length] == self.text[i]:
                        # 更新活动点
                        active_length += 1
                        
                        if last_created:
                            last_created.suffix_link = active_node
                        
                        break
                    
                    # 需要分裂边
                    split = self.Node(next_node.start, [next_node.start + active_length - 1])
                    active_node.children[self.text[active_edge]] = split
                    
                    # 创建新叶子
                    leaf = self.Node(i, leaf_end)
                    split.children[self.text[i]] = leaf
                    
                    # 调整原节点
                    next_node.start += active_length
                    split.children[self.text[next_node.start]] = next_node
                    
                    # 创建后缀链接
                    if last_created:
                        last_created.suffix_link = split
                    last_created = split
                
                remaining -= 1
                
                if active_node == self.root and active_length > 0:
                    active_length -= 1
                    active_edge = i - remaining + 1
                elif active_node != self.root:
                    active_node = active_node.suffix_link
        
        # 设置后缀索引
        self._set_suffix_index(self.root, 0)
    
    def _edge_length(self, node, current_pos):
        """计算边的长度"""
        if isinstance(node.end, list):
            return node.end[0] - node.start + 1
        else:
            return current_pos - node.start + 1
    
    def _set_suffix_index(self, node, label_height):
        """设置后缀索引"""
        if node.start != -1:
            # 非根节点
            label_height += self._edge_length(node, self.n - 1)
        
        is_leaf = True
        for child in node.children.values():
            is_leaf = False
            self._set_suffix_index(child, label_height)
        
        if is_leaf:
            node.suffix_index = self.n - label_height
    
    def search(self, pattern):
        """
        搜索模式串
        时间复杂度：O(m)，m为模式串长度
        """
        node = self.root
        i = 0
        
        while i < len(pattern):
            if pattern[i] in node.children:
                child = node.children[pattern[i]]
                edge_label = self._get_edge_label(child)
                
                j = 0
                while i < len(pattern) and j < len(edge_label) and pattern[i] == edge_label[j]:
                    i += 1
                    j += 1
                
                if j == len(edge_label):
                    node = child
                elif i == len(pattern):
                    return self._collect_leaves(child)
                else:
                    return []
            else:
                return []
        
        return self._collect_leaves(node)
    
    def _get_edge_label(self, node):
        """获取边上的字符串"""
        if isinstance(node.end, list):
            return self.text[node.start:node.end[0] + 1]
        else:
            return self.text[node.start:]
    
    def _collect_leaves(self, node):
        """收集所有叶子节点的后缀索引"""
        indices = []
        
        if node.suffix_index >= 0:
            indices.append(node.suffix_index)
        
        for child in node.children.values():
            indices.extend(self._collect_leaves(child))
        
        return indices
```

### 9. 线段树

```python
class SegmentTree:
    """
    线段树实现
    支持区间查询和单点/区间更新
    """
    def __init__(self, arr):
        self.n = len(arr)
        self.tree = [0] * (4 * self.n)  # 线段树数组
        self.lazy = [0] * (4 * self.n)  # 延迟标记数组
        self._build(arr, 0, 0, self.n - 1)
    
    def _build(self, arr, node, start, end):
        """
        构建线段树
        时间复杂度：O(n)
        """
        if start == end:
            # 叶子节点
            self.tree[node] = arr[start]
        else:
            mid = (start + end) // 2
            left_child = 2 * node + 1
            right_child = 2 * node + 2
            
            # 递归构建左右子树
            self._build(arr, left_child, start, mid)
            self._build(arr, right_child, mid + 1, end)
            
            # 合并子节点信息
            self.tree[node] = self.tree[left_child] + self.tree[right_child]
    
    def update_point(self, idx, val):
        """
        单点更新
        时间复杂度：O(log n)
        """
        self._update_point(0, 0, self.n - 1, idx, val)
    
    def _update_point(self, node, start, end, idx, val):
        """单点更新的递归实现"""
        if start == end:
            self.tree[node] = val
            return
        
        mid = (start + end) // 2
        left_child = 2 * node + 1
        right_child = 2 * node + 2
        
        if idx <= mid:
            self._update_point(left_child, start, mid, idx, val)
        else:
            self._update_point(right_child, mid + 1, end, idx, val)
        
        # 更新当前节点
        self.tree[node] = self.tree[left_child] + self.tree[right_child]
    
    def update_range(self, l, r, val):
        """
        区间更新（使用延迟传播）
        时间复杂度：O(log n)
        """
        self._update_range(0, 0, self.n - 1, l, r, val)
    
    def _update_range(self, node, start, end, l, r, val):
        """区间更新的递归实现"""
        # 处理延迟更新
        if self.lazy[node] != 0:
            self.tree[node] += (end - start + 1) * self.lazy[node]
            
            if start != end:
                # 传播到子节点
                self.lazy[2 * node + 1] += self.lazy[node]
                self.lazy[2 * node + 2] += self.lazy[node]
            
            self.lazy[node] = 0
        
        # 无交集
        if start > r or end < l:
            return
        
        # 完全包含
        if start >= l and end <= r:
            self.tree[node] += (end - start + 1) * val
            
            if start != end:
                # 标记子节点
                self.lazy[2 * node + 1] += val
                self.lazy[2 * node + 2] += val
            
            return
        
        # 部分包含
        mid = (start + end) // 2
        left_child = 2 * node + 1
        right_child = 2 * node + 2
        
        self._update_range(left_child, start, mid, l, r, val)
        self._update_range(right_child, mid + 1, end, l, r, val)
        
        self.tree[node] = self.tree[left_child] + self.tree[right_child]
    
    def query(self, l, r):
        """
        区间查询
        时间复杂度：O(log n)
        """
        return self._query(0, 0, self.n - 1, l, r)
    
    def _query(self, node, start, end, l, r):
        """区间查询的递归实现"""
        # 处理延迟更新
        if self.lazy[node] != 0:
            self.tree[node] += (end - start + 1) * self.lazy[node]
            
            if start != end:
                self.lazy[2 * node + 1] += self.lazy[node]
                self.lazy[2 * node + 2] += self.lazy[node]
            
            self.lazy[node] = 0
        
        # 无交集
        if start > r or end < l:
            return 0
        
        # 完全包含
        if start >= l and end <= r:
            return self.tree[node]
        
        # 部分包含
        mid = (start + end) // 2
        left_sum = self._query(2 * node + 1, start, mid, l, r)
        right_sum = self._query(2 * node + 2, mid + 1, end, l, r)
        
        return left_sum + right_sum


class SegmentTree2D:
    """
    二维线段树
    支持二维区间查询和更新
    """
    def __init__(self, matrix):
        self.rows = len(matrix)
        self.cols = len(matrix[0]) if matrix else 0
        self.tree = [[0] * (4 * self.cols) for _ in range(4 * self.rows)]
        
        if matrix:
            self._build_2d(matrix, 0, 0, self.rows - 1)
    
    def _build_2d(self, matrix, node_x, start_x, end_x):
        """构建二维线段树"""
        if start_x == end_x:
            # 构建一维线段树
            self._build_1d(matrix, node_x, start_x, 0, 0, self.cols - 1)
        else:
            mid_x = (start_x + end_x) // 2
            left_child = 2 * node_x + 1
            right_child = 2 * node_x + 2
            
            self._build_2d(matrix, left_child, start_x, mid_x)
            self._build_2d(matrix, right_child, mid_x + 1, end_x)
            
            # 合并
            self._merge_1d(node_x, left_child, right_child, 0, 0, self.cols - 1)
    
    def _build_1d(self, matrix, node_x, row, node_y, start_y, end_y):
        """构建一维线段树"""
        if start_y == end_y:
            self.tree[node_x][node_y] = matrix[row][start_y]
        else:
            mid_y = (start_y + end_y) // 2
            left_child = 2 * node_y + 1
            right_child = 2 * node_y + 2
            
            self._build_1d(matrix, node_x, row, left_child, start_y, mid_y)
            self._build_1d(matrix, node_x, row, right_child, mid_y + 1, end_y)
            
            self.tree[node_x][node_y] = (self.tree[node_x][left_child] + 
                                         self.tree[node_x][right_child])
    
    def _merge_1d(self, node_x, left_x, right_x, node_y, start_y, end_y):
        """合并一维线段树"""
        if start_y == end_y:
            self.tree[node_x][node_y] = (self.tree[left_x][node_y] + 
                                         self.tree[right_x][node_y])
        else:
            mid_y = (start_y + end_y) // 2
            left_child = 2 * node_y + 1
            right_child = 2 * node_y + 2
            
            self._merge_1d(node_x, left_x, right_x, left_child, start_y, mid_y)
            self._merge_1d(node_x, left_x, right_x, right_child, mid_y + 1, end_y)
            
            self.tree[node_x][node_y] = (self.tree[node_x][left_child] + 
                                         self.tree[node_x][right_child])
    
    def query(self, x1, y1, x2, y2):
        """
        二维区间查询
        时间复杂度：O(log m * log n)
        """
        return self._query_2d(0, 0, self.rows - 1, x1, x2, y1, y2)
    
    def _query_2d(self, node_x, start_x, end_x, x1, x2, y1, y2):
        """二维查询的递归实现"""
        if start_x > x2 or end_x < x1:
            return 0
        
        if start_x >= x1 and end_x <= x2:
            return self._query_1d(node_x, 0, 0, self.cols - 1, y1, y2)
        
        mid_x = (start_x + end_x) // 2
        left_sum = self._query_2d(2 * node_x + 1, start_x, mid_x, x1, x2, y1, y2)
        right_sum = self._query_2d(2 * node_x + 2, mid_x + 1, end_x, x1, x2, y1, y2)
        
        return left_sum + right_sum
    
    def _query_1d(self, node_x, node_y, start_y, end_y, y1, y2):
        """一维查询的递归实现"""
        if start_y > y2 or end_y < y1:
            return 0
        
        if start_y >= y1 and end_y <= y2:
            return self.tree[node_x][node_y]
        
        mid_y = (start_y + end_y) // 2
        left_sum = self._query_1d(node_x, 2 * node_y + 1, start_y, mid_y, y1, y2)
        right_sum = self._query_1d(node_x, 2 * node_y + 2, mid_y + 1, end_y, y1, y2)
        
        return left_sum + right_sum
```

### 10. 树状数组（Fenwick Tree）

```python
class FenwickTree:
    """
    树状数组（Binary Indexed Tree）实现
    用于高效处理前缀和查询和单点更新
    """
    def __init__(self, n):
        self.n = n
        self.tree = [0] * (n + 1)  # 下标从1开始
    
    def lowbit(self, x):
        """
        获取x的最低位1
        例如：lowbit(6) = 2 (二进制110的最低位1是10)
        """
        return x & (-x)
    
    def update(self, idx, delta):
        """
        单点更新：将idx位置的值增加delta
        时间复杂度：O(log n)
        """
        idx += 1  # 转换为1-indexed
        
        while idx <= self.n:
            self.tree[idx] += delta
            idx += self.lowbit(idx)
    
    def query(self, idx):
        """
        查询前缀和：返回[0, idx]的和
        时间复杂度：O(log n)
        """
        idx += 1  # 转换为1-indexed
        result = 0
        
        while idx > 0:
            result += self.tree[idx]
            idx -= self.lowbit(idx)
        
        return result
    
    def range_query(self, left, right):
        """
        区间查询：返回[left, right]的和
        时间复杂度：O(log n)
        """
        if left == 0:
            return self.query(right)
        return self.query(right) - self.query(left - 1)
    
    def build(self, arr):
        """
        从数组构建树状数组
        时间复杂度：O(n log n)
        """
        for i in range(len(arr)):
            self.update(i, arr[i])
    
    def build_optimized(self, arr):
        """
        优化的构建方法
        时间复杂度：O(n)
        """
        # 先复制数组
        for i in range(len(arr)):
            self.tree[i + 1] = arr[i]
        
        # 构建树状数组
        for i in range(1, self.n + 1):
            j = i + self.lowbit(i)
            if j <= self.n:
                self.tree[j] += self.tree[i]


class FenwickTree2D:
    """
    二维树状数组
    支持二维区间查询和单点更新
    """
    def __init__(self, rows, cols):
        self.rows = rows
        self.cols = cols
        self.tree = [[0] * (cols + 1) for _ in range(rows + 1)]
    
    def lowbit(self, x):
        """获取最低位1"""
        return x & (-x)
    
    def update(self, row, col, delta):
        """
        单点更新
        时间复杂度：O(log m * log n)
        """
        row += 1
        col += 1
        
        i = row
        while i <= self.rows:
            j = col
            while j <= self.cols:
                self.tree[i][j] += delta
                j += self.lowbit(j)
            i += self.lowbit(i)
    
    def query(self, row, col):
        """
        查询(0,0)到(row,col)的矩形和
        时间复杂度：O(log m * log n)
        """
        row += 1
        col += 1
        result = 0
        
        i = row
        while i > 0:
            j = col
            while j > 0:
                result += self.tree[i][j]
                j -= self.lowbit(j)
            i -= self.lowbit(i)
        
        return result
    
    def range_query(self, row1, col1, row2, col2):
        """
        查询矩形区域的和
        时间复杂度：O(log m * log n)
        """
        # 使用容斥原理
        total = self.query(row2, col2)
        
        if row1 > 0:
            total -= self.query(row1 - 1, col2)
        
        if col1 > 0:
            total -= self.query(row2, col1 - 1)
        
        if row1 > 0 and col1 > 0:
            total += self.query(row1 - 1, col1 - 1)
        
        return total


class RangeFenwickTree:
    """
    支持区间更新的树状数组
    使用差分数组的思想
    """
    def __init__(self, n):
        self.n = n
        self.tree1 = FenwickTree(n)  # 维护差分数组
        self.tree2 = FenwickTree(n)  # 维护i*diff[i]
    
    def range_update(self, left, right, val):
        """
        区间更新：[left, right]区间内的值都增加val
        时间复杂度：O(log n)
        """
        # 差分数组思想
        self.tree1.update(left, val)
        self.tree1.update(right + 1, -val)
        
        self.tree2.update(left, left * val)
        self.tree2.update(right + 1, -(right + 1) * val)
    
    def point_query(self, idx):
        """
        单点查询
        时间复杂度：O(log n)
        """
        return self.tree1.query(idx)
    
    def range_query(self, left, right):
        """
        区间查询
        时间复杂度：O(log n)
        """
        def prefix_sum(idx):
            # 计算[0, idx]的和
            return (idx + 1) * self.tree1.query(idx) - self.tree2.query(idx)
        
        if left == 0:
            return prefix_sum(right)
        
        return prefix_sum(right) - prefix_sum(left - 1)
```

### 11. 伸展树（Splay Tree）

```python
class SplayNode:
    """伸展树节点"""
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None
        self.parent = None

class SplayTree:
    """
    伸展树实现
    自调整二叉搜索树，最近访问的节点会被移到根部
    """
    def __init__(self):
        self.root = None
    
    def rotate_right(self, x):
        """右旋转"""
        y = x.left
        x.left = y.right
        
        if y.right:
            y.right.parent = x
        
        y.parent = x.parent
        
        if not x.parent:
            self.root = y
        elif x == x.parent.right:
            x.parent.right = y
        else:
            x.parent.left = y
        
        y.right = x
        x.parent = y
    
    def rotate_left(self, x):
        """左旋转"""
        y = x.right
        x.right = y.left
        
        if y.left:
            y.left.parent = x
        
        y.parent = x.parent
        
        if not x.parent:
            self.root = y
        elif x == x.parent.left:
            x.parent.left = y
        else:
            x.parent.right = y
        
        y.left = x
        x.parent = y
    
    def splay(self, x):
        """
        伸展操作：将节点x旋转到根部
        时间复杂度：O(log n) 摊还
        """
        while x.parent:
            if not x.parent.parent:
                # Zig：x的父节点是根
                if x == x.parent.left:
                    self.rotate_right(x.parent)
                else:
                    self.rotate_left(x.parent)
            elif x == x.parent.left and x.parent == x.parent.parent.left:
                # Zig-Zig：x和父节点都是左子节点
                self.rotate_right(x.parent.parent)
                self.rotate_right(x.parent)
            elif x == x.parent.right and x.parent == x.parent.parent.right:
                # Zig-Zig：x和父节点都是右子节点
                self.rotate_left(x.parent.parent)
                self.rotate_left(x.parent)
            elif x == x.parent.right and x.parent == x.parent.parent.left:
                # Zig-Zag：x是右子节点，父节点是左子节点
                self.rotate_left(x.parent)
                self.rotate_right(x.parent)
            else:
                # Zig-Zag：x是左子节点，父节点是右子节点
                self.rotate_right(x.parent)
                self.rotate_left(x.parent)
    
    def search(self, key):
        """
        查找节点
        时间复杂度：O(log n) 摊还
        """
        node = self._search_node(key)
        if node:
            self.splay(node)
            return True
        return False
    
    def _search_node(self, key):
        """查找节点（不进行伸展）"""
        current = self.root
        last = None
        
        while current:
            last = current
            if key < current.key:
                current = current.left
            elif key > current.key:
                current = current.right
            else:
                return current
        
        # 伸展最后访问的节点
        if last:
            self.splay(last)
        
        return None
    
    def insert(self, key):
        """
        插入节点
        时间复杂度：O(log n) 摊还
        """
        if not self.root:
            self.root = SplayNode(key)
            return
        
        # 标准BST插入
        current = self.root
        parent = None
        
        while current:
            parent = current
            if key < current.key:
                current = current.left
            elif key > current.key:
                current = current.right
            else:
                # 键已存在，伸展到根
                self.splay(current)
                return
        
        # 创建新节点
        new_node = SplayNode(key)
        new_node.parent = parent
        
        if key < parent.key:
            parent.left = new_node
        else:
            parent.right = new_node
        
        # 伸展新节点到根
        self.splay(new_node)
    
    def delete(self, key):
        """
        删除节点
        时间复杂度：O(log n) 摊还
        """
        node = self._search_node(key)
        if not node:
            return False
        
        # 伸展到根
        self.splay(node)
        
        # 分离左右子树
        left_tree = node.left
        right_tree = node.right
        
        if left_tree:
            left_tree.parent = None
        if right_tree:
            right_tree.parent = None
        
        if not left_tree:
            self.root = right_tree
        elif not right_tree:
            self.root = left_tree
        else:
            # 找到左子树的最大节点
            self.root = left_tree
            max_node = left_tree
            while max_node.right:
                max_node = max_node.right
            
            # 伸展最大节点到根
            self.splay(max_node)
            
            # 连接右子树
            self.root.right = right_tree
            right_tree.parent = self.root
        
        return True
    
    def split(self, key):
        """
        分裂操作：将树分成两部分
        返回两棵树，第一棵包含所有小于等于key的节点
        """
        if not self.root:
            return None, None
        
        # 查找key或最接近的节点
        self._search_node(key)
        
        if self.root.key <= key:
            # 分离右子树
            right = self.root.right
            if right:
                right.parent = None
            self.root.right = None
            return self.root, right
        else:
            # 分离左子树
            left = self.root.left
            if left:
                left.parent = None
            self.root.left = None
            return left, self.root
    
    def join(self, tree1, tree2):
        """
        合并操作：假设tree1的所有键小于tree2的所有键
        """
        if not tree1:
            return tree2
        if not tree2:
            return tree1
        
        # 找到tree1的最大节点
        max_node = tree1
        while max_node.right:
            max_node = max_node.right
        
        # 伸展到根
        self.root = tree1
        self.splay(max_node)
        
        # 连接tree2
        self.root.right = tree2
        if tree2:
            tree2.parent = self.root
        
        return self.root
    
    def find_min(self):
        """找到最小值"""
        if not self.root:
            return None
        
        current = self.root
        while current.left:
            current = current.left
        
        self.splay(current)
        return current.key
    
    def find_max(self):
        """找到最大值"""
        if not self.root:
            return None
        
        current = self.root
        while current.right:
            current = current.right
        
        self.splay(current)
        return current.key
```

## 第三部分：图结构

### 1. 图的表示与遍历

```python
class Graph:
    """
    图的基本实现
    支持邻接表和邻接矩阵两种表示方法
    """
    def __init__(self, vertices, directed=False):
        self.V = vertices  # 顶点数
        self.directed = directed  # 是否为有向图
        
        # 邻接表表示
        self.adj_list = [[] for _ in range(vertices)]
        
        # 邻接矩阵表示（可选）
        self.adj_matrix = [[0] * vertices for _ in range(vertices)]
        
        # 边的集合（用于某些算法）
        self.edges = []
    
    def add_edge(self, u, v, weight=1):
        """
        添加边
        时间复杂度：O(1)
        """
        # 邻接表
        self.adj_list[u].append((v, weight))
        if not self.directed:
            self.adj_list[v].append((u, weight))
        
        # 邻接矩阵
        self.adj_matrix[u][v] = weight
        if not self.directed:
            self.adj_matrix[v][u] = weight
        
        # 边集合
        self.edges.append((u, v, weight))
        if not self.directed and u != v:
            self.edges.append((v, u, weight))
    
    def dfs(self, start):
        """
        深度优先搜索（迭代版本）
        时间复杂度：O(V + E)
        空间复杂度：O(V)
        """
        visited = [False] * self.V
        stack = [start]
        result = []
        
        while stack:
            vertex = stack.pop()
            
            if not visited[vertex]:
                visited[vertex] = True
                result.append(vertex)
                
                # 添加邻接顶点到栈
                for neighbor, _ in self.adj_list[vertex]:
                    if not visited[neighbor]:
                        stack.append(neighbor)
        
        return result
    
    def dfs_recursive(self, start):
        """
        深度优先搜索（递归版本）
        """
        visited = [False] * self.V
        result = []
        
        def dfs_helper(v):
            visited[v] = True
            result.append(v)
            
            for neighbor, _ in self.adj_list[v]:
                if not visited[neighbor]:
                    dfs_helper(neighbor)
        
        dfs_helper(start)
        return result
    
    def bfs(self, start):
        """
        广度优先搜索
        时间复杂度：O(V + E)
        空间复杂度：O(V)
        """
        from collections import deque
        
        visited = [False] * self.V
        queue = deque([start])
        visited[start] = True
        result = []
        
        while queue:
            vertex = queue.popleft()
            result.append(vertex)
            
            for neighbor, _ in self.adj_list[vertex]:
                if not visited[neighbor]:
                    visited[neighbor] = True
                    queue.append(neighbor)
        
        return result
    
    def has_cycle_undirected(self):
        """
        检测无向图是否有环
        时间复杂度：O(V + E)
        """
        visited = [False] * self.V
        
        def dfs(v, parent):
            visited[v] = True
            
            for neighbor, _ in self.adj_list[v]:
                if not visited[neighbor]:
                    if dfs(neighbor, v):
                        return True
                elif neighbor != parent:
                    # 找到了一个已访问的非父节点
                    return True
            
            return False
        
        # 检查所有连通分量
        for i in range(self.V):
            if not visited[i]:
                if dfs(i, -1):
                    return True
        
        return False
    
    def has_cycle_directed(self):
        """
        检测有向图是否有环
        使用DFS和三色标记法
        时间复杂度：O(V + E)
        """
        # 0: 白色（未访问）
        # 1: 灰色（正在访问）
        # 2: 黑色（已完成）
        color = [0] * self.V
        
        def dfs(v):
            color[v] = 1  # 标记为灰色
            
            for neighbor, _ in self.adj_list[v]:
                if color[neighbor] == 1:
                    # 遇到灰色节点，存在环
                    return True
                if color[neighbor] == 0:
                    if dfs(neighbor):
                        return True
            
            color[v] = 2  # 标记为黑色
            return False
        
        for i in range(self.V):
            if color[i] == 0:
                if dfs(i):
                    return True
        
        return False
    
    def connected_components(self):
        """
        查找所有连通分量（无向图）
        时间复杂度：O(V + E)
        """
        visited = [False] * self.V
        components = []
        
        def dfs(v, component):
            visited[v] = True
            component.append(v)
            
            for neighbor, _ in self.adj_list[v]:
                if not visited[neighbor]:
                    dfs(neighbor, component)
        
        for i in range(self.V):
            if not visited[i]:
                component = []
                dfs(i, component)
                components.append(component)
        
        return components
    
    def is_bipartite(self):
        """
        判断是否为二分图
        使用染色法
        时间复杂度：O(V + E)
        """
        color = [-1] * self.V
        
        def bfs(start):
            from collections import deque
            
            queue = deque([start])
            color[start] = 0
            
            while queue:
                v = queue.popleft()
                
                for neighbor, _ in self.adj_list[v]:
                    if color[neighbor] == -1:
                        # 染成相反的颜色
                        color[neighbor] = 1 - color[v]
                        queue.append(neighbor)
                    elif color[neighbor] == color[v]:
                        # 相邻节点颜色相同，不是二分图
                        return False
            
            return True
        
        for i in range(self.V):
            if color[i] == -1:
                if not bfs(i):
                    return False
        
        return True
    
    def bridges(self):
        """
        找到所有桥（割边）
        时间复杂度：O(V + E)
        """
        visited = [False] * self.V
        disc = [0] * self.V  # 发现时间
        low = [0] * self.V   # 低链接值
        parent = [-1] * self.V
        bridges = []
        self.time = 0
        
        def dfs(u):
            visited[u] = True
            disc[u] = low[u] = self.time
            self.time += 1
            
            for v, _ in self.adj_list[u]:
                if not visited[v]:
                    parent[v] = u
                    dfs(v)
                    
                    low[u] = min(low[u], low[v])
                    
                    # 判断是否为桥
                    if low[v] > disc[u]:
                        bridges.append((u, v))
                
                elif v != parent[u]:
                    low[u] = min(low[u], disc[v])
        
        for i in range(self.V):
            if not visited[i]:
                dfs(i)
        
        return bridges
    
    def articulation_points(self):
        """
        找到所有割点
        时间复杂度：O(V + E)
        """
        visited = [False] * self.V
        disc = [0] * self.V
        low = [0] * self.V
        parent = [-1] * self.V
        ap = [False] * self.V  # 割点标记
        self.time = 0
        
        def dfs(u):
            children = 0
            visited[u] = True
            disc[u] = low[u] = self.time
            self.time += 1
            
            for v, _ in self.adj_list[u]:
                if not visited[v]:
                    children += 1
                    parent[v] = u
                    dfs(v)
                    
                    low[u] = min(low[u], low[v])
                    
                    # 判断u是否为割点
                    if parent[u] == -1 and children > 1:
                        # 根节点有多个子节点
                        ap[u] = True
                    
                    if parent[u] != -1 and low[v] >= disc[u]:
                        # 非根节点的割点条件
                        ap[u] = True
                
                elif v != parent[u]:
                    low[u] = min(low[u], disc[v])
        
        for i in range(self.V):
            if not visited[i]:
                dfs(i)
        
        return [i for i in range(self.V) if ap[i]]
```

### 2. 最短路径算法

#### Dijkstra算法

```python
import heapq

class DijkstraAlgorithm:
    """
    Dijkstra最短路径算法实现
    适用于非负权重的图
    """
    
    @staticmethod
    def dijkstra(graph, start):
        """
        标准Dijkstra算法
        时间复杂度：O((V + E) log V) 使用最小堆
        空间复杂度：O(V)
        
        返回：(distances, parents) 距离数组和父节点数组
        """
        V = graph.V
        distances = [float('inf')] * V
        distances[start] = 0
        parents = [-1] * V
        
        # 最小堆：(距离, 顶点)
        pq = [(0, start)]
        visited = [False] * V
        
        while pq:
            curr_dist, u = heapq.heappop(pq)
            
            # 如果已访问或发现更短路径，跳过
            if visited[u]:
                continue
            
            visited[u] = True
            
            # 松弛相邻边
            for v, weight in graph.adj_list[u]:
                if not visited[v] and curr_dist + weight < distances[v]:
                    distances[v] = curr_dist + weight
                    parents[v] = u
                    heapq.heappush(pq, (distances[v], v))
        
        return distances, parents
    
    @staticmethod
    def dijkstra_with_path(graph, start, end):
        """
        带路径重建的Dijkstra算法
        返回最短路径和距离
        """
        distances, parents = DijkstraAlgorithm.dijkstra(graph, start)
        
        if distances[end] == float('inf'):
            return None, float('inf')
        
        # 重建路径
        path = []
        current = end
        
        while current != -1:
            path.append(current)
            current = parents[current]
        
        path.reverse()
        return path, distances[end]
    
    @staticmethod
    def dijkstra_all_pairs(graph):
        """
        计算所有顶点对之间的最短路径
        时间复杂度：O(V * (V + E) log V)
        """
        V = graph.V
        all_distances = []
        all_parents = []
        
        for i in range(V):
            distances, parents = DijkstraAlgorithm.dijkstra(graph, i)
            all_distances.append(distances)
            all_parents.append(parents)
        
        return all_distances, all_parents


class BidirectionalDijkstra:
    """
    双向Dijkstra算法
    从起点和终点同时搜索，可以显著减少搜索空间
    """
    
    @staticmethod
    def bidirectional_dijkstra(graph, start, end):
        """
        双向搜索实现
        时间复杂度：O((V + E) log V) 但实际运行更快
        """
        V = graph.V
        
        # 前向搜索的数据结构
        dist_forward = [float('inf')] * V
        dist_forward[start] = 0
        parent_forward = [-1] * V
        pq_forward = [(0, start)]
        visited_forward = set()
        
        # 后向搜索的数据结构
        dist_backward = [float('inf')] * V
        dist_backward[end] = 0
        parent_backward = [-1] * V
        pq_backward = [(0, end)]
        visited_backward = set()
        
        # 最短路径长度
        shortest = float('inf')
        meeting_point = -1
        
        while pq_forward and pq_backward:
            # 前向搜索一步
            if pq_forward:
                curr_dist_f, u = heapq.heappop(pq_forward)
                
                if u in visited_forward:
                    continue
                
                visited_forward.add(u)
                
                # 检查是否相遇
                if u in visited_backward:
                    path_length = dist_forward[u] + dist_backward[u]
                    if path_length < shortest:
                        shortest = path_length
                        meeting_point = u
                
                # 松弛边
                for v, weight in graph.adj_list[u]:
                    if v not in visited_forward and curr_dist_f + weight < dist_forward[v]:
                        dist_forward[v] = curr_dist_f + weight
                        parent_forward[v] = u
                        heapq.heappush(pq_forward, (dist_forward[v], v))
            
            # 后向搜索一步
            if pq_backward:
                curr_dist_b, u = heapq.heappop(pq_backward)
                
                if u in visited_backward:
                    continue
                
                visited_backward.add(u)
                
                # 检查是否相遇
                if u in visited_forward:
                    path_length = dist_forward[u] + dist_backward[u]
                    if path_length < shortest:
                        shortest = path_length
                        meeting_point = u
                
                # 在无向图中后向松弛
                for v, weight in graph.adj_list[u]:
                    if v not in visited_backward and curr_dist_b + weight < dist_backward[v]:
                        dist_backward[v] = curr_dist_b + weight
                        parent_backward[v] = u
                        heapq.heappush(pq_backward, (dist_backward[v], v))
        
        # 重建路径
        if meeting_point == -1:
            return None, float('inf')
        
        # 前半部分路径
        path1 = []
        current = meeting_point
        while current != -1:
            path1.append(current)
            current = parent_forward[current]
        path1.reverse()
        
        # 后半部分路径
        path2 = []
        current = parent_backward[meeting_point]
        while current != -1:
            path2.append(current)
            current = parent_backward[current]
        
        return path1 + path2, shortest
```

#### Bellman-Ford算法

```python
class BellmanFord:
    """
    Bellman-Ford最短路径算法
    可以处理负权边，并检测负权环
    """
    
    @staticmethod
    def bellman_ford(graph, start):
        """
        标准Bellman-Ford算法
        时间复杂度：O(VE)
        空间复杂度：O(V)
        """
        V = graph.V
        distances = [float('inf')] * V
        distances[start] = 0
        parents = [-1] * V
        
        # 松弛所有边V-1次
        for _ in range(V - 1):
            updated = False
            
            for u, v, weight in graph.edges:
                if distances[u] != float('inf') and distances[u] + weight < distances[v]:
                    distances[v] = distances[u] + weight
                    parents[v] = u
                    updated = True
            
            # 如果没有更新，提前终止
            if not updated:
                break
        
        # 检测负权环
        for u, v, weight in graph.edges:
            if distances[u] != float('inf') and distances[u] + weight < distances[v]:
                return None, None  # 存在负权环
        
        return distances, parents
    
    @staticmethod
    def bellman_ford_optimized(graph, start):
        """
        优化的Bellman-Ford算法（SPFA）
        使用队列优化，平均时间复杂度：O(kE)，k通常很小
        """
        from collections import deque
        
        V = graph.V
        distances = [float('inf')] * V
        distances[start] = 0
        parents = [-1] * V
        
        # 记录顶点是否在队列中
        in_queue = [False] * V
        in_queue[start] = True
        
        # 记录每个顶点的入队次数（用于检测负环）
        count = [0] * V
        count[start] = 1
        
        queue = deque([start])
        
        while queue:
            u = queue.popleft()
            in_queue[u] = False
            
            # 松弛所有出边
            for v, weight in graph.adj_list[u]:
                if distances[u] + weight < distances[v]:
                    distances[v] = distances[u] + weight
                    parents[v] = u
                    
                    if not in_queue[v]:
                        queue.append(v)
                        in_queue[v] = True
                        count[v] += 1
                        
                        # 如果某个顶点入队超过V次，说明存在负环
                        if count[v] > V:
                            return None, None
        
        return distances, parents


class CurrencyArbitrage:
    """
    使用Bellman-Ford检测货币套利机会
    负权环对应套利机会
    """
    
    @staticmethod
    def find_arbitrage(exchange_rates):
        """
        exchange_rates[i][j] = 从货币i兑换到货币j的汇率
        返回是否存在套利机会和套利路径
        """
        import math
        
        n = len(exchange_rates)
        
        # 将汇率转换为对数形式（乘法变加法）
        # log(a*b*c) = log(a) + log(b) + log(c)
        # 使用负对数，这样找最短路径就是找最大乘积
        log_rates = [[0] * n for _ in range(n)]
        
        for i in range(n):
            for j in range(n):
                if exchange_rates[i][j] > 0:
                    log_rates[i][j] = -math.log(exchange_rates[i][j])
                else:
                    log_rates[i][j] = float('inf')
        
        # 对每种货币运行Bellman-Ford
        for start in range(n):
            distances = [float('inf')] * n
            distances[start] = 0
            parents = [-1] * n
            
            # 松弛n次（而不是n-1次）来检测负环
            for iteration in range(n):
                updated = False
                
                for i in range(n):
                    if distances[i] == float('inf'):
                        continue
                    
                    for j in range(n):
                        if log_rates[i][j] != float('inf'):
                            if distances[i] + log_rates[i][j] < distances[j]:
                                distances[j] = distances[i] + log_rates[i][j]
                                parents[j] = i
                                updated = True
                                
                                # 在第n次迭代时检测到更新，说明有负环
                                if iteration == n - 1:
                                    # 找到负环中的一个顶点
                                    cycle_vertex = j
                                    
                                    # 回溯n步确保在环内
                                    for _ in range(n):
                                        cycle_vertex = parents[cycle_vertex]
                                    
                                    # 重建环
                                    cycle = []
                                    current = cycle_vertex
                                    
                                    while True:
                                        cycle.append(current)
                                        current = parents[current]
                                        if current == cycle_vertex:
                                            cycle.append(current)
                                            break
                                    
                                    return True, cycle
                
                if not updated:
                    break
        
        return False, None
```

#### Floyd-Warshall算法

```python
class FloydWarshall:
    """
    Floyd-Warshall全源最短路径算法
    计算所有顶点对之间的最短路径
    """
    
    @staticmethod
    def floyd_warshall(graph):
        """
        标准Floyd-Warshall算法
        时间复杂度：O(V³)
        空间复杂度：O(V²)
        """
        V = graph.V
        
        # 初始化距离矩阵
        dist = [[float('inf')] * V for _ in range(V)]
        next_vertex = [[None] * V for _ in range(V)]
        
        # 对角线初始化为0
        for i in range(V):
            dist[i][i] = 0
        
        # 从邻接表初始化
        for u in range(V):
            for v, weight in graph.adj_list[u]:
                dist[u][v] = weight
                next_vertex[u][v] = v
        
        # 动态规划
        for k in range(V):
            for i in range(V):
                for j in range(V):
                    # 尝试通过k中转
                    if dist[i][k] + dist[k][j] < dist[i][j]:
                        dist[i][j] = dist[i][k] + dist[k][j]
                        next_vertex[i][j] = next_vertex[i][k]
        
        # 检测负权环
        for i in range(V):
            if dist[i][i] < 0:
                return None, None  # 存在负权环
        
        return dist, next_vertex
    
    @staticmethod
    def reconstruct_path(next_vertex, start, end):
        """
        根据next数组重建路径
        """
        if next_vertex[start][end] is None:
            return None
        
        path = [start]
        while start != end:
            start = next_vertex[start][end]
            path.append(start)
        
        return path
    
    @staticmethod
    def transitive_closure(graph):
        """
        计算传递闭包（可达性矩阵）
        时间复杂度：O(V³)
        """
        V = graph.V
        reach = [[False] * V for _ in range(V)]
        
        # 初始化
        for i in range(V):
            reach[i][i] = True
        
        for u in range(V):
            for v, _ in graph.adj_list[u]:
                reach[u][v] = True
        
        # Floyd-Warshall变体
        for k in range(V):
            for i in range(V):
                for j in range(V):
                    reach[i][j] = reach[i][j] or (reach[i][k] and reach[k][j])
        
        return reach
```

#### A*算法

```python
class AStarAlgorithm:
    """
    A*搜索算法
    使用启发式函数的最短路径算法
    """
    
    @staticmethod
    def a_star(graph, start, goal, heuristic):
        """
        A*算法实现
        heuristic: 启发式函数，估计从节点到目标的距离
        时间复杂度：O(b^d) 其中b是分支因子，d是深度
        """
        import heapq
        
        V = graph.V
        
        # g(n): 从起点到n的实际代价
        g_score = [float('inf')] * V
        g_score[start] = 0
        
        # f(n) = g(n) + h(n)
        f_score = [float('inf')] * V
        f_score[start] = heuristic(start, goal)
        
        # 优先队列：(f_score, 计数器, 节点)
        counter = 0
        open_set = [(f_score[start], counter, start)]
        
        # 记录路径
        came_from = {}
        
        # 已处理的节点
        closed_set = set()
        
        while open_set:
            _, _, current = heapq.heappop(open_set)
            
            if current in closed_set:
                continue
            
            if current == goal:
                # 重建路径
                path = []
                while current in came_from:
                    path.append(current)
                    current = came_from[current]
                path.append(start)
                path.reverse()
                return path, g_score[goal]
            
            closed_set.add(current)
            
            # 检查所有邻居
            for neighbor, weight in graph.adj_list[current]:
                if neighbor in closed_set:
                    continue
                
                tentative_g = g_score[current] + weight
                
                if tentative_g < g_score[neighbor]:
                    # 发现更好的路径
                    came_from[neighbor] = current
                    g_score[neighbor] = tentative_g
                    f_score[neighbor] = tentative_g + heuristic(neighbor, goal)
                    
                    counter += 1
                    heapq.heappush(open_set, (f_score[neighbor], counter, neighbor))
        
        return None, float('inf')


class GridPathfinding:
    """
    网格地图上的路径搜索
    """
    
    def __init__(self, grid):
        """
        grid[i][j] = 0: 可通行
        grid[i][j] = 1: 障碍物
        """
        self.grid = grid
        self.rows = len(grid)
        self.cols = len(grid[0]) if grid else 0
    
    def manhattan_distance(self, p1, p2):
        """曼哈顿距离启发式"""
        return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])
    
    def euclidean_distance(self, p1, p2):
        """欧几里得距离启发式"""
        return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2) ** 0.5
    
    def get_neighbors(self, pos):
        """获取相邻的可通行格子"""
        row, col = pos
        neighbors = []
        
        # 四个方向
        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]
        
        # 如果需要八个方向，添加对角线
        # directions += [(1, 1), (1, -1), (-1, 1), (-1, -1)]
        
        for dr, dc in directions:
            new_row, new_col = row + dr, col + dc
            
            if (0 <= new_row < self.rows and 
                0 <= new_col < self.cols and 
                self.grid[new_row][new_col] == 0):
                
                # 对角线移动的代价是√2
                cost = 1.414 if abs(dr) + abs(dc) == 2 else 1
                neighbors.append(((new_row, new_col), cost))
        
        return neighbors
    
    def a_star_grid(self, start, goal):
        """
        在网格上运行A*算法
        """
        import heapq
        
        # 使用曼哈顿距离作为启发式
        h = lambda pos: self.manhattan_distance(pos, goal)
        
        g_score = {}
        g_score[start] = 0
        
        f_score = {}
        f_score[start] = h(start)
        
        open_set = [(f_score[start], 0, start)]
        counter = 0
        
        came_from = {}
        closed_set = set()
        
        while open_set:
            _, _, current = heapq.heappop(open_set)
            
            if current in closed_set:
                continue
            
            if current == goal:
                # 重建路径
                path = []
                while current in came_from:
                    path.append(current)
                    current = came_from[current]
                path.append(start)
                path.reverse()
                return path
            
            closed_set.add(current)
            
            for neighbor, cost in self.get_neighbors(current):
                if neighbor in closed_set:
                    continue
                
                tentative_g = g_score[current] + cost
                
                if neighbor not in g_score or tentative_g < g_score[neighbor]:
                    came_from[neighbor] = current
                    g_score[neighbor] = tentative_g
                    f_score[neighbor] = tentative_g + h(neighbor)
                    
                    counter += 1
                    heapq.heappush(open_set, (f_score[neighbor], counter, neighbor))
        
        return None  # 无路径
    
    def jump_point_search(self, start, goal):
        """
        跳点搜索算法（JPS）
        A*的优化版本，减少搜索的节点数
        """
        # JPS实现较复杂，这里提供简化版本
        # 主要思想是"跳过"不必要的节点
        pass
```

### 3. 最小生成树

```python
class UnionFind:
    """
    并查集实现（用于Kruskal算法）
    """
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n
        self.count = n  # 连通分量数
    
    def find(self, x):
        """
        查找根节点（带路径压缩）
        时间复杂度：O(α(n))，α是反阿克曼函数
        """
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]
    
    def union(self, x, y):
        """
        合并两个集合（按秩合并）
        """
        root_x = self.find(x)
        root_y = self.find(y)
        
        if root_x == root_y:
            return False
        
        # 按秩合并
        if self.rank[root_x] < self.rank[root_y]:
            self.parent[root_x] = root_y
        elif self.rank[root_x] > self.rank[root_y]:
            self.parent[root_y] = root_x
        else:
            self.parent[root_y] = root_x
            self.rank[root_x] += 1
        
        self.count -= 1
        return True
    
    def connected(self, x, y):
        """判断是否连通"""
        return self.find(x) == self.find(y)


class KruskalMST:
    """
    Kruskal最小生成树算法
    基于贪心策略和并查集
    """
    
    @staticmethod
    def kruskal(graph):
        """
        标准Kruskal算法
        时间复杂度：O(E log E)
        空间复杂度：O(V)
        """
        V = graph.V
        edges = graph.edges.copy()
        
        # 按权重排序
        edges.sort(key=lambda x: x[2])
        
        uf = UnionFind(V)
        mst = []
        total_weight = 0
        
        for u, v, weight in edges:
            if uf.union(u, v):
                mst.append((u, v, weight))
                total_weight += weight
                
                # 已经有V-1条边，形成了生成树
                if len(mst) == V - 1:
                    break
        
        # 检查是否连通
        if uf.count != 1:
            return None, None  # 图不连通
        
        return mst, total_weight
    
    @staticmethod
    def kruskal_with_filter(graph, must_include=None, must_exclude=None):
        """
        带约束的Kruskal算法
        must_include: 必须包含的边
        must_exclude: 必须排除的边
        """
        V = graph.V
        edges = []
        
        # 过滤边
        for u, v, weight in graph.edges:
            edge = (u, v, weight)
            
            if must_exclude and edge in must_exclude:
                continue
            
            edges.append(edge)
        
        # 先加入必须包含的边
        uf = UnionFind(V)
        mst = []
        total_weight = 0
        
        if must_include:
            for u, v, weight in must_include:
                if uf.union(u, v):
                    mst.append((u, v, weight))
                    total_weight += weight
        
        # 按权重排序剩余的边
        edges.sort(key=lambda x: x[2])
        
        # 添加剩余的边
        for u, v, weight in edges:
            if (must_include and (u, v, weight) in must_include):
                continue
            
            if uf.union(u, v):
                mst.append((u, v, weight))
                total_weight += weight
                
                if len(mst) == V - 1:
                    break
        
        if uf.count != 1:
            return None, None
        
        return mst, total_weight


class PrimMST:
    """
    Prim最小生成树算法
    基于贪心策略和优先队列
    """
    
    @staticmethod
    def prim(graph, start=0):
        """
        标准Prim算法
        时间复杂度：O((V + E) log V) 使用最小堆
        空间复杂度：O(V)
        """
        import heapq
        
        V = graph.V
        mst = []
        total_weight = 0
        
        # 记录顶点是否在MST中
        in_mst = [False] * V
        
        # 最小堆：(权重, 当前顶点, 父顶点)
        min_heap = [(0, start, -1)]
        
        while min_heap and len(mst) < V - 1:
            weight, u, parent = heapq.heappop(min_heap)
            
            if in_mst[u]:
                continue
            
            in_mst[u] = True
            
            # 添加边到MST（除了起始顶点）
            if parent != -1:
                mst.append((parent, u, weight))
                total_weight += weight
            
            # 添加所有相邻的边
            for v, w in graph.adj_list[u]:
                if not in_mst[v]:
                    heapq.heappush(min_heap, (w, v, u))
        
        # 检查是否所有顶点都被访问
        if sum(in_mst) != V:
            return None, None  # 图不连通
        
        return mst, total_weight
    
    @staticmethod
    def prim_dense(graph):
        """
        稠密图的Prim算法（使用数组而不是堆）
        时间复杂度：O(V²)
        更适合稠密图
        """
        V = graph.V
        mst = []
        total_weight = 0
        
        # key[i] = 连接i到MST的最小边权重
        key = [float('inf')] * V
        key[0] = 0
        
        # parent[i] = MST中i的父节点
        parent = [-1] * V
        
        # 记录顶点是否在MST中
        in_mst = [False] * V
        
        for _ in range(V):
            # 找到key最小的顶点
            u = -1
            for v in range(V):
                if not in_mst[v] and (u == -1 or key[v] < key[u]):
                    u = v
            
            in_mst[u] = True
            
            # 添加边到MST
            if parent[u] != -1:
                mst.append((parent[u], u, key[u]))
                total_weight += key[u]
            
            # 更新相邻顶点的key值
            for v, weight in graph.adj_list[u]:
                if not in_mst[v] and weight < key[v]:
                    key[v] = weight
                    parent[v] = u
        
        return mst, total_weight


class BoruvkaMST:
    """
    Boruvka最小生成树算法
    并行友好的MST算法
    """
    
    @staticmethod
    def boruvka(graph):
        """
        Boruvka算法实现
        时间复杂度：O(E log V)
        """
        V = graph.V
        uf = UnionFind(V)
        mst = []
        total_weight = 0
        
        # 继续直到只有一个连通分量
        while uf.count > 1:
            # cheapest[i] = 从分量i出去的最小边
            cheapest = [None] * V
            
            # 找到每个分量的最小出边
            for u, v, weight in graph.edges:
                root_u = uf.find(u)
                root_v = uf.find(v)
                
                if root_u != root_v:
                    # 更新分量root_u的最小边
                    if cheapest[root_u] is None or weight < cheapest[root_u][2]:
                        cheapest[root_u] = (u, v, weight)
                    
                    # 更新分量root_v的最小边
                    if cheapest[root_v] is None or weight < cheapest[root_v][2]:
                        cheapest[root_v] = (v, u, weight)
            
            # 添加每个分量的最小边
            for i in range(V):
                if cheapest[i] is not None:
                    u, v, weight = cheapest[i]
                    if uf.union(u, v):
                        mst.append((u, v, weight))
                        total_weight += weight
        
        return mst, total_weight


class SecondMST:
    """
    次小生成树算法
    """
    
    @staticmethod
    def second_best_mst(graph):
        """
        找到次小生成树
        时间复杂度：O(V² + E log E)
        """
        # 首先找到最小生成树
        mst_edges, mst_weight = KruskalMST.kruskal(graph)
        if mst_edges is None:
            return None, None
        
        V = graph.V
        second_best_weight = float('inf')
        second_best_mst = None
        
        # 对MST中的每条边
        for exclude_edge in mst_edges:
            # 尝试找到不包含这条边的MST
            must_exclude = [exclude_edge]
            new_mst, new_weight = KruskalMST.kruskal_with_filter(
                graph, must_exclude=must_exclude
            )
            
            if new_mst and new_weight < second_best_weight:
                second_best_weight = new_weight
                second_best_mst = new_mst
        
        return second_best_mst, second_best_weight
```

### 4. 拓扑排序

```python
class TopologicalSort:
    """
    拓扑排序算法实现
    用于有向无环图（DAG）
    """
    
    @staticmethod
    def kahn_algorithm(graph):
        """
        Kahn算法（基于BFS）
        时间复杂度：O(V + E)
        空间复杂度：O(V)
        """
        from collections import deque
        
        V = graph.V
        
        # 计算入度
        in_degree = [0] * V
        for u in range(V):
            for v, _ in graph.adj_list[u]:
                in_degree[v] += 1
        
        # 将所有入度为0的顶点加入队列
        queue = deque()
        for i in range(V):
            if in_degree[i] == 0:
                queue.append(i)
        
        topo_order = []
        
        while queue:
            u = queue.popleft()
            topo_order.append(u)
            
            # 删除u的所有出边
            for v, _ in graph.adj_list[u]:
                in_degree[v] -= 1
                if in_degree[v] == 0:
                    queue.append(v)
        
        # 检查是否有环
        if len(topo_order) != V:
            return None  # 图中有环
        
        return topo_order
    
    @staticmethod
    def dfs_topological_sort(graph):
        """
        基于DFS的拓扑排序
        时间复杂度：O(V + E)
        """
        V = graph.V
        visited = [False] * V
        stack = []
        
        def dfs(v):
            visited[v] = True
            
            for neighbor, _ in graph.adj_list[v]:
                if not visited[neighbor]:
                    dfs(neighbor)
            
            # 在回溯时将顶点加入栈
            stack.append(v)
        
        # 对所有未访问的顶点进行DFS
        for i in range(V):
            if not visited[i]:
                dfs(i)
        
        # 栈的逆序就是拓扑排序
        return stack[::-1]
    
    @staticmethod
    def all_topological_sorts(graph):
        """
        生成所有可能的拓扑排序
        使用回溯算法
        """
        V = graph.V
        
        # 计算入度
        in_degree = [0] * V
        for u in range(V):
            for v, _ in graph.adj_list[u]:
                in_degree[v] += 1
        
        all_sorts = []
        current_sort = []
        visited = [False] * V
        
        def backtrack():
            # 找到所有入度为0且未访问的顶点
            for v in range(V):
                if in_degree[v] == 0 and not visited[v]:
                    # 选择这个顶点
                    visited[v] = True
                    current_sort.append(v)
                    
                    # 减少相邻顶点的入度
                    for neighbor, _ in graph.adj_list[v]:
                        in_degree[neighbor] -= 1
                    
                    # 递归
                    backtrack()
                    
                    # 回溯
                    visited[v] = False
                    current_sort.pop()
                    
                    # 恢复相邻顶点的入度
                    for neighbor, _ in graph.adj_list[v]:
                        in_degree[neighbor] += 1
            
            # 如果所有顶点都已访问，找到一个拓扑排序
            if len(current_sort) == V:
                all_sorts.append(current_sort[:])
        
        backtrack()
        return all_sorts


class CourseSchedule:
    """
    课程安排问题（拓扑排序的应用）
    """
    
    def __init__(self, num_courses, prerequisites):
        """
        num_courses: 课程数量
        prerequisites: 先修课程列表，prerequisites[i] = [a, b] 表示要学a必须先学b
        """
        self.num_courses = num_courses
        self.graph = Graph(num_courses, directed=True)
        
        for course, prereq in prerequisites:
            self.graph.add_edge(prereq, course)
    
    def can_finish(self):
        """
        判断是否可以完成所有课程
        """
        order = TopologicalSort.kahn_algorithm(self.graph)
        return order is not None
    
    def find_order(self):
        """
        找到一个可行的学习顺序
        """
        return TopologicalSort.kahn_algorithm(self.graph)
    
    def minimum_semesters(self):
        """
        计算完成所有课程需要的最少学期数
        每学期可以学习任意数量的课程，但必须满足先修要求
        """
        from collections import deque
        
        # 计算入度
        in_degree = [0] * self.num_courses
        for u in range(self.num_courses):
            for v, _ in self.graph.adj_list[u]:
                in_degree[v] += 1
        
        # BFS分层
        queue = deque()
        for i in range(self.num_courses):
            if in_degree[i] == 0:
                queue.append(i)
        
        semesters = 0
        studied = 0
        
        while queue:
            # 当前学期可以学习的课程数
            semester_size = len(queue)
            semesters += 1
            
            for _ in range(semester_size):
                course = queue.popleft()
                studied += 1
                
                # 更新后续课程的入度
                for next_course, _ in self.graph.adj_list[course]:
                    in_degree[next_course] -= 1
                    if in_degree[next_course] == 0:
                        queue.append(next_course)
        
        return semesters if studied == self.num_courses else -1


class CriticalPath:
    """
    关键路径算法（AOE网）
    """
    
    def __init__(self, graph):
        self.graph = graph
        self.V = graph.V
    
    def find_critical_path(self):
        """
        找到关键路径
        返回：(最早开始时间, 最晚开始时间, 关键路径)
        """
        # 拓扑排序
        topo_order = TopologicalSort.kahn_algorithm(self.graph)
        if topo_order is None:
            return None, None, None
        
        # 计算最早开始时间（正向）
        earliest = [0] * self.V
        for u in topo_order:
            for v, weight in self.graph.adj_list[u]:
                earliest[v] = max(earliest[v], earliest[u] + weight)
        
        # 计算最晚开始时间（反向）
        latest = [earliest[-1]] * self.V
        for u in reversed(topo_order):
            for v, weight in self.graph.adj_list[u]:
                latest[u] = min(latest[u], latest[v] - weight)
        
        # 找到关键路径
        critical_path = []
        for u in range(self.V):
            for v, weight in self.graph.adj_list[u]:
                # 如果最早开始时间等于最晚开始时间，则在关键路径上
                if earliest[u] == latest[u] and earliest[v] == latest[v]:
                    if earliest[u] + weight == earliest[v]:
                        critical_path.append((u, v, weight))
        
        return earliest, latest, critical_path
```

### 5. 强连通分量

```python
class StronglyConnectedComponents:
    """
    强连通分量算法
    """
    
    @staticmethod
    def tarjan_scc(graph):
        """
        Tarjan算法求强连通分量
        时间复杂度：O(V + E)
        """
        V = graph.V
        
        # 初始化
        index_counter = [0]
        stack = []
        lowlinks = [0] * V
        index = [0] * V
        on_stack = [False] * V
        undefined = -1
        
        for v in range(V):
            index[v] = undefined
        
        sccs = []
        
        def strongconnect(v):
            # 设置深度索引
            index[v] = index_counter[0]
            lowlinks[v] = index_counter[0]
            index_counter[0] += 1
            stack.append(v)
            on_stack[v] = True
            
            # 考虑v的后继
            for w, _ in graph.adj_list[v]:
                if index[w] == undefined:
                    # 后继w未被访问，递归
                    strongconnect(w)
                    lowlinks[v] = min(lowlinks[v], lowlinks[w])
                elif on_stack[w]:
                    # 后继w在栈中，更新lowlink
                    lowlinks[v] = min(lowlinks[v], index[w])
            
            # 如果v是根节点，弹出栈中的强连通分量
            if lowlinks[v] == index[v]:
                scc = []
                while True:
                    w = stack.pop()
                    on_stack[w] = False
                    scc.append(w)
                    if w == v:
                        break
                sccs.append(scc)
        
        # 对所有顶点运行算法
        for v in range(V):
            if index[v] == undefined:
                strongconnect(v)
        
        return sccs
    
    @staticmethod
    def kosaraju_scc(graph):
        """
        Kosaraju算法求强连通分量
        时间复杂度：O(V + E)
        """
        V = graph.V
        
        # 第一次DFS，记录完成时间
        visited = [False] * V
        finish_stack = []
        
        def dfs1(v):
            visited[v] = True
            for neighbor, _ in graph.adj_list[v]:
                if not visited[neighbor]:
                    dfs1(neighbor)
            finish_stack.append(v)
        
        for v in range(V):
            if not visited[v]:
                dfs1(v)
        
        # 构建反向图
        reverse_graph = Graph(V, directed=True)
        for u in range(V):
            for v, weight in graph.adj_list[u]:
                reverse_graph.add_edge(v, u, weight)
        
        # 第二次DFS，在反向图上按完成时间逆序遍历
        visited = [False] * V
        sccs = []
        
        def dfs2(v, scc):
            visited[v] = True
            scc.append(v)
            for neighbor, _ in reverse_graph.adj_list[v]:
                if not visited[neighbor]:
                    dfs2(neighbor, scc)
        
        while finish_stack:
            v = finish_stack.pop()
            if not visited[v]:
                scc = []
                dfs2(v, scc)
                sccs.append(scc)
        
        return sccs
    
    @staticmethod
    def condensation_graph(graph, sccs):
        """
        构建凝聚图（将每个SCC缩成一个点）
        """
        V = graph.V
        
        # 为每个顶点分配SCC编号
        scc_id = [-1] * V
        for i, scc in enumerate(sccs):
            for v in scc:
                scc_id[v] = i
        
        # 构建凝聚图
        num_sccs = len(sccs)
        condensed = Graph(num_sccs, directed=True)
        
        # 添加SCC之间的边
        added_edges = set()
        for u in range(V):
            for v, weight in graph.adj_list[u]:
                scc_u, scc_v = scc_id[u], scc_id[v]
                
                if scc_u != scc_v and (scc_u, scc_v) not in added_edges:
                    condensed.add_edge(scc_u, scc_v)
                    added_edges.add((scc_u, scc_v))
        
        return condensed


class TwoSAT:
    """
    2-SAT问题求解
    """
    
    def __init__(self, n):
        """n: 变量数量"""
        self.n = n
        # 每个变量有两个节点：x和¬x
        self.graph = Graph(2 * n, directed=True)
    
    def add_clause(self, x, is_x, y, is_y):
        """
        添加子句 (x ∨ y)
        is_x: True表示x，False表示¬x
        is_y: True表示y，False表示¬y
        """
        # (x ∨ y) 等价于 (¬x → y) ∧ (¬y → x)
        u = 2 * x + (0 if is_x else 1)
        v = 2 * y + (1 if is_y else 0)
        self.graph.add_edge(v, u)  # ¬y → x
        
        u = 2 * y + (0 if is_y else 1)
        v = 2 * x + (1 if is_x else 0)
        self.graph.add_edge(v, u)  # ¬x → y
    
    def solve(self):
        """
        求解2-SAT问题
        返回：(是否有解, 解)
        """
        # 找到强连通分量
        sccs = StronglyConnectedComponents.tarjan_scc(self.graph)
        
        # 为每个顶点分配SCC编号
        scc_id = [-1] * (2 * self.n)
        for i, scc in enumerate(sccs):
            for v in scc:
                scc_id[v] = i
        
        # 检查是否有解
        assignment = [False] * self.n
        
        for i in range(self.n):
            # x和¬x在同一个SCC中，无解
            if scc_id[2 * i] == scc_id[2 * i + 1]:
                return False, None
            
            # 根据拓扑序分配值
            # 如果¬x的SCC编号 < x的SCC编号，则x = True
            assignment[i] = scc_id[2 * i + 1] < scc_id[2 * i]
        
        return True, assignment
```

### 6. 二分图匹配

```python
class BipartiteMatching:
    """
    二分图匹配算法
    """
    
    def __init__(self, left_size, right_size):
        self.left_size = left_size
        self.right_size = right_size
        self.graph = [[] for _ in range(left_size)]
    
    def add_edge(self, u, v):
        """添加从左侧u到右侧v的边"""
        self.graph[u].append(v)
    
    def hungarian_algorithm(self):
        """
        匈牙利算法求最大匹配
        时间复杂度：O(VE)
        """
        # match[v] = u 表示右侧v匹配左侧u
        match = [-1] * self.right_size
        
        def dfs(u, visited):
            """为左侧顶点u寻找增广路径"""
            for v in self.graph[u]:
                if visited[v]:
                    continue
                
                visited[v] = True
                
                # v未匹配，或者v的匹配可以找到其他增广路径
                if match[v] == -1 or dfs(match[v], visited):
                    match[v] = u
                    return True
            
            return False
        
        matching = 0
        for u in range(self.left_size):
            visited = [False] * self.right_size
            if dfs(u, visited):
                matching += 1
        
        return matching, match
    
    def hopcroft_karp(self):
        """
        Hopcroft-Karp算法求最大匹配
        时间复杂度：O(E√V)
        """
        from collections import deque
        
        # pair_u[u] = v 表示左侧u匹配右侧v
        pair_u = [-1] * self.left_size
        # pair_v[v] = u 表示右侧v匹配左侧u
        pair_v = [-1] * self.right_size
        
        def bfs():
            """BFS寻找增广路径"""
            queue = deque()
            dist = [-1] * self.left_size
            
            # 将所有未匹配的左侧顶点加入队列
            for u in range(self.left_size):
                if pair_u[u] == -1:
                    dist[u] = 0
                    queue.append(u)
            
            found = False
            
            while queue:
                u = queue.popleft()
                
                for v in self.graph[u]:
                    if pair_v[v] == -1:
                        # 找到增广路径
                        found = True
                    else:
                        # 继续搜索
                        next_u = pair_v[v]
                        if dist[next_u] == -1:
                            dist[next_u] = dist[u] + 1
                            queue.append(next_u)
            
            return found
        
        def dfs(u, dist):
            """DFS构建增广路径"""
            if u == -1:
                return True
            
            for v in self.graph[u]:
                if pair_v[v] == -1 or (dist[pair_v[v]] == dist[u] + 1 and 
                                       dfs(pair_v[v], dist)):
                    pair_v[v] = u
                    pair_u[u] = v
                    return True
            
            # 标记为已访问
            dist[u] = -1
            return False
        
        matching = 0
        
        while bfs():
            dist = [-1] * self.left_size
            
            for u in range(self.left_size):
                if pair_u[u] == -1 and dfs(u, dist):
                    matching += 1
        
        return matching, (pair_u, pair_v)


class WeightedBipartiteMatching:
    """
    带权二分图匹配（KM算法）
    """
    
    def __init__(self, n):
        """n: 左右两侧顶点数（假设相等）"""
        self.n = n
        self.weight = [[0] * n for _ in range(n)]
    
    def set_weight(self, u, v, w):
        """设置边(u,v)的权重"""
        self.weight[u][v] = w
    
    def kuhn_munkres(self):
        """
        KM算法求最大权完美匹配
        时间复杂度：O(n³)
        """
        n = self.n
        INF = float('inf')
        
        # 顶标
        lx = [max(self.weight[i]) for i in range(n)]
        ly = [0] * n
        
        # 匹配
        match_x = [-1] * n
        match_y = [-1] * n
        
        # 辅助数组
        visx = [False] * n
        visy = [False] * n
        slack = [0] * n
        
        def dfs(x):
            visx[x] = True
            
            for y in range(n):
                if visy[y]:
                    continue
                
                gap = lx[x] + ly[y] - self.weight[x][y]
                
                if gap == 0:
                    # 在相等子图中
                    visy[y] = True
                    
                    if match_y[y] == -1 or dfs(match_y[y]):
                        match_x[x] = y
                        match_y[y] = x
                        return True
                else:
                    slack[y] = min(slack[y], gap)
            
            return False
        
        # 为每个x寻找匹配
        for x in range(n):
            # 初始化
            for i in range(n):
                slack[i] = INF
            
            while True:
                # 清空访问标记
                visx = [False] * n
                visy = [False] * n
                
                if dfs(x):
                    break
                
                # 更新顶标
                delta = INF
                for y in range(n):
                    if not visy[y]:
                        delta = min(delta, slack[y])
                
                for i in range(n):
                    if visx[i]:
                        lx[i] -= delta
                    if visy[i]:
                        ly[i] += delta
                    else:
                        slack[i] -= delta
        
        # 计算总权重
        total_weight = sum(self.weight[i][match_x[i]] for i in range(n))
        
        return match_x, total_weight


class MaximumBipartiteEdgeCover:
    """
    二分图最小边覆盖
    """
    
    @staticmethod
    def minimum_edge_cover(left_size, right_size, edges):
        """
        求最小边覆盖
        最小边覆盖 = V - 最大匹配
        """
        # 创建二分图
        bm = BipartiteMatching(left_size, right_size)
        for u, v in edges:
            bm.add_edge(u, v)
        
        # 求最大匹配
        max_matching, _ = bm.hungarian_algorithm()
        
        # 最小边覆盖
        min_cover = (left_size + right_size) - max_matching
        
        return min_cover
```

### 7. 网络流

```python
class MaxFlow:
    """
    最大流算法实现
    """
    
    def __init__(self, n):
        self.n = n
        self.graph = [[0] * n for _ in range(n)]
    
    def add_edge(self, u, v, capacity):
        """添加容量为capacity的边"""
        self.graph[u][v] += capacity
    
    def ford_fulkerson(self, source, sink):
        """
        Ford-Fulkerson算法（使用DFS）
        时间复杂度：O(E * max_flow)
        """
        # 创建残留网络
        residual = [row[:] for row in self.graph]
        parent = [-1] * self.n
        max_flow = 0
        
        def dfs(s, t, parent):
            """DFS寻找增广路径"""
            visited = [False] * self.n
            stack = [s]
            visited[s] = True
            
            while stack:
                u = stack.pop()
                
                for v in range(self.n):
                    if not visited[v] and residual[u][v] > 0:
                        visited[v] = True
                        parent[v] = u
                        
                        if v == t:
                            return True
                        
                        stack.append(v)
            
            return False
        
        # 当存在增广路径时
        while dfs(source, sink, parent):
            # 找到路径上的最小残留容量
            path_flow = float('inf')
            v = sink
            
            while v != source:
                u = parent[v]
                path_flow = min(path_flow, residual[u][v])
                v = u
            
            # 更新残留网络
            v = sink
            while v != source:
                u = parent[v]
                residual[u][v] -= path_flow
                residual[v][u] += path_flow
                v = u
            
            max_flow += path_flow
        
        return max_flow
    
    def edmonds_karp(self, source, sink):
        """
        Edmonds-Karp算法（使用BFS）
        时间复杂度：O(VE²)
        """
        from collections import deque
        
        residual = [row[:] for row in self.graph]
        parent = [-1] * self.n
        max_flow = 0
        
        def bfs(s, t, parent):
            """BFS寻找最短增广路径"""
            visited = [False] * self.n
            queue = deque([s])
            visited[s] = True
            
            while queue:
                u = queue.popleft()
                
                for v in range(self.n):
                    if not visited[v] and residual[u][v] > 0:
                        visited[v] = True
                        parent[v] = u
                        
                        if v == t:
                            return True
                        
                        queue.append(v)
            
            return False
        
        while bfs(source, sink, parent):
            # 找到路径上的最小残留容量
            path_flow = float('inf')
            v = sink
            
            while v != source:
                u = parent[v]
                path_flow = min(path_flow, residual[u][v])
                v = u
            
            # 更新残留网络
            v = sink
            while v != source:
                u = parent[v]
                residual[u][v] -= path_flow
                residual[v][u] += path_flow
                v = u
            
            max_flow += path_flow
        
        return max_flow
    
    def dinic(self, source, sink):
        """
        Dinic算法
        时间复杂度：O(V²E)
        """
        from collections import deque
        
        def bfs(source, sink, level):
            """构建层次图"""
            for i in range(self.n):
                level[i] = -1
            
            level[source] = 0
            queue = deque([source])
            
            while queue:
                u = queue.popleft()
                
                for v in range(self.n):
                    if level[v] < 0 and self.graph[u][v] > 0:
                        level[v] = level[u] + 1
                        queue.append(v)
            
            return level[sink] >= 0
        
        def dfs(u, sink, flow, level, start):
            """在层次图中DFS寻找增广路径"""
            if u == sink:
                return flow
            
            while start[u] < self.n:
                v = start[u]
                
                if (level[v] == level[u] + 1 and 
                    self.graph[u][v] > 0):
                    
                    min_flow = min(flow, self.graph[u][v])
                    pushed = dfs(v, sink, min_flow, level, start)
                    
                    if pushed > 0:
                        self.graph[u][v] -= pushed
                        self.graph[v][u] += pushed
                        return pushed
                
                start[u] += 1
            
            return 0
        
        max_flow = 0
        level = [-1] * self.n
        
        while bfs(source, sink, level):
            start = [0] * self.n
            
            while True:
                pushed = dfs(source, sink, float('inf'), level, start)
                if pushed == 0:
                    break
                max_flow += pushed
        
        return max_flow


class MinCostMaxFlow:
    """
    最小费用最大流
    """
    
    def __init__(self, n):
        self.n = n
        self.capacity = [[0] * n for _ in range(n)]
        self.cost = [[0] * n for _ in range(n)]
    
    def add_edge(self, u, v, cap, cost):
        """添加容量为cap、单位费用为cost的边"""
        self.capacity[u][v] += cap
        self.cost[u][v] = cost
        self.cost[v][u] = -cost  # 反向边费用为负
    
    def min_cost_max_flow(self, source, sink):
        """
        最小费用最大流算法（基于SPFA）
        时间复杂度：O(V²E²)
        """
        from collections import deque
        
        flow = 0
        total_cost = 0
        
        while True:
            # SPFA寻找最小费用增广路径
            dist = [float('inf')] * self.n
            parent = [-1] * self.n
            in_queue = [False] * self.n
            
            dist[source] = 0
            queue = deque([source])
            in_queue[source] = True
            
            while queue:
                u = queue.popleft()
                in_queue[u] = False
                
                for v in range(self.n):
                    if (self.capacity[u][v] > 0 and 
                        dist[u] + self.cost[u][v] < dist[v]):
                        
                        dist[v] = dist[u] + self.cost[u][v]
                        parent[v] = u
                        
                        if not in_queue[v]:
                            queue.append(v)
                            in_queue[v] = True
            
            # 没有增广路径
            if dist[sink] == float('inf'):
                break
            
            # 找到路径上的最小容量
            path_flow = float('inf')
            v = sink
            
            while v != source:
                u = parent[v]
                path_flow = min(path_flow, self.capacity[u][v])
                v = u
            
            # 更新网络
            v = sink
            while v != source:
                u = parent[v]
                self.capacity[u][v] -= path_flow
                self.capacity[v][u] += path_flow
                total_cost += path_flow * self.cost[u][v]
                v = u
            
            flow += path_flow
        
        return flow, total_cost


class NetworkFlowApplications:
    """
    网络流的应用
    """
    
    @staticmethod
    def maximum_bipartite_matching_flow(left_size, right_size, edges):
        """
        使用网络流解决二分图最大匹配
        """
        # 创建网络：源点 + 左侧 + 右侧 + 汇点
        n = left_size + right_size + 2
        source = 0
        sink = n - 1
        
        flow = MaxFlow(n)
        
        # 源点到左侧
        for i in range(left_size):
            flow.add_edge(source, i + 1, 1)
        
        # 左侧到右侧
        for u, v in edges:
            flow.add_edge(u + 1, left_size + v + 1, 1)
        
        # 右侧到汇点
        for i in range(right_size):
            flow.add_edge(left_size + i + 1, sink, 1)
        
        return flow.edmonds_karp(source, sink)
    
    @staticmethod
    def vertex_disjoint_paths(graph, source, sink, k):
        """
        找到k条顶点不相交的路径
        """
        n = graph.V
        
        # 拆点：每个顶点拆成入点和出点
        flow = MaxFlow(2 * n)
        
        # 顶点内部容量为1（除了源点和汇点）
        for v in range(n):
            if v != source and v != sink:
                flow.add_edge(2 * v, 2 * v + 1, 1)
            else:
                flow.add_edge(2 * v, 2 * v + 1, k)
        
        # 边的容量
        for u in range(n):
            for v, _ in graph.adj_list[u]:
                flow.add_edge(2 * u + 1, 2 * v, 1)
        
        max_paths = flow.edmonds_karp(2 * source, 2 * sink + 1)
        return min(max_paths, k)
```

## 第四部分：高级数据结构

### 1. 并查集（带优化）

```python
class UnionFindAdvanced:
    """
    高级并查集实现
    支持撤销操作和持久化
    """
    
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n
        self.size = [1] * n  # 每个集合的大小
        self.count = n  # 连通分量数
        self.history = []  # 操作历史，用于撤销
    
    def find(self, x):
        """
        查找根节点（路径压缩）
        注意：路径压缩会影响撤销操作，可选择性使用
        """
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]
    
    def find_no_compression(self, x):
        """查找根节点（不压缩路径，支持撤销）"""
        while self.parent[x] != x:
            x = self.parent[x]
        return x
    
    def union(self, x, y, record_history=True):
        """
        合并两个集合
        record_history: 是否记录历史以支持撤销
        """
        root_x = self.find(x)
        root_y = self.find(y)
        
        if root_x == root_y:
            return False
        
        # 记录历史
        if record_history:
            self.history.append({
                'type': 'union',
                'root_x': root_x,
                'root_y': root_y,
                'rank_x': self.rank[root_x],
                'rank_y': self.rank[root_y],
                'size_x': self.size[root_x],
                'size_y': self.size[root_y]
            })
        
        # 按秩合并
        if self.rank[root_x] < self.rank[root_y]:
            self.parent[root_x] = root_y
            self.size[root_y] += self.size[root_x]
        elif self.rank[root_x] > self.rank[root_y]:
            self.parent[root_y] = root_x
            self.size[root_x] += self.size[root_y]
        else:
            self.parent[root_y] = root_x
            self.size[root_x] += self.size[root_y]
            self.rank[root_x] += 1
        
        self.count -= 1
        return True
    
    def undo(self):
        """撤销最后一次合并操作"""
        if not self.history:
            return False
        
        op = self.history.pop()
        
        if op['type'] == 'union':
            root_x = op['root_x']
            root_y = op['root_y']
            
            # 恢复parent关系
            if self.parent[root_x] == root_y:
                self.parent[root_x] = root_x
            else:
                self.parent[root_y] = root_y
            
            # 恢复rank和size
            self.rank[root_x] = op['rank_x']
            self.rank[root_y] = op['rank_y']
            self.size[root_x] = op['size_x']
            self.size[root_y] = op['size_y']
            
            self.count += 1
        
        return True
    
    def get_component_size(self, x):
        """获取x所在连通分量的大小"""
        return self.size[self.find(x)]
    
    def get_components(self):
        """获取所有连通分量"""
        components = {}
        for i in range(len(self.parent)):
            root = self.find(i)
            if root not in components:
                components[root] = []
            components[root].append(i)
        return list(components.values())


class PersistentUnionFind:
    """
    可持久化并查集
    支持查询历史版本
    """
    
    def __init__(self, n):
        self.n = n
        self.versions = [{}]  # 版本历史
        self.current_version = 0
        
        # 初始版本
        self.versions[0] = {
            'parent': list(range(n)),
            'rank': [0] * n,
            'timestamp': 0
        }
    
    def find(self, x, version=None):
        """在指定版本中查找"""
        if version is None:
            version = self.current_version
        
        parent = self.versions[version]['parent']
        
        # 不使用路径压缩以保持版本一致性
        while parent[x] != x:
            x = parent[x]
        
        return x
    
    def union(self, x, y):
        """合并并创建新版本"""
        # 复制当前版本
        new_version = {
            'parent': self.versions[self.current_version]['parent'][:],
            'rank': self.versions[self.current_version]['rank'][:],
            'timestamp': self.current_version + 1
        }
        
        root_x = self.find(x)
        root_y = self.find(y)
        
        if root_x != root_y:
            # 按秩合并
            if new_version['rank'][root_x] < new_version['rank'][root_y]:
                new_version['parent'][root_x] = root_y
            elif new_version['rank'][root_x] > new_version['rank'][root_y]:
                new_version['parent'][root_y] = root_x
            else:
                new_version['parent'][root_y] = root_x
                new_version['rank'][root_x] += 1
        
        self.versions.append(new_version)
        self.current_version += 1
        
        return root_x != root_y
    
    def connected_at_version(self, x, y, version):
        """查询在特定版本是否连通"""
        return self.find(x, version) == self.find(y, version)
```

### 2. LRU/LFU缓存

```python
class LRUCache:
    """
    LRU（最近最少使用）缓存实现
    使用双向链表 + 哈希表
    """
    
    class Node:
        def __init__(self, key=0, value=0):
            self.key = key
            self.value = value
            self.prev = None
            self.next = None
    
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}  # key -> node
        
        # 哨兵节点
        self.head = self.Node()
        self.tail = self.Node()
        self.head.next = self.tail
        self.tail.prev = self.head
    
    def get(self, key):
        """
        获取值
        时间复杂度：O(1)
        """
        if key not in self.cache:
            return -1
        
        node = self.cache[key]
        # 移到头部
        self._move_to_head(node)
        return node.value
    
    def put(self, key, value):
        """
        设置值
        时间复杂度：O(1)
        """
        if key in self.cache:
            # 更新值并移到头部
            node = self.cache[key]
            node.value = value
            self._move_to_head(node)
        else:
            # 创建新节点
            node = self.Node(key, value)
            self.cache[key] = node
            self._add_to_head(node)
            
            # 超出容量，删除尾部节点
            if len(self.cache) > self.capacity:
                tail = self._remove_tail()
                del self.cache[tail.key]
    
    def _add_to_head(self, node):
        """在头部添加节点"""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def _remove_node(self, node):
        """删除节点"""
        prev_node = node.prev
        next_node = node.next
        prev_node.next = next_node
        next_node.prev = prev_node
    
    def _move_to_head(self, node):
        """移动节点到头部"""
        self._remove_node(node)
        self._add_to_head(node)
    
    def _remove_tail(self):
        """删除尾部节点"""
        tail = self.tail.prev
        self._remove_node(tail)
        return tail


class LFUCache:
    """
    LFU（最不经常使用）缓存实现
    使用双哈希表 + 双向链表
    """
    
    class Node:
        def __init__(self, key=0, value=0):
            self.key = key
            self.value = value
            self.freq = 1
            self.prev = None
            self.next = None
    
    class FreqList:
        def __init__(self):
            self.head = LFUCache.Node()
            self.tail = LFUCache.Node()
            self.head.next = self.tail
            self.tail.prev = self.head
            self.size = 0
    
    def __init__(self, capacity):
        self.capacity = capacity
        self.min_freq = 0
        self.key_to_node = {}  # key -> node
        self.freq_to_list = {}  # freq -> FreqList
    
    def get(self, key):
        """
        获取值
        时间复杂度：O(1)
        """
        if key not in self.key_to_node:
            return -1
        
        node = self.key_to_node[key]
        self._update_freq(node)
        return node.value
    
    def put(self, key, value):
        """
        设置值
        时间复杂度：O(1)
        """
        if self.capacity == 0:
            return
        
        if key in self.key_to_node:
            # 更新已存在的键
            node = self.key_to_node[key]
            node.value = value
            self._update_freq(node)
        else:
            # 添加新键
            if len(self.key_to_node) >= self.capacity:
                # 删除最少使用的节点
                self._remove_min_freq_node()
            
            # 创建新节点
            node = self.Node(key, value)
            self.key_to_node[key] = node
            
            # 添加到频率为1的链表
            if 1 not in self.freq_to_list:
                self.freq_to_list[1] = self.FreqList()
            
            self._add_to_head(self.freq_to_list[1], node)
            self.min_freq = 1
    
    def _update_freq(self, node):
        """更新节点的频率"""
        freq = node.freq
        freq_list = self.freq_to_list[freq]
        
        # 从当前频率链表中删除
        self._remove_node(freq_list, node)
        
        # 如果当前频率链表为空且是最小频率，更新最小频率
        if freq_list.size == 0:
            del self.freq_to_list[freq]
            if self.min_freq == freq:
                self.min_freq += 1
        
        # 增加频率并添加到新链表
        node.freq += 1
        new_freq = node.freq
        
        if new_freq not in self.freq_to_list:
            self.freq_to_list[new_freq] = self.FreqList()
        
        self._add_to_head(self.freq_to_list[new_freq], node)
    
    def _remove_min_freq_node(self):
        """删除最小频率的节点"""
        freq_list = self.freq_to_list[self.min_freq]
        node = freq_list.tail.prev
        
        self._remove_node(freq_list, node)
        del self.key_to_node[node.key]
        
        if freq_list.size == 0:
            del self.freq_to_list[self.min_freq]
    
    def _add_to_head(self, freq_list, node):
        """在链表头部添加节点"""
        node.prev = freq_list.head
        node.next = freq_list.head.next
        freq_list.head.next.prev = node
        freq_list.head.next = node
        freq_list.size += 1
    
    def _remove_node(self, freq_list, node):
        """从链表中删除节点"""
        prev_node = node.prev
        next_node = node.next
        prev_node.next = next_node
        next_node.prev = prev_node
        freq_list.size -= 1


class TwoQueueCache:
    """
    2Q缓存算法
    使用两个队列：FIFO队列和LRU队列
    """
    
    def __init__(self, capacity):
        self.capacity = capacity
        self.fifo_size = capacity // 4  # FIFO队列占25%
        self.lru_size = capacity - self.fifo_size
        
        self.fifo = {}  # FIFO队列
        self.fifo_list = []
        self.lru = LRUCache(self.lru_size)  # LRU队列
        self.history = set()  # 访问历史
    
    def get(self, key):
        """获取值"""
        # 先查FIFO
        if key in self.fifo:
            # 从FIFO提升到LRU
            value = self.fifo[key]
            del self.fifo[key]
            self.fifo_list.remove(key)
            self.lru.put(key, value)
            return value
        
        # 再查LRU
        return self.lru.get(key)
    
    def put(self, key, value):
        """设置值"""
        # 如果在历史中，直接加入LRU
        if key in self.history:
            self.lru.put(key, value)
        else:
            # 首次访问，加入FIFO
            if len(self.fifo) >= self.fifo_size:
                # FIFO满了，删除最老的
                old_key = self.fifo_list.pop(0)
                del self.fifo[old_key]
            
            self.fifo[key] = value
            self.fifo_list.append(key)
            self.history.add(key)
```

### 3. 布隆过滤器

```python
class BloomFilter:
    """
    布隆过滤器实现
    用于高效的成员测试，允许一定的假阳性
    """
    
    def __init__(self, capacity, error_rate=0.01):
        """
        capacity: 预期元素数量
        error_rate: 期望的假阳性率
        """
        # 计算最优的位数组大小和哈希函数数量
        self.capacity = capacity
        self.error_rate = error_rate
        
        # m = -n * ln(p) / (ln(2)^2)
        self.bit_size = int(-capacity * math.log(error_rate) / (math.log(2) ** 2))
        
        # k = m / n * ln(2)
        self.hash_count = int(self.bit_size / capacity * math.log(2))
        
        # 位数组
        self.bits = [False] * self.bit_size
        
        # 实际插入的元素数量
        self.count = 0
    
    def _hash(self, item, seed):
        """
        生成哈希值
        使用不同的种子生成多个哈希函数
        """
        import hashlib
        
        h = hashlib.md5()
        h.update(str(item).encode('utf-8'))
        h.update(str(seed).encode('utf-8'))
        
        return int(h.hexdigest(), 16) % self.bit_size
    
    def add(self, item):
        """
        添加元素
        时间复杂度：O(k)，k为哈希函数数量
        """
        for i in range(self.hash_count):
            index = self._hash(item, i)
            self.bits[index] = True
        
        self.count += 1
    
    def contains(self, item):
        """
        检查元素是否存在
        时间复杂度：O(k)
        可能返回假阳性，但绝不会返回假阴性
        """
        for i in range(self.hash_count):
            index = self._hash(item, i)
            if not self.bits[index]:
                return False
        
        return True
    
    def false_positive_probability(self):
        """计算当前的假阳性概率"""
        # (1 - e^(-kn/m))^k
        return (1 - math.exp(-self.hash_count * self.count / self.bit_size)) ** self.hash_count
    
    def __contains__(self, item):
        """支持 in 操作符"""
        return self.contains(item)


class CountingBloomFilter:
    """
    计数布隆过滤器
    支持删除操作
    """
    
    def __init__(self, capacity, error_rate=0.01, counter_bits=4):
        """
        counter_bits: 每个计数器的位数
        """
        self.capacity = capacity
        self.error_rate = error_rate
        self.counter_bits = counter_bits
        self.max_count = (1 << counter_bits) - 1
        
        # 计算参数
        self.bit_size = int(-capacity * math.log(error_rate) / (math.log(2) ** 2))
        self.hash_count = int(self.bit_size / capacity * math.log(2))
        
        # 计数数组
        self.counters = [0] * self.bit_size
    
    def _hash(self, item, seed):
        """生成哈希值"""
        import hashlib
        
        h = hashlib.sha256()
        h.update(str(item).encode('utf-8'))
        h.update(str(seed).encode('utf-8'))
        
        return int(h.hexdigest(), 16) % self.bit_size
    
    def add(self, item):
        """添加元素"""
        for i in range(self.hash_count):
            index = self._hash(item, i)
            if self.counters[index] < self.max_count:
                self.counters[index] += 1
    
    def remove(self, item):
        """
        删除元素
        注意：只有确定元素存在时才应该调用此方法
        """
        # 先检查是否可能存在
        if not self.contains(item):
            return False
        
        for i in range(self.hash_count):
            index = self._hash(item, i)
            if self.counters[index] > 0:
                self.counters[index] -= 1
        
        return True
    
    def contains(self, item):
        """检查元素是否存在"""
        for i in range(self.hash_count):
            index = self._hash(item, i)
            if self.counters[index] == 0:
                return False
        
        return True


class ScalableBloomFilter:
    """
    可扩展布隆过滤器
    当容量不足时自动扩展
    """
    
    def __init__(self, initial_capacity=1000, error_rate=0.01, growth_rate=2):
        self.error_rate = error_rate
        self.growth_rate = growth_rate
        
        # 布隆过滤器列表
        self.filters = []
        self.capacities = []
        
        # 创建初始过滤器
        self._add_filter(initial_capacity)
    
    def _add_filter(self, capacity):
        """添加新的布隆过滤器"""
        # 每个新过滤器的错误率递减
        filter_error_rate = self.error_rate * (0.5 ** len(self.filters))
        
        new_filter = BloomFilter(capacity, filter_error_rate)
        self.filters.append(new_filter)
        self.capacities.append(capacity)
    
    def add(self, item):
        """添加元素"""
        # 如果元素已存在，不重复添加
        if self.contains(item):
            return
        
        # 添加到最新的过滤器
        current_filter = self.filters[-1]
        current_filter.add(item)
        
        # 检查是否需要扩展
        if current_filter.count >= current_filter.capacity:
            new_capacity = self.capacities[-1] * self.growth_rate
            self._add_filter(int(new_capacity))
    
    def contains(self, item):
        """检查元素是否存在"""
        for f in self.filters:
            if f.contains(item):
                return True
        return False
```

### 4. 位图与位运算

```python
class BitMap:
    """
    位图实现
    用于高效存储和操作大量布尔值
    """
    
    def __init__(self, size):
        """
        size: 位图大小（位数）
        """
        self.size = size
        # 每个整数存储32位
        self.bits_per_word = 32
        self.words = [0] * ((size + self.bits_per_word - 1) // self.bits_per_word)
    
    def set(self, pos):
        """
        设置第pos位为1
        时间复杂度：O(1)
        """
        if pos < 0 or pos >= self.size:
            raise IndexError("Position out of range")
        
        word_index = pos // self.bits_per_word
        bit_index = pos % self.bits_per_word
        self.words[word_index] |= (1 << bit_index)
    
    def clear(self, pos):
        """
        设置第pos位为0
        时间复杂度：O(1)
        """
        if pos < 0 or pos >= self.size:
            raise IndexError("Position out of range")
        
        word_index = pos // self.bits_per_word
        bit_index = pos % self.bits_per_word
        self.words[word_index] &= ~(1 << bit_index)
    
    def get(self, pos):
        """
        获取第pos位的值
        时间复杂度：O(1)
        """
        if pos < 0 or pos >= self.size:
            raise IndexError("Position out of range")
        
        word_index = pos // self.bits_per_word
        bit_index = pos % self.bits_per_word
        return bool(self.words[word_index] & (1 << bit_index))
    
    def flip(self, pos):
        """
        翻转第pos位
        时间复杂度：O(1)
        """
        if pos < 0 or pos >= self.size:
            raise IndexError("Position out of range")
        
        word_index = pos // self.bits_per_word
        bit_index = pos % self.bits_per_word
        self.words[word_index] ^= (1 << bit_index)
    
    def count(self):
        """
        统计1的个数
        时间复杂度：O(n/32)
        """
        count = 0
        for word in self.words:
            # Brian Kernighan算法
            while word:
                word &= word - 1
                count += 1
        return count
    
    def all(self):
        """检查是否所有位都是1"""
        full_words = self.size // self.bits_per_word
        remainder = self.size % self.bits_per_word
        
        # 检查完整的字
        for i in range(full_words):
            if self.words[i] != 0xFFFFFFFF:
                return False
        
        # 检查剩余的位
        if remainder > 0:
            mask = (1 << remainder) - 1
            if self.words[full_words] != mask:
                return False
        
        return True
    
    def any(self):
        """检查是否有任何位是1"""
        return any(word != 0 for word in self.words)
    
    def none(self):
        """检查是否所有位都是0"""
        return all(word == 0 for word in self.words)
    
    def __and__(self, other):
        """位与操作"""
        if self.size != other.size:
            raise ValueError("Bitmaps must have the same size")
        
        result = BitMap(self.size)
        for i in range(len(self.words)):
            result.words[i] = self.words[i] & other.words[i]
        return result
    
    def __or__(self, other):
        """位或操作"""
        if self.size != other.size:
            raise ValueError("Bitmaps must have the same size")
        
        result = BitMap(self.size)
        for i in range(len(self.words)):
            result.words[i] = self.words[i] | other.words[i]
        return result
    
    def __xor__(self, other):
        """位异或操作"""
        if self.size != other.size:
            raise ValueError("Bitmaps must have the same size")
        
        result = BitMap(self.size)
        for i in range(len(self.words)):
            result.words[i] = self.words[i] ^ other.words[i]
        return result


class BitOperations:
    """
    常用位运算技巧集合
    """
    
    @staticmethod
    def get_bit(num, i):
        """获取第i位"""
        return (num >> i) & 1
    
    @staticmethod
    def set_bit(num, i):
        """设置第i位为1"""
        return num | (1 << i)
    
    @staticmethod
    def clear_bit(num, i):
        """清除第i位"""
        return num & ~(1 << i)
    
    @staticmethod
    def update_bit(num, i, bit):
        """更新第i位"""
        mask = ~(1 << i)
        return (num & mask) | (bit << i)
    
    @staticmethod
    def is_power_of_two(n):
        """判断是否为2的幂"""
        return n > 0 and (n & (n - 1)) == 0
    
    @staticmethod
    def count_ones(n):
        """统计二进制中1的个数"""
        count = 0
        while n:
            n &= n - 1  # 清除最低位的1
            count += 1
        return count
    
    @staticmethod
    def find_missing_number(nums):
        """
        找出缺失的数字
        nums包含0到n中的n个数字
        """
        n = len(nums)
        xor_all = 0
        xor_nums = 0
        
        # 0到n的异或
        for i in range(n + 1):
            xor_all ^= i
        
        # nums中所有数的异或
        for num in nums:
            xor_nums ^= num
        
        # 缺失的数字
        return xor_all ^ xor_nums
    
    @staticmethod
    def find_two_missing_numbers(nums, n):
        """
        找出两个缺失的数字
        nums包含1到n中的n-2个数字
        """
        # 计算所有缺失数字的异或
        xor_all = 0
        for i in range(1, n + 1):
            xor_all ^= i
        
        for num in nums:
            xor_all ^= num
        
        # xor_all = missing1 ^ missing2
        # 找到一个为1的位
        rightmost_bit = xor_all & -xor_all
        
        # 根据这一位将数字分成两组
        missing1 = missing2 = 0
        
        for i in range(1, n + 1):
            if i & rightmost_bit:
                missing1 ^= i
            else:
                missing2 ^= i
        
        for num in nums:
            if num & rightmost_bit:
                missing1 ^= num
            else:
                missing2 ^= num
        
        return missing1, missing2
    
    @staticmethod
    def gray_code(n):
        """生成n位格雷码"""
        return n ^ (n >> 1)
    
    @staticmethod
    def reverse_bits(n, width=32):
        """反转二进制位"""
        result = 0
        for i in range(width):
            result = (result << 1) | (n & 1)
            n >>= 1
        return result


class RoaringBitmap:
    """
    Roaring Bitmap实现
    适用于稀疏数据的压缩位图
    """
    
    def __init__(self):
        # 使用字典存储容器
        # key: 高16位, value: 容器（数组或位图）
        self.containers = {}
        self.CONTAINER_SIZE = 1 << 16  # 65536
        self.ARRAY_CONTAINER_MAX = 4096  # 数组容器的最大元素数
    
    def add(self, x):
        """添加元素"""
        high = x >> 16
        low = x & 0xFFFF
        
        if high not in self.containers:
            self.containers[high] = {'type': 'array', 'data': []}
        
        container = self.containers[high]
        
        if container['type'] == 'array':
            if low not in container['data']:
                container['data'].append(low)
                container['data'].sort()
                
                # 如果数组太大，转换为位图
                if len(container['data']) > self.ARRAY_CONTAINER_MAX:
                    self._convert_to_bitmap(high)
        else:
            # 位图容器
            container['data'][low] = True
    
    def contains(self, x):
        """检查元素是否存在"""
        high = x >> 16
        low = x & 0xFFFF
        
        if high not in self.containers:
            return False
        
        container = self.containers[high]
        
        if container['type'] == 'array':
            return low in container['data']
        else:
            return container['data'].get(low, False)
    
    def _convert_to_bitmap(self, high):
        """将数组容器转换为位图容器"""
        container = self.containers[high]
        bitmap = {}
        
        for val in container['data']:
            bitmap[val] = True
        
        container['type'] = 'bitmap'
        container['data'] = bitmap
    
    def cardinality(self):
        """计算元素总数"""
        count = 0
        for container in self.containers.values():
            if container['type'] == 'array':
                count += len(container['data'])
            else:
                count += len(container['data'])
        return count
    
    def to_array(self):
        """转换为数组"""
        result = []
        
        for high in sorted(self.containers.keys()):
            container = self.containers[high]
            base = high << 16
            
            if container['type'] == 'array':
                for low in container['data']:
                    result.append(base | low)
            else:
                for low in sorted(container['data'].keys()):
                    result.append(base | low)
        
        return result
```

### 5. 可持久化数据结构

```python
class PersistentArray:
    """
    可持久化数组
    使用路径复制实现
    """
    
    class Node:
        def __init__(self, value=None):
            self.value = value
            self.left = None
            self.right = None
    
    def __init__(self, arr):
        self.versions = []
        self.size = len(arr)
        
        # 构建初始版本
        root = self._build(arr, 0, len(arr) - 1)
        self.versions.append(root)
    
    def _build(self, arr, left, right):
        """构建完全二叉树"""
        if left > right:
            return None
        
        mid = (left + right) // 2
        node = self.Node(arr[mid])
        
        if left < mid:
            node.left = self._build(arr, left, mid - 1)
        if mid < right:
            node.right = self._build(arr, mid + 1, right)
        
        return node
    
    def get(self, version, index):
        """
        获取指定版本的元素
        时间复杂度：O(log n)
        """
        if version >= len(self.versions):
            raise ValueError("Invalid version")
        
        return self._get(self.versions[version], index, 0, self.size - 1)
    
    def _get(self, node, index, left, right):
        """递归获取元素"""
        if left == right:
            return node.value
        
        mid = (left + right) // 2
        
        if index <= mid:
            return self._get(node.left, index, left, mid)
        else:
            return self._get(node.right, index, mid + 1, right)
    
    def set(self, version, index, value):
        """
        创建新版本并设置元素
        时间复杂度：O(log n)
        空间复杂度：O(log n) 每次修改
        """
        if version >= len(self.versions):
            raise ValueError("Invalid version")
        
        new_root = self._set(self.versions[version], index, value, 0, self.size - 1)
        self.versions.append(new_root)
        
        return len(self.versions) - 1  # 返回新版本号
    
    def _set(self, node, index, value, left, right):
        """递归设置元素（路径复制）"""
        if left == right:
            new_node = self.Node(value)
            return new_node
        
        # 复制当前节点
        new_node = self.Node(node.value)
        mid = (left + right) // 2
        
        if index <= mid:
            new_node.left = self._set(node.left, index, value, left, mid)
            new_node.right = node.right  # 共享右子树
        else:
            new_node.left = node.left  # 共享左子树
            new_node.right = self._set(node.right, index, value, mid + 1, right)
        
        return new_node


class PersistentSegmentTree:
    """
    可持久化线段树（主席树）
    支持查询历史版本的区间和
    """
    
    class Node:
        def __init__(self, left=None, right=None, sum_val=0):
            self.left = left
            self.right = right
            self.sum = sum_val
    
    def __init__(self, arr):
        self.n = len(arr)
        self.roots = []
        
        # 构建初始版本
        self.roots.append(self._build(arr, 0, self.n - 1))
    
    def _build(self, arr, start, end):
        """构建线段树"""
        if start == end:
            return self.Node(sum_val=arr[start])
        
        mid = (start + end) // 2
        left = self._build(arr, start, mid)
        right = self._build(arr, mid + 1, end)
        
        return self.Node(left, right, left.sum + right.sum)
    
    def update(self, version, index, value):
        """
        更新并创建新版本
        时间复杂度：O(log n)
        """
        if version >= len(self.roots):
            raise ValueError("Invalid version")
        
        new_root = self._update(self.roots[version], 0, self.n - 1, index, value)
        self.roots.append(new_root)
        
        return len(self.roots) - 1
    
    def _update(self, node, start, end, index, value):
        """递归更新（路径复制）"""
        if start == end:
            return self.Node(sum_val=value)
        
        mid = (start + end) // 2
        
        if index <= mid:
            # 更新左子树，复制右子树
            left = self._update(node.left, start, mid, index, value)
            return self.Node(left, node.right, left.sum + node.right.sum)
        else:
            # 更新右子树，复制左子树
            right = self._update(node.right, mid + 1, end, index, value)
            return self.Node(node.left, right, node.left.sum + right.sum)
    
    def query(self, version, left, right):
        """
        查询指定版本的区间和
        时间复杂度：O(log n)
        """
        if version >= len(self.roots):
            raise ValueError("Invalid version")
        
        return self._query(self.roots[version], 0, self.n - 1, left, right)
    
    def _query(self, node, start, end, left, right):
        """递归查询"""
        if left <= start and end <= right:
            return node.sum
        
        mid = (start + end) // 2
        result = 0
        
        if left <= mid:
            result += self._query(node.left, start, mid, left, right)
        
        if right > mid:
            result += self._query(node.right, mid + 1, end, left, right)
        
        return result
    
    def query_kth_smallest(self, version1, version2, k):
        """
        查询两个版本之间第k小的元素
        用于解决区间第k小问题
        """
        return self._query_kth(
            self.roots[version1], 
            self.roots[version2], 
            0, self.n - 1, k
        )
    
    def _query_kth(self, node1, node2, start, end, k):
        """递归查询第k小"""
        if start == end:
            return start
        
        mid = (start + end) // 2
        left_count = node2.left.sum - node1.left.sum
        
        if k <= left_count:
            return self._query_kth(node1.left, node2.left, start, mid, k)
        else:
            return self._query_kth(
                node1.right, node2.right, 
                mid + 1, end, k - left_count
            )


class PersistentTrie:
    """
    可持久化字典树
    """
    
    class Node:
        def __init__(self):
            self.children = {}
            self.is_end = False
            self.version = 0
    
    def __init__(self):
        self.roots = [self.Node()]  # 版本0的根节点
        self.current_version = 0
    
    def insert(self, version, word):
        """
        在指定版本基础上插入单词
        返回新版本号
        """
        if version > self.current_version:
            raise ValueError("Invalid version")
        
        self.current_version += 1
        new_root = self._insert(self.roots[version], word, 0)
        self.roots.append(new_root)
        
        return self.current_version
    
    def _insert(self, node, word, index):
        """递归插入（路径复制）"""
        # 复制当前节点
        new_node = self.Node()
        new_node.children = node.children.copy()
        new_node.is_end = node.is_end
        new_node.version = self.current_version
        
        if index == len(word):
            new_node.is_end = True
            return new_node
        
        char = word[index]
        
        if char in node.children:
            # 复制并修改子节点
            new_node.children[char] = self._insert(
                node.children[char], word, index + 1
            )
        else:
            # 创建新的子节点
            new_node.children[char] = self._create_path(word, index + 1)
        
        return new_node
    
    def _create_path(self, word, index):
        """创建新路径"""
        if index == len(word):
            node = self.Node()
            node.is_end = True
            node.version = self.current_version
            return node
        
        node = self.Node()
        node.version = self.current_version
        node.children[word[index]] = self._create_path(word, index + 1)
        
        return node
    
    def search(self, version, word):
        """
        在指定版本中搜索单词
        时间复杂度：O(m)，m为单词长度
        """
        if version > self.current_version:
            raise ValueError("Invalid version")
        
        node = self.roots[version]
        
        for char in word:
            if char not in node.children:
                return False
            node = node.children[char]
        
        return node.is_end
```

## 第五部分：基础算法

### 1. 排序算法

```python
class SortingAlgorithms:
    """
    十种经典排序算法实现
    """
    
    @staticmethod
    def bubble_sort(arr):
        """
        冒泡排序
        时间复杂度：O(n²)
        空间复杂度：O(1)
        稳定排序
        """
        n = len(arr)
        
        for i in range(n):
            # 优化：如果一轮没有交换，说明已经有序
            swapped = False
            
            # 每轮将最大元素冒泡到末尾
            for j in range(n - i - 1):
                if arr[j] > arr[j + 1]:
                    arr[j], arr[j + 1] = arr[j + 1], arr[j]
                    swapped = True
            
            if not swapped:
                break
        
        return arr
    
    @staticmethod
    def selection_sort(arr):
        """
        选择排序
        时间复杂度：O(n²)
        空间复杂度：O(1)
        不稳定排序
        """
        n = len(arr)
        
        for i in range(n):
            # 找到剩余部分的最小元素
            min_idx = i
            for j in range(i + 1, n):
                if arr[j] < arr[min_idx]:
                    min_idx = j
            
            # 交换到当前位置
            arr[i], arr[min_idx] = arr[min_idx], arr[i]
        
        return arr
    
    @staticmethod
    def insertion_sort(arr):
        """
        插入排序
        时间复杂度：O(n²)，最好O(n)
        空间复杂度：O(1)
        稳定排序
        """
        n = len(arr)
        
        for i in range(1, n):
            key = arr[i]
            j = i - 1
            
            # 将大于key的元素后移
            while j >= 0 and arr[j] > key:
                arr[j + 1] = arr[j]
                j -= 1
            
            # 插入key到正确位置
            arr[j + 1] = key
        
        return arr
    
    @staticmethod
    def shell_sort(arr):
        """
        希尔排序
        时间复杂度：O(n log n) ~ O(n²)
        空间复杂度：O(1)
        不稳定排序
        """
        n = len(arr)
        gap = n // 2
        
        while gap > 0:
            # 对每个子序列进行插入排序
            for i in range(gap, n):
                temp = arr[i]
                j = i
                
                while j >= gap and arr[j - gap] > temp:
                    arr[j] = arr[j - gap]
                    j -= gap
                
                arr[j] = temp
            
            gap //= 2
        
        return arr
    
    @staticmethod
    def merge_sort(arr):
        """
        归并排序
        时间复杂度：O(n log n)
        空间复杂度：O(n)
        稳定排序
        """
        def merge(left, right):
            """合并两个有序数组"""
            result = []
            i = j = 0
            
            while i < len(left) and j < len(right):
                if left[i] <= right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
            
            # 添加剩余元素
            result.extend(left[i:])
            result.extend(right[j:])
            
            return result
        
        # 递归基
        if len(arr) <= 1:
            return arr
        
        # 分割
        mid = len(arr) // 2
        left = merge_sort(arr[:mid])
        right = merge_sort(arr[mid:])
        
        # 合并
        return merge(left, right)
    
    @staticmethod
    def quick_sort(arr):
        """
        快速排序
        时间复杂度：平均O(n log n)，最坏O(n²)
        空间复杂度：O(log n)
        不稳定排序
        """
        def partition(arr, low, high):
            """
            分区函数
            选择最后一个元素作为基准
            """
            pivot = arr[high]
            i = low - 1  # 小于基准的元素的最右索引
            
            for j in range(low, high):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[high] = arr[high], arr[i + 1]
            return i + 1
        
        def quick_sort_helper(arr, low, high):
            """递归排序"""
            if low < high:
                # 分区
                pi = partition(arr, low, high)
                
                # 递归排序左右部分
                quick_sort_helper(arr, low, pi - 1)
                quick_sort_helper(arr, pi + 1, high)
        
        quick_sort_helper(arr, 0, len(arr) - 1)
        return arr
    
    @staticmethod
    def quick_sort_3way(arr):
        """
        三路快速排序
        适用于有大量重复元素的情况
        """
        def partition_3way(arr, low, high):
            """三路分区"""
            if low >= high:
                return
            
            lt = low  # arr[low..lt-1] < pivot
            gt = high  # arr[gt+1..high] > pivot
            i = low + 1  # arr[lt..i-1] == pivot
            pivot = arr[low]
            
            while i <= gt:
                if arr[i] < pivot:
                    arr[lt], arr[i] = arr[i], arr[lt]
                    lt += 1
                    i += 1
                elif arr[i] > pivot:
                    arr[i], arr[gt] = arr[gt], arr[i]
                    gt -= 1
                else:
                    i += 1
            
            # 递归排序左右部分
            partition_3way(arr, low, lt - 1)
            partition_3way(arr, gt + 1, high)
        
        partition_3way(arr, 0, len(arr) - 1)
        return arr
    
    @staticmethod
    def heap_sort(arr):
        """
        堆排序
        时间复杂度：O(n log n)
        空间复杂度：O(1)
        不稳定排序
        """
        def heapify(arr, n, i):
            """
            堆化以i为根的子树
            n是堆的大小
            """
            largest = i
            left = 2 * i + 1
            right = 2 * i + 2
            
            # 找到最大的节点
            if left < n and arr[left] > arr[largest]:
                largest = left
            
            if right < n and arr[right] > arr[largest]:
                largest = right
            
            # 如果最大的不是根节点
            if largest != i:
                arr[i], arr[largest] = arr[largest], arr[i]
                # 递归堆化受影响的子树
                heapify(arr, n, largest)
        
        n = len(arr)
        
        # 构建最大堆
        for i in range(n // 2 - 1, -1, -1):
            heapify(arr, n, i)
        
        # 一个个提取元素
        for i in range(n - 1, 0, -1):
            arr[0], arr[i] = arr[i], arr[0]  # 交换
            heapify(arr, i, 0)
        
        return arr
    
    @staticmethod
    def counting_sort(arr, max_val=None):
        """
        计数排序
        时间复杂度：O(n + k)，k为值域范围
        空间复杂度：O(k)
        稳定排序
        适用于值域较小的非负整数
        """
        if not arr:
            return arr
        
        if max_val is None:
            max_val = max(arr)
        
        # 计数数组
        count = [0] * (max_val + 1)
        
        # 统计每个元素出现次数
        for num in arr:
            count[num] += 1
        
        # 累积计数
        for i in range(1, len(count)):
            count[i] += count[i - 1]
        
        # 构建输出数组
        output = [0] * len(arr)
        
        # 从后向前遍历，保证稳定性
        for i in range(len(arr) - 1, -1, -1):
            output[count[arr[i]] - 1] = arr[i]
            count[arr[i]] -= 1
        
        return output
    
    @staticmethod
    def radix_sort(arr):
        """
        基数排序
        时间复杂度：O(d * (n + k))，d为位数，k为基数
        空间复杂度：O(n + k)
        稳定排序
        """
        def counting_sort_for_radix(arr, exp):
            """对指定位进行计数排序"""
            n = len(arr)
            output = [0] * n
            count = [0] * 10
            
            # 统计当前位的数字分布
            for i in range(n):
                index = (arr[i] // exp) % 10
                count[index] += 1
            
            # 累积计数
            for i in range(1, 10):
                count[i] += count[i - 1]
            
            # 构建输出数组
            for i in range(n - 1, -1, -1):
                index = (arr[i] // exp) % 10
                output[count[index] - 1] = arr[i]
                count[index] -= 1
            
            # 复制回原数组
            for i in range(n):
                arr[i] = output[i]
        
        if not arr:
            return arr
        
        # 找到最大值以确定位数
        max_val = max(arr)
        
        # 对每一位进行计数排序
        exp = 1
        while max_val // exp > 0:
            counting_sort_for_radix(arr, exp)
            exp *= 10
        
        return arr
    
    @staticmethod
    def bucket_sort(arr, num_buckets=10):
        """
        桶排序
        时间复杂度：平均O(n + k)，最坏O(n²)
        空间复杂度：O(n + k)
        稳定排序
        适用于均匀分布的数据
        """
        if not arr:
            return arr
        
        # 找到最大最小值
        min_val = min(arr)
        max_val = max(arr)
        
        # 计算桶的大小
        bucket_range = (max_val - min_val) / num_buckets
        
        # 创建桶
        buckets = [[] for _ in range(num_buckets)]
        
        # 将元素分配到桶中
        for num in arr:
            index = int((num - min_val) / bucket_range)
            # 处理最大值的情况
            if index == num_buckets:
                index = num_buckets - 1
            buckets[index].append(num)
        
        # 对每个桶进行排序（使用插入排序）
        result = []
        for bucket in buckets:
            # 插入排序
            for i in range(1, len(bucket)):
                key = bucket[i]
                j = i - 1
                while j >= 0 and bucket[j] > key:
                    bucket[j + 1] = bucket[j]
                    j -= 1
                bucket[j + 1] = key
            
            result.extend(bucket)
        
        return result


class SortingOptimizations:
    """
    排序算法的优化技巧
    """
    
    @staticmethod
    def intro_sort(arr):
        """
        内省排序（Introspective Sort）
        结合快速排序、堆排序和插入排序
        C++ STL sort的实现
        """
        def insertion_sort_partial(arr, left, right):
            """部分区间的插入排序"""
            for i in range(left + 1, right + 1):
                key = arr[i]
                j = i - 1
                while j >= left and arr[j] > key:
                    arr[j + 1] = arr[j]
                    j -= 1
                arr[j + 1] = key
        
        def heap_sort_partial(arr, left, right):
            """部分区间的堆排序"""
            def heapify(arr, n, i, left):
                largest = i
                l = 2 * i + 1
                r = 2 * i + 2
                
                if l < n and arr[left + l] > arr[left + largest]:
                    largest = l
                
                if r < n and arr[left + r] > arr[left + largest]:
                    largest = r
                
                if largest != i:
                    arr[left + i], arr[left + largest] = \
                        arr[left + largest], arr[left + i]
                    heapify(arr, n, largest, left)
            
            n = right - left + 1
            
            # 构建堆
            for i in range(n // 2 - 1, -1, -1):
                heapify(arr, n, i, left)
            
            # 提取元素
            for i in range(n - 1, 0, -1):
                arr[left], arr[left + i] = arr[left + i], arr[left]
                heapify(arr, i, 0, left)
        
        def intro_sort_util(arr, left, right, depth_limit):
            """内省排序的递归实现"""
            size = right - left + 1
            
            # 小数组使用插入排序
            if size < 16:
                insertion_sort_partial(arr, left, right)
                return
            
            # 深度限制到达，使用堆排序
            if depth_limit == 0:
                heap_sort_partial(arr, left, right)
                return
            
            # 快速排序
            pivot = arr[right]
            i = left - 1
            
            for j in range(left, right):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[right] = arr[right], arr[i + 1]
            partition = i + 1
            
            intro_sort_util(arr, left, partition - 1, depth_limit - 1)
            intro_sort_util(arr, partition + 1, right, depth_limit - 1)
        
        import math
        n = len(arr)
        if n > 1:
            depth_limit = 2 * int(math.log2(n))
            intro_sort_util(arr, 0, n - 1, depth_limit)
        
        return arr
    
    @staticmethod
    def tim_sort(arr):
        """
        TimSort（简化版）
        Python和Java的默认排序算法
        结合归并排序和插入排序
        """
        MIN_MERGE = 32
        
        def insertion_sort_for_tim(arr, left, right):
            """优化的插入排序"""
            for i in range(left + 1, right + 1):
                key_item = arr[i]
                j = i - 1
                while j >= left and arr[j] > key_item:
                    arr[j + 1] = arr[j]
                    j -= 1
                arr[j + 1] = key_item
        
        def merge_for_tim(arr, left, mid, right):
            """合并两个有序区间"""
            left_part = arr[left:mid + 1]
            right_part = arr[mid + 1:right + 1]
            
            i = j = 0
            k = left
            
            while i < len(left_part) and j < len(right_part):
                if left_part[i] <= right_part[j]:
                    arr[k] = left_part[i]
                    i += 1
                else:
                    arr[k] = right_part[j]
                    j += 1
                k += 1
            
            while i < len(left_part):
                arr[k] = left_part[i]
                i += 1
                k += 1
            
            while j < len(right_part):
                arr[k] = right_part[j]
                j += 1
                k += 1
        
        n = len(arr)
        
        # 对小块进行插入排序
        for start in range(0, n, MIN_MERGE):
            end = min(start + MIN_MERGE - 1, n - 1)
            insertion_sort_for_tim(arr, start, end)
        
        # 开始归并
        size = MIN_MERGE
        while size < n:
            for start in range(0, n, size * 2):
                mid = start + size - 1
                end = min(start + size * 2 - 1, n - 1)
                
                if mid < end:
                    merge_for_tim(arr, start, mid, end)
            
            size *= 2
        
        return arr
```

### 2. 查找算法

```python
class SearchAlgorithms:
    """
    各种查找算法实现
    """
    
    @staticmethod
    def linear_search(arr, target):
        """
        线性查找
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        for i in range(len(arr)):
            if arr[i] == target:
                return i
        return -1
    
    @staticmethod
    def binary_search(arr, target):
        """
        二分查找（迭代版）
        时间复杂度：O(log n)
        空间复杂度：O(1)
        前提：数组有序
        """
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid = left + (right - left) // 2  # 防止溢出
            
            if arr[mid] == target:
                return mid
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return -1
    
    @staticmethod
    def binary_search_recursive(arr, target, left=0, right=None):
        """
        二分查找（递归版）
        时间复杂度：O(log n)
        空间复杂度：O(log n)
        """
        if right is None:
            right = len(arr) - 1
        
        if left > right:
            return -1
        
        mid = left + (right - left) // 2
        
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            return SearchAlgorithms.binary_search_recursive(
                arr, target, mid + 1, right
            )
        else:
            return SearchAlgorithms.binary_search_recursive(
                arr, target, left, mid - 1
            )
    
    @staticmethod
    def binary_search_first(arr, target):
        """
        查找第一个等于target的元素
        """
        left, right = 0, len(arr) - 1
        result = -1
        
        while left <= right:
            mid = left + (right - left) // 2
            
            if arr[mid] == target:
                result = mid
                right = mid - 1  # 继续在左侧查找
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return result
    
    @staticmethod
    def binary_search_last(arr, target):
        """
        查找最后一个等于target的元素
        """
        left, right = 0, len(arr) - 1
        result = -1
        
        while left <= right:
            mid = left + (right - left) // 2
            
            if arr[mid] == target:
                result = mid
                left = mid + 1  # 继续在右侧查找
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return result
    
    @staticmethod
    def lower_bound(arr, target):
        """
        查找第一个大于等于target的元素位置
        """
        left, right = 0, len(arr)
        
        while left < right:
            mid = left + (right - left) // 2
            
            if arr[mid] < target:
                left = mid + 1
            else:
                right = mid
        
        return left
    
    @staticmethod
    def upper_bound(arr, target):
        """
        查找第一个大于target的元素位置
        """
        left, right = 0, len(arr)
        
        while left < right:
            mid = left + (right - left) // 2
            
            if arr[mid] <= target:
                left = mid + 1
            else:
                right = mid
        
        return left
    
    @staticmethod
    def ternary_search(arr, target):
        """
        三分查找
        时间复杂度：O(log₃ n)
        适用于有序数组
        """
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid1 = left + (right - left) // 3
            mid2 = right - (right - left) // 3
            
            if arr[mid1] == target:
                return mid1
            if arr[mid2] == target:
                return mid2
            
            if target < arr[mid1]:
                right = mid1 - 1
            elif target > arr[mid2]:
                left = mid2 + 1
            else:
                left = mid1 + 1
                right = mid2 - 1
        
        return -1
    
    @staticmethod
    def interpolation_search(arr, target):
        """
        插值查找
        时间复杂度：平均O(log log n)，最坏O(n)
        适用于均匀分布的有序数组
        """
        left, right = 0, len(arr) - 1
        
        while left <= right and target >= arr[left] and target <= arr[right]:
            # 如果只有一个元素
            if left == right:
                if arr[left] == target:
                    return left
                return -1
            
            # 根据目标值估算位置
            pos = left + int(
                ((target - arr[left]) / (arr[right] - arr[left])) * 
                (right - left)
            )
            
            if arr[pos] == target:
                return pos
            elif arr[pos] < target:
                left = pos + 1
            else:
                right = pos - 1
        
        return -1
    
    @staticmethod
    def exponential_search(arr, target):
        """
        指数查找
        时间复杂度：O(log n)
        适用于无界或大型有序数组
        """
        if not arr:
            return -1
        
        # 如果目标在第一个位置
        if arr[0] == target:
            return 0
        
        # 找到范围
        i = 1
        while i < len(arr) and arr[i] <= target:
            i *= 2
        
        # 在找到的范围内进行二分查找
        return SearchAlgorithms.binary_search_in_range(
            arr, target, i // 2, min(i, len(arr) - 1)
        )
    
    @staticmethod
    def binary_search_in_range(arr, target, left, right):
        """在指定范围内二分查找"""
        while left <= right:
            mid = left + (right - left) // 2
            
            if arr[mid] == target:
                return mid
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return -1
    
    @staticmethod
    def jump_search(arr, target):
        """
        跳跃查找
        时间复杂度：O(√n)
        空间复杂度：O(1)
        """
        import math
        
        n = len(arr)
        step = int(math.sqrt(n))
        prev = 0
        
        # 跳跃查找块
        while arr[min(step, n) - 1] < target:
            prev = step
            step += int(math.sqrt(n))
            if prev >= n:
                return -1
        
        # 在块内线性查找
        while arr[prev] < target:
            prev += 1
            if prev == min(step, n):
                return -1
        
        if arr[prev] == target:
            return prev
        
        return -1
    
    @staticmethod
    def fibonacci_search(arr, target):
        """
        斐波那契查找
        时间复杂度：O(log n)
        使用斐波那契数列分割数组
        """
        n = len(arr)
        
        # 初始化斐波那契数列
        fib2 = 0  # (m-2)'th Fibonacci number
        fib1 = 1  # (m-1)'th Fibonacci number
        fib = fib2 + fib1  # m'th Fibonacci number
        
        # 找到大于等于n的最小斐波那契数
        while fib < n:
            fib2 = fib1
            fib1 = fib
            fib = fib2 + fib1
        
        offset = -1
        
        while fib > 1:
            # 检查fib2是否有效位置
            i = min(offset + fib2, n - 1)
            
            if arr[i] < target:
                fib = fib1
                fib1 = fib2
                fib2 = fib - fib1
                offset = i
            elif arr[i] > target:
                fib = fib2
                fib1 = fib1 - fib2
                fib2 = fib - fib1
            else:
                return i
        
        # 检查最后一个元素
        if fib1 and offset + 1 < n and arr[offset + 1] == target:
            return offset + 1
        
        return -1


class SpecializedSearch:
    """
    特殊情况下的查找算法
    """
    
    @staticmethod
    def search_in_rotated_array(arr, target):
        """
        在旋转排序数组中查找
        时间复杂度：O(log n)
        """
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid = left + (right - left) // 2
            
            if arr[mid] == target:
                return mid
            
            # 判断哪一半是有序的
            if arr[left] <= arr[mid]:
                # 左半部分有序
                if arr[left] <= target < arr[mid]:
                    right = mid - 1
                else:
                    left = mid + 1
            else:
                # 右半部分有序
                if arr[mid] < target <= arr[right]:
                    left = mid + 1
                else:
                    right = mid - 1
        
        return -1
    
    @staticmethod
    def search_in_2d_matrix(matrix, target):
        """
        在二维矩阵中查找
        矩阵每行递增，每列递增
        时间复杂度：O(m + n)
        """
        if not matrix or not matrix[0]:
            return False
        
        rows, cols = len(matrix), len(matrix[0])
        row, col = 0, cols - 1
        
        while row < rows and col >= 0:
            if matrix[row][col] == target:
                return True
            elif matrix[row][col] > target:
                col -= 1
            else:
                row += 1
        
        return False
    
    @staticmethod
    def find_peak_element(arr):
        """
        寻找峰值元素
        峰值元素是指其值大于左右相邻元素的元素
        时间复杂度：O(log n)
        """
        left, right = 0, len(arr) - 1
        
        while left < right:
            mid = left + (right - left) // 2
            
            if arr[mid] > arr[mid + 1]:
                # 峰值在左侧（包括mid）
                right = mid
            else:
                # 峰值在右侧
                left = mid + 1
        
        return left
    
    @staticmethod
    def find_kth_smallest(arr, k):
        """
        查找第k小的元素（快速选择算法）
        时间复杂度：平均O(n)，最坏O(n²)
        """
        def partition(arr, left, right):
            pivot = arr[right]
            i = left - 1
            
            for j in range(left, right):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[right] = arr[right], arr[i + 1]
            return i + 1
        
        def quick_select(arr, left, right, k):
            if left == right:
                return arr[left]
            
            pivot_index = partition(arr, left, right)
            
            if k == pivot_index:
                return arr[k]
            elif k < pivot_index:
                return quick_select(arr, left, pivot_index - 1, k)
            else:
                return quick_select(arr, pivot_index + 1, right, k)
        
        return quick_select(arr, 0, len(arr) - 1, k - 1)
```

### 3. 双指针与滑动窗口

```python
class TwoPointers:
    """
    双指针技巧的各种应用
    """
    
    @staticmethod
    def two_sum_sorted(arr, target):
        """
        有序数组的两数之和
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        left, right = 0, len(arr) - 1
        
        while left < right:
            current_sum = arr[left] + arr[right]
            
            if current_sum == target:
                return [left, right]
            elif current_sum < target:
                left += 1
            else:
                right -= 1
        
        return []
    
    @staticmethod
    def three_sum(nums):
        """
        三数之和（找出所有和为0的三元组）
        时间复杂度：O(n²)
        """
        nums.sort()
        result = []
        n = len(nums)
        
        for i in range(n - 2):
            # 跳过重复元素
            if i > 0 and nums[i] == nums[i - 1]:
                continue
            
            left, right = i + 1, n - 1
            
            while left < right:
                total = nums[i] + nums[left] + nums[right]
                
                if total == 0:
                    result.append([nums[i], nums[left], nums[right]])
                    
                    # 跳过重复元素
                    while left < right and nums[left] == nums[left + 1]:
                        left += 1
                    while left < right and nums[right] == nums[right - 1]:
                        right -= 1
                    
                    left += 1
                    right -= 1
                elif total < 0:
                    left += 1
                else:
                    right -= 1
        
        return result
    
    @staticmethod
    def remove_duplicates(arr):
        """
        删除有序数组中的重复项
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if not arr:
            return 0
        
        # 慢指针指向下一个不重复元素的位置
        slow = 1
        
        for fast in range(1, len(arr)):
            if arr[fast] != arr[fast - 1]:
                arr[slow] = arr[fast]
                slow += 1
        
        return slow
    
    @staticmethod
    def container_with_most_water(height):
        """
        盛最多水的容器
        时间复杂度：O(n)
        """
        left, right = 0, len(height) - 1
        max_area = 0
        
        while left < right:
            # 计算当前面积
            width = right - left
            area = min(height[left], height[right]) * width
            max_area = max(max_area, area)
            
            # 移动较矮的一边
            if height[left] < height[right]:
                left += 1
            else:
                right -= 1
        
        return max_area
    
    @staticmethod
    def partition_labels(s):
        """
        划分字母区间
        使每个字母最多出现在一个片段中
        """
        # 记录每个字符最后出现的位置
        last = {c: i for i, c in enumerate(s)}
        
        result = []
        start = 0
        end = 0
        
        for i, c in enumerate(s):
            end = max(end, last[c])
            
            if i == end:
                # 找到一个片段
                result.append(end - start + 1)
                start = i + 1
        
        return result


class SlidingWindow:
    """
    滑动窗口技巧的各种应用
    """
    
    @staticmethod
    def max_sum_subarray(arr, k):
        """
        固定大小窗口的最大和
        时间复杂度：O(n)
        """
        if len(arr) < k:
            return 0
        
        # 计算第一个窗口
        window_sum = sum(arr[:k])
        max_sum = window_sum
        
        # 滑动窗口
        for i in range(k, len(arr)):
            window_sum = window_sum - arr[i - k] + arr[i]
            max_sum = max(max_sum, window_sum)
        
        return max_sum
    
    @staticmethod
    def longest_substring_without_repeating(s):
        """
        无重复字符的最长子串
        时间复杂度：O(n)
        """
        char_index = {}
        max_length = 0
        left = 0
        
        for right, char in enumerate(s):
            # 如果字符已经在窗口中
            if char in char_index and char_index[char] >= left:
                left = char_index[char] + 1
            
            char_index[char] = right
            max_length = max(max_length, right - left + 1)
        
        return max_length
    
    @staticmethod
    def min_window_substring(s, t):
        """
        最小覆盖子串
        时间复杂度：O(n)
        """
        if not s or not t:
            return ""
        
        # 统计t中字符频率
        dict_t = {}
        for char in t:
            dict_t[char] = dict_t.get(char, 0) + 1
        
        required = len(dict_t)
        left = right = 0
        formed = 0
        
        # 窗口中字符频率
        window_counts = {}
        
        # 结果
        ans = float("inf"), None, None
        
        while right < len(s):
            # 扩展窗口
            char = s[right]
            window_counts[char] = window_counts.get(char, 0) + 1
            
            if char in dict_t and window_counts[char] == dict_t[char]:
                formed += 1
            
            # 收缩窗口
            while left <= right and formed == required:
                char = s[left]
                
                # 更新结果
                if right - left + 1 < ans[0]:
                    ans = (right - left + 1, left, right)
                
                window_counts[char] -= 1
                if char in dict_t and window_counts[char] < dict_t[char]:
                    formed -= 1
                
                left += 1
            
            right += 1
        
        return "" if ans[0] == float("inf") else s[ans[1]:ans[2] + 1]
    
    @staticmethod
    def max_consecutive_ones_with_k_flips(nums, k):
        """
        最多可以翻转k个0的最长连续1
        时间复杂度：O(n)
        """
        left = 0
        zeros = 0
        max_length = 0
        
        for right in range(len(nums)):
            if nums[right] == 0:
                zeros += 1
            
            # 如果0的数量超过k，收缩窗口
            while zeros > k:
                if nums[left] == 0:
                    zeros -= 1
                left += 1
            
            max_length = max(max_length, right - left + 1)
        
        return max_length
    
    @staticmethod
    def find_anagrams(s, p):
        """
        找到字符串中所有字母异位词
        时间复杂度：O(n)
        """
        if len(s) < len(p):
            return []
        
        # 统计p中字符频率
        p_count = {}
        for char in p:
            p_count[char] = p_count.get(char, 0) + 1
        
        # 滑动窗口
        window_count = {}
        result = []
        
        # 初始化窗口
        for i in range(len(p)):
            char = s[i]
            window_count[char] = window_count.get(char, 0) + 1
        
        # 检查第一个窗口
        if window_count == p_count:
            result.append(0)
        
        # 滑动窗口
        for i in range(len(p), len(s)):
            # 添加新字符
            char_add = s[i]
            window_count[char_add] = window_count.get(char_add, 0) + 1
            
            # 删除旧字符
            char_remove = s[i - len(p)]
            window_count[char_remove] -= 1
            if window_count[char_remove] == 0:
                del window_count[char_remove]
            
            # 检查是否为异位词
            if window_count == p_count:
                result.append(i - len(p) + 1)
        
        return result
    
    @staticmethod
    def longest_subarray_with_sum_k(arr, k):
        """
        和为k的最长子数组（正数数组）
        时间复杂度：O(n)
        """
        left = 0
        current_sum = 0
        max_length = 0
        
        for right in range(len(arr)):
            current_sum += arr[right]
            
            # 收缩窗口
            while current_sum > k and left <= right:
                current_sum -= arr[left]
                left += 1
            
            if current_sum == k:
                max_length = max(max_length, right - left + 1)
        
        return max_length
    
    @staticmethod
    def min_size_subarray_sum(target, nums):
        """
        长度最小的子数组（和大于等于target）
        时间复杂度：O(n)
        """
        left = 0
        current_sum = 0
        min_length = float('inf')
        
        for right in range(len(nums)):
            current_sum += nums[right]
            
            while current_sum >= target:
                min_length = min(min_length, right - left + 1)
                current_sum -= nums[left]
                left += 1
        
        return min_length if min_length != float('inf') else 0


class AdvancedSlidingWindow:
    """
    高级滑动窗口技巧
    """
    
    @staticmethod
    def sliding_window_median(nums, k):
        """
        滑动窗口中位数
        使用两个堆维护
        时间复杂度：O(n log k)
        """
        import heapq
        
        def add_num(num, small, large):
            """添加数字到堆中"""
            if len(small) == len(large):
                heapq.heappush(large, -heapq.heappushpop(small, -num))
            else:
                heapq.heappush(small, -heapq.heappushpop(large, num))
        
        def remove_num(num, small, large):
            """从堆中删除数字"""
            if num <= -small[0]:
                small.remove(-num)
                heapq.heapify(small)
            else:
                large.remove(num)
                heapq.heapify(large)
        
        def get_median(small, large):
            """获取中位数"""
            if len(small) == len(large):
                return (-small[0] + large[0]) / 2.0
            return float(large[0])
        
        small = []  # 最大堆（存负数）
        large = []  # 最小堆
        result = []
        
        # 初始化窗口
        for i in range(k):
            add_num(nums[i], small, large)
        
        result.append(get_median(small, large))
        
        # 滑动窗口
        for i in range(k, len(nums)):
            # 删除出窗口的元素
            remove_num(nums[i - k], small, large)
            
            # 添加新元素
            add_num(nums[i], small, large)
            
            # 平衡两个堆
            if len(small) > len(large) + 1:
                heapq.heappush(large, -heapq.heappop(small))
            elif len(large) > len(small):
                heapq.heappush(small, -heapq.heappop(large))
            
            result.append(get_median(small, large))
        
        return result
    
    @staticmethod
    def count_subarrays_with_sum_k(arr, k):
        """
        和为k的子数组个数
        使用前缀和 + 哈希表
        时间复杂度：O(n)
        """
        prefix_sum = 0
        count = 0
        sum_count = {0: 1}  # 前缀和为0的个数为1
        
        for num in arr:
            prefix_sum += num
            
            # 查找是否存在前缀和为 prefix_sum - k
            if prefix_sum - k in sum_count:
                count += sum_count[prefix_sum - k]
            
            # 更新当前前缀和的计数
            sum_count[prefix_sum] = sum_count.get(prefix_sum, 0) + 1
        
        return count
```

### 4. 分治算法

```python
class DivideAndConquer:
    """
    分治算法的经典应用
    """
    
    @staticmethod
    def merge_sort_divide_conquer(arr):
        """
        归并排序（分治思想的典型应用）
        时间复杂度：O(n log n)
        """
        if len(arr) <= 1:
            return arr
        
        # 分割
        mid = len(arr) // 2
        left = DivideAndConquer.merge_sort_divide_conquer(arr[:mid])
        right = DivideAndConquer.merge_sort_divide_conquer(arr[mid:])
        
        # 合并
        return DivideAndConquer._merge(left, right)
    
    @staticmethod
    def _merge(left, right):
        """合并两个有序数组"""
        result = []
        i = j = 0
        
        while i < len(left) and j < len(right):
            if left[i] <= right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        
        result.extend(left[i:])
        result.extend(right[j:])
        return result
    
    @staticmethod
    def count_inversions(arr):
        """
        计算逆序对数量
        时间复杂度：O(n log n)
        """
        def merge_count_split_inv(left, right):
            """合并并计算分割逆序对"""
            i = j = 0
            inv_count = 0
            result = []
            
            while i < len(left) and j < len(right):
                if left[i] <= right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    inv_count += len(left) - i
                    j += 1
            
            result.extend(left[i:])
            result.extend(right[j:])
            
            return result, inv_count
        
        def count_inversions_helper(arr):
            if len(arr) <= 1:
                return arr, 0
            
            mid = len(arr) // 2
            left, left_inv = count_inversions_helper(arr[:mid])
            right, right_inv = count_inversions_helper(arr[mid:])
            merged, split_inv = merge_count_split_inv(left, right)
            
            return merged, left_inv + right_inv + split_inv
        
        _, total_inversions = count_inversions_helper(arr)
        return total_inversions
    
    @staticmethod
    def closest_pair_of_points(points):
        """
        最近点对问题
        时间复杂度：O(n log n)
        """
        import math
        
        def distance(p1, p2):
            """计算两点间距离"""
            return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
        
        def brute_force(points):
            """暴力法求解小规模问题"""
            min_dist = float('inf')
            n = len(points)
            
            for i in range(n):
                for j in range(i + 1, n):
                    min_dist = min(min_dist, distance(points[i], points[j]))
            
            return min_dist
        
        def strip_closest(strip, d):
            """在条带中查找最近点对"""
            min_dist = d
            strip.sort(key=lambda p: p[1])  # 按y坐标排序
            
            for i in range(len(strip)):
                j = i + 1
                while j < len(strip) and (strip[j][1] - strip[i][1]) < min_dist:
                    min_dist = min(min_dist, distance(strip[i], strip[j]))
                    j += 1
            
            return min_dist
        
        def closest_pair_recursive(px, py):
            """递归求解最近点对"""
            n = len(px)
            
            # 小规模问题用暴力法
            if n <= 3:
                return brute_force(px)
            
            # 分割
            mid = n // 2
            midpoint = px[mid]
            
            pyl = [p for p in py if p[0] <= midpoint[0]]
            pyr = [p for p in py if p[0] > midpoint[0]]
            
            # 递归求解
            dl = closest_pair_recursive(px[:mid], pyl)
            dr = closest_pair_recursive(px[mid:], pyr)
            
            d = min(dl, dr)
            
            # 构建条带
            strip = [p for p in py if abs(p[0] - midpoint[0]) < d]
            
            # 在条带中查找
            return min(d, strip_closest(strip, d))
        
        # 预处理：排序
        px = sorted(points, key=lambda p: p[0])
        py = sorted(points, key=lambda p: p[1])
        
        return closest_pair_recursive(px, py)
    
    @staticmethod
    def maximum_subarray(nums):
        """
        最大子数组和（分治法）
        时间复杂度：O(n log n)
        """
        def max_crossing_sum(arr, left, mid, right):
            """计算跨越中点的最大子数组和"""
            # 左侧最大和
            left_sum = float('-inf')
            sum_val = 0
            for i in range(mid, left - 1, -1):
                sum_val += arr[i]
                left_sum = max(left_sum, sum_val)
            
            # 右侧最大和
            right_sum = float('-inf')
            sum_val = 0
            for i in range(mid + 1, right + 1):
                sum_val += arr[i]
                right_sum = max(right_sum, sum_val)
            
            return left_sum + right_sum
        
        def max_subarray_helper(arr, left, right):
            """递归求解最大子数组和"""
            if left == right:
                return arr[left]
            
            mid = (left + right) // 2
            
            # 三种情况的最大值
            left_sum = max_subarray_helper(arr, left, mid)
            right_sum = max_subarray_helper(arr, mid + 1, right)
            cross_sum = max_crossing_sum(arr, left, mid, right)
            
            return max(left_sum, right_sum, cross_sum)
        
        return max_subarray_helper(nums, 0, len(nums) - 1)
    
    @staticmethod
    def matrix_multiplication_strassen(A, B):
        """
        Strassen矩阵乘法
        时间复杂度：O(n^2.807)
        """
        n = len(A)
        
        # 基础情况
        if n == 1:
            return [[A[0][0] * B[0][0]]]
        
        # 分割矩阵
        mid = n // 2
        
        # A的子矩阵
        A11 = [[A[i][j] for j in range(mid)] for i in range(mid)]
        A12 = [[A[i][j] for j in range(mid, n)] for i in range(mid)]
        A21 = [[A[i][j] for j in range(mid)] for i in range(mid, n)]
        A22 = [[A[i][j] for j in range(mid, n)] for i in range(mid, n)]
        
        # B的子矩阵
        B11 = [[B[i][j] for j in range(mid)] for i in range(mid)]
        B12 = [[B[i][j] for j in range(mid, n)] for i in range(mid)]
        B21 = [[B[i][j] for j in range(mid)] for i in range(mid, n)]
        B22 = [[B[i][j] for j in range(mid, n)] for i in range(mid, n)]
        
        # 计算7个矩阵乘积
        def add_matrix(X, Y):
            return [[X[i][j] + Y[i][j] for j in range(len(X[0]))] 
                    for i in range(len(X))]
        
        def subtract_matrix(X, Y):
            return [[X[i][j] - Y[i][j] for j in range(len(X[0]))] 
                    for i in range(len(X))]
        
        M1 = DivideAndConquer.matrix_multiplication_strassen(
            add_matrix(A11, A22), add_matrix(B11, B22)
        )
        M2 = DivideAndConquer.matrix_multiplication_strassen(
            add_matrix(A21, A22), B11
        )
        M3 = DivideAndConquer.matrix_multiplication_strassen(
            A11, subtract_matrix(B12, B22)
        )
        M4 = DivideAndConquer.matrix_multiplication_strassen(
            A22, subtract_matrix(B21, B11)
        )
        M5 = DivideAndConquer.matrix_multiplication_strassen(
            add_matrix(A11, A12), B22
        )
        M6 = DivideAndConquer.matrix_multiplication_strassen(
            subtract_matrix(A21, A11), add_matrix(B11, B12)
        )
        M7 = DivideAndConquer.matrix_multiplication_strassen(
            subtract_matrix(A12, A22), add_matrix(B21, B22)
        )
        
        # 计算结果矩阵的子矩阵
        C11 = add_matrix(subtract_matrix(add_matrix(M1, M4), M5), M7)
        C12 = add_matrix(M3, M5)
        C21 = add_matrix(M2, M4)
        C22 = add_matrix(subtract_matrix(add_matrix(M1, M3), M2), M6)
        
        # 组合结果
        C = [[0] * n for _ in range(n)]
        for i in range(mid):
            for j in range(mid):
                C[i][j] = C11[i][j]
                C[i][j + mid] = C12[i][j]
                C[i + mid][j] = C21[i][j]
                C[i + mid][j + mid] = C22[i][j]
        
        return C
    
    @staticmethod
    def kth_smallest_element(arr, k):
        """
        第k小元素（快速选择算法）
        时间复杂度：平均O(n)，最坏O(n²)
        """
        def partition(arr, left, right):
            """分区函数"""
            pivot = arr[right]
            i = left - 1
            
            for j in range(left, right):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[right] = arr[right], arr[i + 1]
            return i + 1
        
        def quick_select(arr, left, right, k):
            """快速选择"""
            if left == right:
                return arr[left]
            
            pivot_index = partition(arr, left, right)
            
            if k == pivot_index:
                return arr[k]
            elif k < pivot_index:
                return quick_select(arr, left, pivot_index - 1, k)
            else:
                return quick_select(arr, pivot_index + 1, right, k)
        
        return quick_select(arr, 0, len(arr) - 1, k - 1)


class TournamentMethod:
    """
    锦标赛方法（分治思想的应用）
    """
    
    @staticmethod
    def find_min_max(arr):
        """
        同时找到最小值和最大值
        比较次数：3n/2 - 2
        """
        def min_max_helper(arr, left, right):
            # 只有一个元素
            if left == right:
                return arr[left], arr[left]
            
            # 有两个元素
            if right - left == 1:
                if arr[left] < arr[right]:
                    return arr[left], arr[right]
                else:
                    return arr[right], arr[left]
            
            # 分治
            mid = (left + right) // 2
            min1, max1 = min_max_helper(arr, left, mid)
            min2, max2 = min_max_helper(arr, mid + 1, right)
            
            return min(min1, min2), max(max1, max2)
        
        if not arr:
            return None, None
        
        return min_max_helper(arr, 0, len(arr) - 1)
    
    @staticmethod
    def find_second_minimum(arr):
        """
        找到第二小的元素
        使用锦标赛树
        """
        if len(arr) < 2:
            return None
        
        # 构建锦标赛树
        n = len(arr)
        tree = {}
        
        # 初始化叶子节点
        for i in range(n):
            tree[(0, i)] = (arr[i], [])
        
        # 构建树
        level = 0
        while (1 << level) < n:
            for i in range(0, n - (1 << level), 1 << (level + 1)):
                left = tree[(level, i)]
                right = tree[(level, i + (1 << level))]
                
                if left[0] < right[0]:
                    # 左边赢，记录右边作为候选
                    tree[(level + 1, i)] = (left[0], left[1] + [right[0]])
                else:
                    # 右边赢，记录左边作为候选
                    tree[(level + 1, i)] = (right[0], right[1] + [left[0]])
            
            level += 1
        
        # 最小值的候选列表中找第二小
        min_val, candidates = tree[(level, 0)]
        return min(candidates) if candidates else None
```

### 5. 递归与回溯

```python
class RecursionBasics:
    """
    递归算法基础
    """
    
    @staticmethod
    def factorial(n):
        """
        阶乘（递归实现）
        时间复杂度：O(n)
        空间复杂度：O(n) 递归调用栈
        """
        if n <= 1:
            return 1
        return n * RecursionBasics.factorial(n - 1)
    
    @staticmethod
    def fibonacci(n):
        """
        斐波那契数列（递归实现）
        时间复杂度：O(2^n) 未优化
        """
        if n <= 1:
            return n
        return RecursionBasics.fibonacci(n - 1) + RecursionBasics.fibonacci(n - 2)
    
    @staticmethod
    def fibonacci_memo(n, memo=None):
        """
        斐波那契数列（带记忆化的递归）
        时间复杂度：O(n)
        空间复杂度：O(n)
        """
        if memo is None:
            memo = {}
        
        if n in memo:
            return memo[n]
        
        if n <= 1:
            return n
        
        memo[n] = RecursionBasics.fibonacci_memo(n - 1, memo) + \
                  RecursionBasics.fibonacci_memo(n - 2, memo)
        return memo[n]
    
    @staticmethod
    def tower_of_hanoi(n, source, target, auxiliary):
        """
        汉诺塔问题
        时间复杂度：O(2^n)
        """
        if n == 1:
            print(f"Move disk 1 from {source} to {target}")
            return
        
        # 将n-1个盘子从源移到辅助
        RecursionBasics.tower_of_hanoi(n - 1, source, auxiliary, target)
        
        # 将最大的盘子从源移到目标
        print(f"Move disk {n} from {source} to {target}")
        
        # 将n-1个盘子从辅助移到目标
        RecursionBasics.tower_of_hanoi(n - 1, auxiliary, target, source)
    
    @staticmethod
    def power(x, n):
        """
        快速幂（递归实现）
        时间复杂度：O(log n)
        """
        if n == 0:
            return 1
        
        if n < 0:
            return 1 / RecursionBasics.power(x, -n)
        
        if n % 2 == 0:
            half = RecursionBasics.power(x, n // 2)
            return half * half
        else:
            return x * RecursionBasics.power(x, n - 1)
    
    @staticmethod
    def generate_parentheses(n):
        """
        生成所有有效的括号组合
        时间复杂度：O(4^n / sqrt(n)) 卡特兰数
        """
        result = []
        
        def backtrack(current, open_count, close_count):
            # 基础情况：生成了n对括号
            if len(current) == 2 * n:
                result.append(current)
                return
            
            # 可以添加左括号
            if open_count < n:
                backtrack(current + "(", open_count + 1, close_count)
            
            # 可以添加右括号
            if close_count < open_count:
                backtrack(current + ")", open_count, close_count + 1)
        
        backtrack("", 0, 0)
        return result


class BacktrackingAlgorithms:
    """
    回溯算法的经典应用
    """
    
    @staticmethod
    def permutations(nums):
        """
        全排列
        时间复杂度：O(n! * n)
        空间复杂度：O(n)
        """
        result = []
        
        def backtrack(path, remaining):
            # 基础情况：没有剩余元素
            if not remaining:
                result.append(path[:])  # 深拷贝
                return
            
            # 尝试每个剩余元素
            for i in range(len(remaining)):
                # 选择
                path.append(remaining[i])
                
                # 递归
                backtrack(path, remaining[:i] + remaining[i+1:])
                
                # 撤销选择
                path.pop()
        
        backtrack([], nums)
        return result
    
    @staticmethod
    def permutations_no_duplicates(nums):
        """
        无重复全排列
        时间复杂度：O(n! * n)
        """
        nums.sort()  # 排序以便处理重复
        result = []
        used = [False] * len(nums)
        
        def backtrack(path):
            if len(path) == len(nums):
                result.append(path[:])
                return
            
            for i in range(len(nums)):
                # 跳过已使用的元素
                if used[i]:
                    continue
                
                # 跳过重复元素
                if i > 0 and nums[i] == nums[i-1] and not used[i-1]:
                    continue
                
                # 选择
                path.append(nums[i])
                used[i] = True
                
                # 递归
                backtrack(path)
                
                # 撤销
                path.pop()
                used[i] = False
        
        backtrack([])
        return result
    
    @staticmethod
    def combinations(n, k):
        """
        组合
        时间复杂度：O(C(n,k) * k)
        """
        result = []
        
        def backtrack(start, path):
            # 找到一个组合
            if len(path) == k:
                result.append(path[:])
                return
            
            # 剪枝：剩余元素不足
            if k - len(path) > n - start + 1:
                return
            
            for i in range(start, n + 1):
                path.append(i)
                backtrack(i + 1, path)
                path.pop()
        
        backtrack(1, [])
        return result
    
    @staticmethod
    def combination_sum(candidates, target):
        """
        组合总和（可重复使用元素）
        时间复杂度：O(2^n)
        """
        result = []
        
        def backtrack(remain, combo, start):
            if remain == 0:
                result.append(combo[:])
                return
            
            if remain < 0:
                return
            
            for i in range(start, len(candidates)):
                combo.append(candidates[i])
                # 注意：i不增加，因为可以重复使用
                backtrack(remain - candidates[i], combo, i)
                combo.pop()
        
        backtrack(target, [], 0)
        return result
    
    @staticmethod
    def subsets(nums):
        """
        子集
        时间复杂度：O(2^n * n)
        """
        result = []
        
        def backtrack(start, path):
            # 每个节点都是一个子集
            result.append(path[:])
            
            for i in range(start, len(nums)):
                path.append(nums[i])
                backtrack(i + 1, path)
                path.pop()
        
        backtrack(0, [])
        return result
    
    @staticmethod
    def n_queens(n):
        """
        N皇后问题
        时间复杂度：O(n!)
        """
        def is_safe(board, row, col):
            """检查位置是否安全"""
            # 检查列
            for i in range(row):
                if board[i][col] == 'Q':
                    return False
            
            # 检查左上对角线
            i, j = row - 1, col - 1
            while i >= 0 and j >= 0:
                if board[i][j] == 'Q':
                    return False
                i -= 1
                j -= 1
            
            # 检查右上对角线
            i, j = row - 1, col + 1
            while i >= 0 and j < n:
                if board[i][j] == 'Q':
                    return False
                i -= 1
                j += 1
            
            return True
        
        def backtrack(board, row):
            if row == n:
                # 找到一个解
                result.append([''.join(row) for row in board])
                return
            
            for col in range(n):
                if is_safe(board, row, col):
                    board[row][col] = 'Q'
                    backtrack(board, row + 1)
                    board[row][col] = '.'
        
        result = []
        board = [['.' for _ in range(n)] for _ in range(n)]
        backtrack(board, 0)
        return result
    
    @staticmethod
    def sudoku_solver(board):
        """
        数独求解器
        时间复杂度：O(9^m) m为空格数
        """
        def is_valid(board, row, col, num):
            """检查数字是否有效"""
            # 检查行
            for j in range(9):
                if board[row][j] == num:
                    return False
            
            # 检查列
            for i in range(9):
                if board[i][col] == num:
                    return False
            
            # 检查3x3宫格
            start_row = (row // 3) * 3
            start_col = (col // 3) * 3
            for i in range(3):
                for j in range(3):
                    if board[start_row + i][start_col + j] == num:
                        return False
            
            return True
        
        def solve():
            # 找到空格
            for i in range(9):
                for j in range(9):
                    if board[i][j] == '.':
                        # 尝试1-9
                        for num in '123456789':
                            if is_valid(board, i, j, num):
                                board[i][j] = num
                                
                                if solve():
                                    return True
                                
                                # 回溯
                                board[i][j] = '.'
                        
                        return False
            
            return True  # 所有格子都填满了
        
        solve()
        return board
    
    @staticmethod
    def word_search(board, word):
        """
        单词搜索
        时间复杂度：O(m*n*4^L) L为单词长度
        """
        if not board or not board[0]:
            return False
        
        rows, cols = len(board), len(board[0])
        
        def dfs(i, j, k):
            """DFS搜索"""
            if k == len(word):
                return True
            
            if (i < 0 or i >= rows or j < 0 or j >= cols or 
                board[i][j] != word[k]):
                return False
            
            # 标记已访问
            temp = board[i][j]
            board[i][j] = '#'
            
            # 四个方向搜索
            found = (dfs(i+1, j, k+1) or dfs(i-1, j, k+1) or 
                    dfs(i, j+1, k+1) or dfs(i, j-1, k+1))
            
            # 恢复
            board[i][j] = temp
            
            return found
        
        # 从每个位置开始尝试
        for i in range(rows):
            for j in range(cols):
                if dfs(i, j, 0):
                    return True
        
        return False


class AdvancedBacktracking:
    """
    高级回溯技巧
    """
    
    @staticmethod
    def solve_crossword(board, words):
        """
        填字游戏求解
        """
        rows, cols = len(board), len(board[0])
        
        def can_place_horizontal(word, row, col):
            """检查是否可以水平放置单词"""
            if col + len(word) > cols:
                return False
            
            for i, char in enumerate(word):
                if board[row][col + i] not in ('.', char):
                    return False
            
            return True
        
        def can_place_vertical(word, row, col):
            """检查是否可以垂直放置单词"""
            if row + len(word) > rows:
                return False
            
            for i, char in enumerate(word):
                if board[row + i][col] not in ('.', char):
                    return False
            
            return True
        
        def place_horizontal(word, row, col):
            """水平放置单词"""
            old = []
            for i, char in enumerate(word):
                old.append(board[row][col + i])
                board[row][col + i] = char
            return old
        
        def place_vertical(word, row, col):
            """垂直放置单词"""
            old = []
            for i, char in enumerate(word):
                old.append(board[row + i][col])
                board[row + i][col] = char
            return old
        
        def remove_horizontal(word, row, col, old):
            """移除水平单词"""
            for i in range(len(word)):
                board[row][col + i] = old[i]
        
        def remove_vertical(word, row, col, old):
            """移除垂直单词"""
            for i in range(len(word)):
                board[row + i][col] = old[i]
        
        def solve(word_index):
            if word_index == len(words):
                return True
            
            word = words[word_index]
            
            # 尝试所有位置
            for row in range(rows):
                for col in range(cols):
                    # 尝试水平放置
                    if can_place_horizontal(word, row, col):
                        old = place_horizontal(word, row, col)
                        if solve(word_index + 1):
                            return True
                        remove_horizontal(word, row, col, old)
                    
                    # 尝试垂直放置
                    if can_place_vertical(word, row, col):
                        old = place_vertical(word, row, col)
                        if solve(word_index + 1):
                            return True
                        remove_vertical(word, row, col, old)
            
            return False
        
        solve(0)
        return board
    
    @staticmethod
    def generate_maze(rows, cols):
        """
        迷宫生成（使用回溯法）
        """
        import random
        
        # 初始化迷宫（所有墙都存在）
        maze = [[1 for _ in range(2 * cols + 1)] for _ in range(2 * rows + 1)]
        
        # 设置起点和终点
        for i in range(1, 2 * rows, 2):
            for j in range(1, 2 * cols, 2):
                maze[i][j] = 0
        
        def get_neighbors(r, c):
            """获取未访问的邻居"""
            neighbors = []
            directions = [(0, 2), (2, 0), (0, -2), (-2, 0)]
            
            for dr, dc in directions:
                nr, nc = r + dr, c + dc
                if (1 <= nr < 2 * rows and 1 <= nc < 2 * cols and 
                    maze[nr][nc] == 0):
                    neighbors.append((nr, nc, dr, dc))
            
            return neighbors
        
        def carve_path(r, c):
            """雕刻路径"""
            maze[r][c] = 2  # 标记为已访问
            
            neighbors = get_neighbors(r, c)
            random.shuffle(neighbors)
            
            for nr, nc, dr, dc in neighbors:
                if maze[nr][nc] == 0:  # 未访问
                    # 打通墙
                    maze[r + dr // 2][c + dc // 2] = 0
                    carve_path(nr, nc)
        
        # 从起点开始生成
        carve_path(1, 1)
        
        # 清理访问标记
        for i in range(1, 2 * rows, 2):
            for j in range(1, 2 * cols, 2):
                if maze[i][j] == 2:
                    maze[i][j] = 0
        
        return maze
```

### 6. 贪心算法

```python
class GreedyAlgorithms:
    """
    贪心算法的经典应用
    """
    
    @staticmethod
    def activity_selection(activities):
        """
        活动选择问题
        activities: [(start, end), ...]
        时间复杂度：O(n log n)
        """
        # 按结束时间排序
        activities.sort(key=lambda x: x[1])
        
        selected = [activities[0]]
        last_end = activities[0][1]
        
        for i in range(1, len(activities)):
            # 如果当前活动的开始时间大于等于上一个活动的结束时间
            if activities[i][0] >= last_end:
                selected.append(activities[i])
                last_end = activities[i][1]
        
        return selected
    
    @staticmethod
    def fractional_knapsack(capacity, items):
        """
        分数背包问题
        items: [(value, weight), ...]
        时间复杂度：O(n log n)
        """
        # 计算单位价值并排序
        value_per_weight = [(v/w, v, w) for v, w in items]
        value_per_weight.sort(reverse=True)
        
        total_value = 0
        remaining_capacity = capacity
        
        for vpw, value, weight in value_per_weight:
            if remaining_capacity >= weight:
                # 完全装入
                total_value += value
                remaining_capacity -= weight
            else:
                # 部分装入
                total_value += vpw * remaining_capacity
                break
        
        return total_value
    
    @staticmethod
    def huffman_coding(frequencies):
        """
        霍夫曼编码
        frequencies: {'char': freq, ...}
        时间复杂度：O(n log n)
        """
        import heapq
        
        class Node:
            def __init__(self, char=None, freq=0, left=None, right=None):
                self.char = char
                self.freq = freq
                self.left = left
                self.right = right
            
            def __lt__(self, other):
                return self.freq < other.freq
        
        # 构建最小堆
        heap = []
        for char, freq in frequencies.items():
            heapq.heappush(heap, Node(char, freq))
        
        # 构建霍夫曼树
        while len(heap) > 1:
            left = heapq.heappop(heap)
            right = heapq.heappop(heap)
            
            parent = Node(freq=left.freq + right.freq, left=left, right=right)
            heapq.heappush(heap, parent)
        
        # 生成编码
        codes = {}
        
        def generate_codes(node, code=""):
            if node.char:  # 叶子节点
                codes[node.char] = code
                return
            
            if node.left:
                generate_codes(node.left, code + "0")
            if node.right:
                generate_codes(node.right, code + "1")
        
        root = heap[0]
        generate_codes(root)
        
        return codes
    
    @staticmethod
    def job_scheduling(jobs):
        """
        作业调度问题（最大化利润）
        jobs: [(deadline, profit), ...]
        时间复杂度：O(n²)
        """
        # 按利润降序排序
        jobs.sort(key=lambda x: x[1], reverse=True)
        
        # 找到最大截止时间
        max_deadline = max(job[0] for job in jobs)
        
        # 时间槽
        slots = [-1] * (max_deadline + 1)
        total_profit = 0
        scheduled_jobs = []
        
        for deadline, profit in jobs:
            # 从截止时间开始向前找空闲时间槽
            for t in range(min(deadline, max_deadline), 0, -1):
                if slots[t] == -1:
                    slots[t] = len(scheduled_jobs)
                    scheduled_jobs.append((deadline, profit))
                    total_profit += profit
                    break
        
        return scheduled_jobs, total_profit
    
    @staticmethod
    def minimum_spanning_tree_kruskal(edges, n):
        """
        Kruskal最小生成树算法（贪心）
        edges: [(u, v, weight), ...]
        时间复杂度：O(E log E)
        """
        # 并查集
        parent = list(range(n))
        
        def find(x):
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent[px] = py
                return True
            return False
        
        # 按权重排序
        edges.sort(key=lambda x: x[2])
        
        mst = []
        total_weight = 0
        
        for u, v, weight in edges:
            if union(u, v):
                mst.append((u, v, weight))
                total_weight += weight
                
                if len(mst) == n - 1:
                    break
        
        return mst, total_weight
    
    @staticmethod
    def dijkstra_shortest_path(graph, start):
        """
        Dijkstra最短路径算法（贪心）
        graph: {node: [(neighbor, weight), ...]}
        时间复杂度：O((V + E) log V)
        """
        import heapq
        
        distances = {node: float('inf') for node in graph}
        distances[start] = 0
        
        pq = [(0, start)]
        visited = set()
        
        while pq:
            curr_dist, curr_node = heapq.heappop(pq)
            
            if curr_node in visited:
                continue
            
            visited.add(curr_node)
            
            for neighbor, weight in graph[curr_node]:
                distance = curr_dist + weight
                
                if distance < distances[neighbor]:
                    distances[neighbor] = distance
                    heapq.heappush(pq, (distance, neighbor))
        
        return distances
    
    @staticmethod
    def gas_station(gas, cost):
        """
        加油站问题
        gas[i]: 在i站获得的油量
        cost[i]: 从i站到i+1站的油耗
        时间复杂度：O(n)
        """
        n = len(gas)
        total_gas = sum(gas)
        total_cost = sum(cost)
        
        # 如果总油量小于总消耗，无解
        if total_gas < total_cost:
            return -1
        
        start = 0
        tank = 0
        
        for i in range(n):
            tank += gas[i] - cost[i]
            
            # 如果油箱空了，从下一站重新开始
            if tank < 0:
                start = i + 1
                tank = 0
        
        return start
    
    @staticmethod
    def jump_game(nums):
        """
        跳跃游戏（最少跳跃次数）
        时间复杂度：O(n)
        """
        n = len(nums)
        if n <= 1:
            return 0
        
        jumps = 0
        current_end = 0
        farthest = 0
        
        for i in range(n - 1):
            farthest = max(farthest, i + nums[i])
            
            if i == current_end:
                jumps += 1
                current_end = farthest
                
                if current_end >= n - 1:
                    break
        
        return jumps


class IntervalGreedy:
    """
    区间相关的贪心算法
    """
    
    @staticmethod
    def merge_intervals(intervals):
        """
        合并区间
        时间复杂度：O(n log n)
        """
        if not intervals:
            return []
        
        # 按起始位置排序
        intervals.sort(key=lambda x: x[0])
        
        merged = [intervals[0]]
        
        for current in intervals[1:]:
            last = merged[-1]
            
            # 如果有重叠，合并
            if current[0] <= last[1]:
                merged[-1] = [last[0], max(last[1], current[1])]
            else:
                merged.append(current)
        
        return merged
    
    @staticmethod
    def interval_partitioning(intervals):
        """
        区间分组（最少会议室）
        时间复杂度：O(n log n)
        """
        import heapq
        
        if not intervals:
            return 0
        
        # 按开始时间排序
        intervals.sort(key=lambda x: x[0])
        
        # 最小堆存储每个会议室的结束时间
        rooms = []
        heapq.heappush(rooms, intervals[0][1])
        
        for i in range(1, len(intervals)):
            # 如果当前会议可以使用最早结束的会议室
            if intervals[i][0] >= rooms[0]:
                heapq.heappop(rooms)
            
            # 分配会议室
            heapq.heappush(rooms, intervals[i][1])
        
        return len(rooms)
    
    @staticmethod
    def non_overlapping_intervals(intervals):
        """
        无重叠区间（移除最少区间数）
        时间复杂度：O(n log n)
        """
        if not intervals:
            return 0
        
        # 按结束时间排序
        intervals.sort(key=lambda x: x[1])
        
        count = 1  # 保留的区间数
        end = intervals[0][1]
        
        for i in range(1, len(intervals)):
            if intervals[i][0] >= end:
                count += 1
                end = intervals[i][1]
        
        return len(intervals) - count


class StringGreedy:
    """
    字符串相关的贪心算法
    """
    
    @staticmethod
    def remove_duplicate_letters(s):
        """
        去除重复字母（保持字典序最小）
        时间复杂度：O(n)
        """
        # 统计每个字符的出现次数
        count = {}
        for char in s:
            count[char] = count.get(char, 0) + 1
        
        # 记录字符是否在栈中
        in_stack = set()
        stack = []
        
        for char in s:
            count[char] -= 1
            
            if char in in_stack:
                continue
            
            # 如果栈顶字符大于当前字符，且后面还会出现
            while stack and stack[-1] > char and count[stack[-1]] > 0:
                removed = stack.pop()
                in_stack.remove(removed)
            
            stack.append(char)
            in_stack.add(char)
        
        return ''.join(stack)
    
    @staticmethod
    def partition_labels(s):
        """
        划分字母区间
        时间复杂度：O(n)
        """
        # 记录每个字符最后出现的位置
        last_occurrence = {}
        for i, char in enumerate(s):
            last_occurrence[char] = i
        
        partitions = []
        start = 0
        end = 0
        
        for i, char in enumerate(s):
            end = max(end, last_occurrence[char])
            
            if i == end:
                partitions.append(end - start + 1)
                start = i + 1
        
        return partitions
    
    @staticmethod
    def reorganize_string(s):
        """
        重构字符串（相邻字符不同）
        时间复杂度：O(n log k) k为字符种类数
        """
        import heapq
        from collections import Counter
        
        # 统计字符频率
        count = Counter(s)
        
        # 检查是否可能
        max_count = max(count.values())
        if max_count > (len(s) + 1) // 2:
            return ""
        
        # 最大堆（使用负数）
        heap = [(-freq, char) for char, freq in count.items()]
        heapq.heapify(heap)
        
        result = []
        prev_freq, prev_char = 0, ''
        
        while heap:
            freq, char = heapq.heappop(heap)
            result.append(char)
            
            # 将之前的字符放回堆中
            if prev_freq < 0:
                heapq.heappush(heap, (prev_freq, prev_char))
            
            # 更新频率
            prev_freq, prev_char = freq + 1, char
        
        return ''.join(result)
```

### 7. 动态规划

```python
class DynamicProgrammingBasics:
    """
    动态规划基础问题
    """
    
    @staticmethod
    def fibonacci_dp(n):
        """
        斐波那契数列（动态规划）
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if n <= 1:
            return n
        
        prev2, prev1 = 0, 1
        
        for i in range(2, n + 1):
            current = prev1 + prev2
            prev2 = prev1
            prev1 = current
        
        return prev1
    
    @staticmethod
    def climbing_stairs(n):
        """
        爬楼梯问题
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if n <= 2:
            return n
        
        prev2, prev1 = 1, 2
        
        for i in range(3, n + 1):
            current = prev1 + prev2
            prev2 = prev1
            prev1 = current
        
        return prev1
    
    @staticmethod
    def house_robber(nums):
        """
        打家劫舍
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        if not nums:
            return 0
        if len(nums) == 1:
            return nums[0]
        
        prev2 = nums[0]
        prev1 = max(nums[0], nums[1])
        
        for i in range(2, len(nums)):
            current = max(prev1, prev2 + nums[i])
            prev2 = prev1
            prev1 = current
        
        return prev1
    
    @staticmethod
    def maximum_subarray(nums):
        """
        最大子数组和（Kadane算法）
        时间复杂度：O(n)
        空间复杂度：O(1)
        """
        max_sum = current_sum = nums[0]
        
        for num in nums[1:]:
            current_sum = max(num, current_sum + num)
            max_sum = max(max_sum, current_sum)
        
        return max_sum
    
    @staticmethod
    def coin_change(coins, amount):
        """
        零钱兑换（最少硬币数）
        时间复杂度：O(amount * len(coins))
        空间复杂度：O(amount)
        """
        dp = [float('inf')] * (amount + 1)
        dp[0] = 0
        
        for i in range(1, amount + 1):
            for coin in coins:
                if coin <= i:
                    dp[i] = min(dp[i], dp[i - coin] + 1)
        
        return dp[amount] if dp[amount] != float('inf') else -1
    
    @staticmethod
    def unique_paths(m, n):
        """
        不同路径
        时间复杂度：O(m * n)
        空间复杂度：O(n)
        """
        dp = [1] * n
        
        for i in range(1, m):
            for j in range(1, n):
                dp[j] += dp[j - 1]
        
        return dp[n - 1]
    
    @staticmethod
    def min_path_sum(grid):
        """
        最小路径和
        时间复杂度：O(m * n)
        空间复杂度：O(1) 原地修改
        """
        if not grid or not grid[0]:
            return 0
        
        m, n = len(grid), len(grid[0])
        
        # 第一行
        for j in range(1, n):
            grid[0][j] += grid[0][j - 1]
        
        # 第一列
        for i in range(1, m):
            grid[i][0] += grid[i - 1][0]
        
        # 其余位置
        for i in range(1, m):
            for j in range(1, n):
                grid[i][j] += min(grid[i - 1][j], grid[i][j - 1])
        
        return grid[m - 1][n - 1]


class SequenceDynamicProgramming:
    """
    序列相关的动态规划
    """
    
    @staticmethod
    def longest_increasing_subsequence(nums):
        """
        最长递增子序列
        时间复杂度：O(n²)
        """
        if not nums:
            return 0
        
        n = len(nums)
        dp = [1] * n
        
        for i in range(1, n):
            for j in range(i):
                if nums[j] < nums[i]:
                    dp[i] = max(dp[i], dp[j] + 1)
        
        return max(dp)
    
    @staticmethod
    def lis_binary_search(nums):
        """
        最长递增子序列（二分查找优化）
        时间复杂度：O(n log n)
        """
        if not nums:
            return 0
        
        # tails[i]表示长度为i+1的递增子序列的最小尾部元素
        tails = []
        
        for num in nums:
            # 二分查找插入位置
            left, right = 0, len(tails)
            
            while left < right:
                mid = (left + right) // 2
                if tails[mid] < num:
                    left = mid + 1
                else:
                    right = mid
            
            # 更新或添加
            if left == len(tails):
                tails.append(num)
            else:
                tails[left] = num
        
        return len(tails)
    
    @staticmethod
    def longest_common_subsequence(text1, text2):
        """
        最长公共子序列
        时间复杂度：O(m * n)
        空间复杂度：O(m * n)
        """
        m, n = len(text1), len(text2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if text1[i - 1] == text2[j - 1]:
                    dp[i][j] = dp[i - 1][j - 1] + 1
                else:
                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
        
        return dp[m][n]
    
    @staticmethod
    def edit_distance(word1, word2):
        """
        编辑距离
        时间复杂度：O(m * n)
        空间复杂度：O(m * n)
        """
        m, n = len(word1), len(word2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        # 初始化
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        
        # 填充DP表
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if word1[i - 1] == word2[j - 1]:
                    dp[i][j] = dp[i - 1][j - 1]
                else:
                    dp[i][j] = 1 + min(
                        dp[i - 1][j],      # 删除
                        dp[i][j - 1],      # 插入
                        dp[i - 1][j - 1]   # 替换
                    )
        
        return dp[m][n]
    
    @staticmethod
    def palindromic_substrings(s):
        """
        回文子串数量
        时间复杂度：O(n²)
        """
        n = len(s)
        dp = [[False] * n for _ in range(n)]
        count = 0
        
        # 单个字符
        for i in range(n):
            dp[i][i] = True
            count += 1
        
        # 两个字符
        for i in range(n - 1):
            if s[i] == s[i + 1]:
                dp[i][i + 1] = True
                count += 1
        
        # 三个及以上字符
        for length in range(3, n + 1):
            for i in range(n - length + 1):
                j = i + length - 1
                if s[i] == s[j] and dp[i + 1][j - 1]:
                    dp[i][j] = True
                    count += 1
        
        return count
    
    @staticmethod
    def longest_palindromic_subsequence(s):
        """
        最长回文子序列
        时间复杂度：O(n²)
        """
        n = len(s)
        dp = [[0] * n for _ in range(n)]
        
        # 单个字符
        for i in range(n):
            dp[i][i] = 1
        
        # 从短到长
        for length in range(2, n + 1):
            for i in range(n - length + 1):
                j = i + length - 1
                
                if s[i] == s[j]:
                    dp[i][j] = dp[i + 1][j - 1] + 2
                else:
                    dp[i][j] = max(dp[i + 1][j], dp[i][j - 1])
        
        return dp[0][n - 1]


class KnapsackProblems:
    """
    背包问题系列
    """
    
    @staticmethod
    def knapsack_01(weights, values, capacity):
        """
        0/1背包问题
        时间复杂度：O(n * capacity)
        空间复杂度：O(capacity)
        """
        n = len(weights)
        dp = [0] * (capacity + 1)
        
        for i in range(n):
            # 从后向前遍历，避免重复使用
            for w in range(capacity, weights[i] - 1, -1):
                dp[w] = max(dp[w], dp[w - weights[i]] + values[i])
        
        return dp[capacity]
    
    @staticmethod
    def knapsack_unbounded(weights, values, capacity):
        """
        完全背包问题
        时间复杂度：O(n * capacity)
        空间复杂度：O(capacity)
        """
        n = len(weights)
        dp = [0] * (capacity + 1)
        
        for i in range(n):
            # 从前向后遍历，允许重复使用
            for w in range(weights[i], capacity + 1):
                dp[w] = max(dp[w], dp[w - weights[i]] + values[i])
        
        return dp[capacity]
    
    @staticmethod
    def knapsack_multiple(weights, values, counts, capacity):
        """
        多重背包问题
        时间复杂度：O(capacity * Σcounts[i])
        """
        n = len(weights)
        dp = [0] * (capacity + 1)
        
        for i in range(n):
            # 二进制优化
            k = 1
            while k <= counts[i]:
                # 当作0/1背包处理
                for w in range(capacity, k * weights[i] - 1, -1):
                    dp[w] = max(dp[w], dp[w - k * weights[i]] + k * values[i])
                
                counts[i] -= k
                k *= 2
            
            # 处理剩余的
            if counts[i] > 0:
                for w in range(capacity, counts[i] * weights[i] - 1, -1):
                    dp[w] = max(dp[w], 
                               dp[w - counts[i] * weights[i]] + counts[i] * values[i])
        
        return dp[capacity]
    
    @staticmethod
    def partition_equal_subset_sum(nums):
        """
        分割等和子集
        时间复杂度：O(n * sum)
        """
        total_sum = sum(nums)
        
        # 如果总和为奇数，不能分割
        if total_sum % 2 != 0:
            return False
        
        target = total_sum // 2
        dp = [False] * (target + 1)
        dp[0] = True
        
        for num in nums:
            for j in range(target, num - 1, -1):
                dp[j] = dp[j] or dp[j - num]
        
        return dp[target]
    
    @staticmethod
    def target_sum(nums, target):
        """
        目标和（添加正负号）
        时间复杂度：O(n * sum)
        """
        total_sum = sum(nums)
        
        # 转换为子集和问题
        # sum(P) - sum(N) = target
        # sum(P) + sum(N) = sum(nums)
        # 2 * sum(P) = target + sum(nums)
        
        if (target + total_sum) % 2 != 0 or target > total_sum:
            return 0
        
        subset_sum = (target + total_sum) // 2
        
        if subset_sum < 0:
            return 0
        
        dp = [0] * (subset_sum + 1)
        dp[0] = 1
        
        for num in nums:
            for j in range(subset_sum, num - 1, -1):
                dp[j] += dp[j - num]
        
        return dp[subset_sum]


class IntervalDynamicProgramming:
    """
    区间动态规划
    """
    
    @staticmethod
    def burst_balloons(nums):
        """
        戳气球
        时间复杂度：O(n³)
        空间复杂度：O(n²)
        """
        # 添加虚拟气球
        balloons = [1] + nums + [1]
        n = len(balloons)
        
        # dp[i][j]表示戳破(i,j)之间所有气球的最大硬币数
        dp = [[0] * n for _ in range(n)]
        
        # 枚举区间长度
        for length in range(1, n - 1):
            for left in range(n - length - 1):
                right = left + length + 1
                
                # 枚举最后戳破的气球
                for k in range(left + 1, right):
                    coins = (balloons[left] * balloons[k] * balloons[right] +
                            dp[left][k] + dp[k][right])
                    dp[left][right] = max(dp[left][right], coins)
        
        return dp[0][n - 1]
    
    @staticmethod
    def matrix_chain_multiplication(dimensions):
        """
        矩阵链乘法
        dimensions[i]表示第i个矩阵的行数，dimensions[i+1]表示列数
        时间复杂度：O(n³)
        """
        n = len(dimensions) - 1
        dp = [[0] * n for _ in range(n)]
        
        # 枚举链长度
        for length in range(2, n + 1):
            for i in range(n - length + 1):
                j = i + length - 1
                dp[i][j] = float('inf')
                
                # 枚举分割点
                for k in range(i, j):
                    cost = (dp[i][k] + dp[k + 1][j] + 
                           dimensions[i] * dimensions[k + 1] * dimensions[j + 1])
                    dp[i][j] = min(dp[i][j], cost)
        
        return dp[0][n - 1]
    
    @staticmethod
    def stone_game(stones):
        """
        石子游戏
        时间复杂度：O(n²)
        """
        n = len(stones)
        
        # dp[i][j]表示从i到j先手比后手多的分数
        dp = [[0] * n for _ in range(n)]
        
        # 基础情况：只有一堆石子
        for i in range(n):
            dp[i][i] = stones[i]
        
        # 枚举区间长度
        for length in range(2, n + 1):
            for i in range(n - length + 1):
                j = i + length - 1
                dp[i][j] = max(
                    stones[i] - dp[i + 1][j],
                    stones[j] - dp[i][j - 1]
                )
        
        return dp[0][n - 1] > 0


class TreeDynamicProgramming:
    """
    树形动态规划
    """
    
    @staticmethod
    def house_robber_iii(root):
        """
        打家劫舍III（树形）
        时间复杂度：O(n)
        """
        def rob_tree(node):
            if not node:
                return 0, 0
            
            left_rob, left_not_rob = rob_tree(node.left)
            right_rob, right_not_rob = rob_tree(node.right)
            
            # 抢劫当前节点
            rob = node.val + left_not_rob + right_not_rob
            
            # 不抢劫当前节点
            not_rob = max(left_rob, left_not_rob) + max(right_rob, right_not_rob)
            
            return rob, not_rob
        
        return max(rob_tree(root))
    
    @staticmethod
    def binary_tree_cameras(root):
        """
        监控二叉树
        时间复杂度：O(n)
        """
        def dfs(node):
            if not node:
                return 0, 0, float('inf')
            
            # 左子树
            l_uncovered, l_covered, l_camera = dfs(node.left)
            # 右子树
            r_uncovered, r_covered, r_camera = dfs(node.right)
            
            # 当前节点未被覆盖
            uncovered = l_covered + r_covered
            
            # 当前节点被覆盖（但没有相机）
            covered = min(
                l_camera + r_camera,
                l_camera + r_covered,
                l_covered + r_camera
            )
            
            # 当前节点有相机
            camera = 1 + min(l_uncovered, l_covered, l_camera) + \
                     min(r_uncovered, r_covered, r_camera)
            
            return uncovered, covered, camera
        
        uncovered, covered, camera = dfs(root)
        return min(covered, camera)
    
    @staticmethod
    def tree_diameter_dp(n, edges):
        """
        树的直径（动态规划）
        时间复杂度：O(n)
        """
        # 构建邻接表
        graph = [[] for _ in range(n)]
        for u, v in edges:
            graph[u].append(v)
            graph[v].append(u)
        
        diameter = 0
        
        def dfs(node, parent):
            nonlocal diameter
            
            # 记录两条最长路径
            max1 = max2 = 0
            
            for neighbor in graph[node]:
                if neighbor != parent:
                    length = dfs(neighbor, node) + 1
                    
                    if length > max1:
                        max2 = max1
                        max1 = length
                    elif length > max2:
                        max2 = length
            
            # 更新直径
            diameter = max(diameter, max1 + max2)
            
            return max1
        
        dfs(0, -1)
        return diameter


class StateCompressionDP:
    """
    状态压缩动态规划
    """
    
    @staticmethod
    def traveling_salesman(dist):
        """
        旅行商问题（TSP）
        时间复杂度：O(n² * 2^n)
        空间复杂度：O(n * 2^n)
        """
        n = len(dist)
        # dp[mask][i]表示访问了mask中的城市，最后在i的最小距离
        dp = [[float('inf')] * n for _ in range(1 << n)]
        
        # 从城市0开始
        dp[1][0] = 0
        
        for mask in range(1 << n):
            for u in range(n):
                if not (mask & (1 << u)):
                    continue
                
                for v in range(n):
                    if mask & (1 << v):
                        continue
                    
                    new_mask = mask | (1 << v)
                    dp[new_mask][v] = min(dp[new_mask][v], 
                                         dp[mask][u] + dist[u][v])
        
        # 返回起点
        result = float('inf')
        full_mask = (1 << n) - 1
        
        for i in range(1, n):
            result = min(result, dp[full_mask][i] + dist[i][0])
        
        return result
    
    @staticmethod
    def hamilton_path(graph):
        """
        哈密尔顿路径
        时间复杂度：O(n² * 2^n)
        """
        n = len(graph)
        # dp[mask][i]表示访问了mask中的节点，最后在i是否可行
        dp = [[False] * n for _ in range(1 << n)]
        
        # 初始化：每个节点都可以作为起点
        for i in range(n):
            dp[1 << i][i] = True
        
        for mask in range(1 << n):
            for u in range(n):
                if not dp[mask][u]:
                    continue
                
                for v in range(n):
                    if (mask & (1 << v)) or u == v:
                        continue
                    
                    if graph[u][v]:
                        dp[mask | (1 << v)][v] = True
        
        # 检查是否存在哈密尔顿路径
        full_mask = (1 << n) - 1
        return any(dp[full_mask][i] for i in range(n))
    
    @staticmethod
    def maximum_students(seats):
        """
        参加考试的最大学生数
        时间复杂度：O(m * 2^n * 2^n)
        """
        m, n = len(seats), len(seats[0])
        
        # 预处理每行的有效状态
        valid_masks = []
        for row in seats:
            valid = []
            for mask in range(1 << n):
                # 检查是否有相邻的学生
                if mask & (mask << 1):
                    continue
                
                # 检查是否坐在坏椅子上
                valid_seat = True
                for j in range(n):
                    if (mask & (1 << j)) and row[j] == '#':
                        valid_seat = False
                        break
                
                if valid_seat:
                    valid.append(mask)
            
            valid_masks.append(valid)
        
        # dp[i][mask]表示前i行，第i行状态为mask的最大学生数
        dp = [{} for _ in range(m + 1)]
        dp[0][0] = 0
        
        for i in range(m):
            for prev_mask in dp[i]:
                for curr_mask in valid_masks[i]:
                    # 检查左前和右前是否有冲突
                    if (curr_mask << 1) & prev_mask:
                        continue
                    if (curr_mask >> 1) & prev_mask:
                        continue
                    
                    students = bin(curr_mask).count('1')
                    if curr_mask not in dp[i + 1]:
                        dp[i + 1][curr_mask] = 0
                    
                    dp[i + 1][curr_mask] = max(
                        dp[i + 1][curr_mask],
                        dp[i][prev_mask] + students
                    )
        
        return max(dp[m].values()) if dp[m] else 0
```

## 第六部分：高级算法

### 1. 字符串算法

```python
class KMPAlgorithm:
    """
    KMP字符串匹配算法
    """
    
    @staticmethod
    def compute_lps(pattern):
        """
        计算最长前缀后缀数组（LPS）
        时间复杂度：O(m)
        """
        m = len(pattern)
        lps = [0] * m
        length = 0  # 最长前缀后缀的长度
        i = 1
        
        while i < m:
            if pattern[i] == pattern[length]:
                length += 1
                lps[i] = length
                i += 1
            else:
                if length != 0:
                    # 回退到前一个最长前缀后缀
                    length = lps[length - 1]
                else:
                    lps[i] = 0
                    i += 1
        
        return lps
    
    @staticmethod
    def kmp_search(text, pattern):
        """
        KMP搜索
        时间复杂度：O(n + m)
        空间复杂度：O(m)
        """
        n, m = len(text), len(pattern)
        if m == 0:
            return []
        
        # 计算LPS数组
        lps = KMPAlgorithm.compute_lps(pattern)
        
        result = []
        i = j = 0  # i指向text，j指向pattern
        
        while i < n:
            if text[i] == pattern[j]:
                i += 1
                j += 1
                
                if j == m:
                    # 找到匹配
                    result.append(i - j)
                    j = lps[j - 1]
            else:
                if j != 0:
                    # 利用LPS数组跳过已匹配的部分
                    j = lps[j - 1]
                else:
                    i += 1
        
        return result
    
    @staticmethod
    def kmp_count_occurrences(text, pattern):
        """
        统计模式串出现次数
        """
        positions = KMPAlgorithm.kmp_search(text, pattern)
        return len(positions)


class BoyerMooreAlgorithm:
    """
    Boyer-Moore字符串匹配算法
    """
    
    @staticmethod
    def build_bad_char_table(pattern):
        """
        构建坏字符表
        时间复杂度：O(m + σ) σ为字符集大小
        """
        bad_char = {}
        
        # 记录每个字符在模式串中最右出现的位置
        for i in range(len(pattern)):
            bad_char[pattern[i]] = i
        
        return bad_char
    
    @staticmethod
    def build_good_suffix_table(pattern):
        """
        构建好后缀表
        时间复杂度：O(m)
        """
        m = len(pattern)
        good_suffix = [0] * m
        
        # 辅助数组
        suffix = [-1] * m
        suffix[m - 1] = m
        
        # 计算suffix数组
        for i in range(m - 2, -1, -1):
            j = i
            while j >= 0 and pattern[j] == pattern[m - 1 - i + j]:
                j -= 1
            suffix[i] = i - j
        
        # 情况1：模式串中有子串匹配上好后缀
        for i in range(m):
            good_suffix[i] = m
        
        j = 0
        for i in range(m - 1, -1, -1):
            if suffix[i] == i + 1:
                while j < m - 1 - i:
                    if good_suffix[j] == m:
                        good_suffix[j] = m - 1 - i
                    j += 1
        
        # 情况2：好后缀的前缀出现在模式串头部
        for i in range(m - 1):
            good_suffix[m - 1 - suffix[i]] = m - 1 - i
        
        return good_suffix
    
    @staticmethod
    def boyer_moore_search(text, pattern):
        """
        Boyer-Moore搜索
        时间复杂度：最好O(n/m)，最坏O(nm)
        """
        n, m = len(text), len(pattern)
        if m == 0:
            return []
        
        # 构建表
        bad_char = BoyerMooreAlgorithm.build_bad_char_table(pattern)
        good_suffix = BoyerMooreAlgorithm.build_good_suffix_table(pattern)
        
        result = []
        i = 0  # text中的起始位置
        
        while i <= n - m:
            j = m - 1  # 从后向前匹配
            
            while j >= 0 and pattern[j] == text[i + j]:
                j -= 1
            
            if j < 0:
                # 找到匹配
                result.append(i)
                i += good_suffix[0] if i + m < n else 1
            else:
                # 计算跳跃距离
                bad_char_skip = j - bad_char.get(text[i + j], -1)
                good_suffix_skip = good_suffix[j]
                i += max(bad_char_skip, good_suffix_skip)
        
        return result


class RabinKarpAlgorithm:
    """
    Rabin-Karp字符串匹配算法（基于滚动哈希）
    """
    
    def __init__(self, base=256, prime=101):
        self.base = base  # 进制
        self.prime = prime  # 质数
    
    def search(self, text, pattern):
        """
        Rabin-Karp搜索
        时间复杂度：平均O(n + m)，最坏O(nm)
        """
        n, m = len(text), len(pattern)
        if m == 0:
            return []
        
        # 计算pattern的哈希值
        pattern_hash = 0
        text_hash = 0
        h = 1  # base^(m-1) % prime
        
        for i in range(m - 1):
            h = (h * self.base) % self.prime
        
        # 计算初始哈希值
        for i in range(m):
            pattern_hash = (self.base * pattern_hash + ord(pattern[i])) % self.prime
            text_hash = (self.base * text_hash + ord(text[i])) % self.prime
        
        result = []
        
        # 滑动窗口
        for i in range(n - m + 1):
            # 检查哈希值是否相等
            if pattern_hash == text_hash:
                # 进一步验证字符是否真的相等（避免哈希冲突）
                if text[i:i + m] == pattern:
                    result.append(i)
            
            # 计算下一个窗口的哈希值
            if i < n - m:
                text_hash = (self.base * (text_hash - ord(text[i]) * h) + 
                            ord(text[i + m])) % self.prime
                
                # 确保哈希值为正
                if text_hash < 0:
                    text_hash += self.prime
        
        return result
    
    def search_multiple_patterns(self, text, patterns):
        """
        同时搜索多个模式串
        """
        result = {pattern: [] for pattern in patterns}
        
        # 找到最短的模式串长度
        min_length = min(len(p) for p in patterns)
        
        # 计算所有模式串的哈希值
        pattern_hashes = {}
        for pattern in patterns:
            if len(pattern) == min_length:
                hash_val = 0
                for char in pattern:
                    hash_val = (self.base * hash_val + ord(char)) % self.prime
                if hash_val not in pattern_hashes:
                    pattern_hashes[hash_val] = []
                pattern_hashes[hash_val].append(pattern)
        
        # 搜索
        n = len(text)
        if min_length == 0 or n < min_length:
            return result
        
        # 计算h = base^(min_length-1) % prime
        h = 1
        for i in range(min_length - 1):
            h = (h * self.base) % self.prime
        
        # 初始哈希
        text_hash = 0
        for i in range(min_length):
            text_hash = (self.base * text_hash + ord(text[i])) % self.prime
        
        # 滑动窗口
        for i in range(n - min_length + 1):
            if text_hash in pattern_hashes:
                # 验证匹配
                for pattern in pattern_hashes[text_hash]:
                    if text[i:i + min_length] == pattern:
                        result[pattern].append(i)
            
            # 更新哈希值
            if i < n - min_length:
                text_hash = (self.base * (text_hash - ord(text[i]) * h) + 
                            ord(text[i + min_length])) % self.prime
                if text_hash < 0:
                    text_hash += self.prime
        
        return result


class AhoCorasickAutomaton:
    """
    AC自动机（多模式串匹配）
    """
    
    class Node:
        def __init__(self):
            self.children = {}
            self.fail = None  # 失败指针
            self.output = []  # 输出列表
    
    def __init__(self):
        self.root = self.Node()
        self.patterns = []
    
    def add_pattern(self, pattern):
        """
        添加模式串
        时间复杂度：O(m)
        """
        node = self.root
        
        for char in pattern:
            if char not in node.children:
                node.children[char] = self.Node()
            node = node.children[char]
        
        node.output.append(len(self.patterns))
        self.patterns.append(pattern)
    
    def build_failure_links(self):
        """
        构建失败指针
        时间复杂度：O(Σm)
        """
        from collections import deque
        
        queue = deque()
        
        # 第一层节点的失败指针指向根
        for child in self.root.children.values():
            child.fail = self.root
            queue.append(child)
        
        # BFS构建失败指针
        while queue:
            node = queue.popleft()
            
            for char, child in node.children.items():
                queue.append(child)
                
                # 寻找失败指针
                fail_node = node.fail
                
                while fail_node and char not in fail_node.children:
                    fail_node = fail_node.fail
                
                if fail_node:
                    child.fail = fail_node.children[char]
                else:
                    child.fail = self.root
                
                # 合并输出
                if child.fail:
                    child.output.extend(child.fail.output)
    
    def search(self, text):
        """
        搜索所有模式串
        时间复杂度：O(n + z) z为匹配总数
        """
        result = {pattern: [] for pattern in self.patterns}
        node = self.root
        
        for i, char in enumerate(text):
            # 沿着失败指针找到可以匹配的节点
            while node and char not in node.children:
                node = node.fail
            
            if not node:
                node = self.root
                continue
            
            node = node.children[char]
            
            # 输出所有匹配
            for pattern_idx in node.output:
                pattern = self.patterns[pattern_idx]
                result[pattern].append(i - len(pattern) + 1)
        
        return result


class ManacherAlgorithm:
    """
    Manacher算法（最长回文子串）
    """
    
    @staticmethod
    def preprocess(s):
        """
        预处理字符串，插入特殊字符
        """
        return '#' + '#'.join(s) + '#'
    
    @staticmethod
    def longest_palindrome(s):
        """
        找到最长回文子串
        时间复杂度：O(n)
        空间复杂度：O(n)
        """
        if not s:
            return ""
        
        # 预处理
        processed = ManacherAlgorithm.preprocess(s)
        n = len(processed)
        
        # P[i]表示以i为中心的回文半径
        P = [0] * n
        center = 0  # 当前回文的中心
        right = 0   # 当前回文的右边界
        
        max_len = 0
        max_center = 0
        
        for i in range(n):
            # 利用对称性
            mirror = 2 * center - i
            
            if i < right:
                P[i] = min(right - i, P[mirror])
            
            # 尝试扩展
            try:
                while (i + P[i] + 1 < n and i - P[i] - 1 >= 0 and
                       processed[i + P[i] + 1] == processed[i - P[i] - 1]):
                    P[i] += 1
            except:
                pass
            
            # 更新中心和右边界
            if i + P[i] > right:
                center = i
                right = i + P[i]
            
            # 更新最长回文
            if P[i] > max_len:
                max_len = P[i]
                max_center = i
        
        # 提取原始字符串中的回文
        start = (max_center - max_len) // 2
        return s[start:start + max_len]
    
    @staticmethod
    def count_palindromic_substrings(s):
        """
        统计回文子串的数量
        时间复杂度：O(n)
        """
        if not s:
            return 0
        
        processed = ManacherAlgorithm.preprocess(s)
        n = len(processed)
        
        P = [0] * n
        center = 0
        right = 0
        count = 0
        
        for i in range(n):
            mirror = 2 * center - i
            
            if i < right:
                P[i] = min(right - i, P[mirror])
            
            while (i + P[i] + 1 < n and i - P[i] - 1 >= 0 and
                   processed[i + P[i] + 1] == processed[i - P[i] - 1]):
                P[i] += 1
            
            if i + P[i] > right:
                center = i
                right = i + P[i]
            
            # 统计以i为中心的回文数
            count += (P[i] + 1) // 2
        
        return count


class StringHashing:
    """
    字符串哈希算法
    """
    
    def __init__(self, s, base=31, mod=10**9 + 7):
        self.s = s
        self.n = len(s)
        self.base = base
        self.mod = mod
        
        # 预计算前缀哈希和幂
        self.prefix_hash = [0] * (self.n + 1)
        self.power = [1] * (self.n + 1)
        
        for i in range(self.n):
            self.prefix_hash[i + 1] = (self.prefix_hash[i] * base + 
                                      ord(s[i]) - ord('a') + 1) % mod
            self.power[i + 1] = (self.power[i] * base) % mod
    
    def get_hash(self, left, right):
        """
        获取子串s[left:right+1]的哈希值
        时间复杂度：O(1)
        """
        return (self.prefix_hash[right + 1] - 
                self.prefix_hash[left] * self.power[right - left + 1]) % self.mod
    
    def find_repeated_substrings(self, length):
        """
        找到所有长度为length的重复子串
        时间复杂度：O(n)
        """
        if length > self.n:
            return []
        
        hash_map = {}
        repeated = []
        
        for i in range(self.n - length + 1):
            hash_val = self.get_hash(i, i + length - 1)
            
            if hash_val in hash_map:
                # 验证是否真的相等（避免哈希冲突）
                if self.s[hash_map[hash_val]:hash_map[hash_val] + length] == \
                   self.s[i:i + length]:
                    repeated.append(self.s[i:i + length])
            else:
                hash_map[hash_val] = i
        
        return list(set(repeated))
    
    def longest_common_substring(self, other):
        """
        与另一个字符串的最长公共子串
        时间复杂度：O(n² log n)
        """
        other_hash = StringHashing(other, self.base, self.mod)
        
        def has_common_substring(length):
            """检查是否有长度为length的公共子串"""
            hash_set = set()
            
            # 收集第一个字符串的所有子串哈希
            for i in range(self.n - length + 1):
                hash_set.add(self.get_hash(i, i + length - 1))
            
            # 检查第二个字符串
            for i in range(other_hash.n - length + 1):
                if other_hash.get_hash(i, i + length - 1) in hash_set:
                    return True
            
            return False
        
        # 二分查找最长公共子串长度
        left, right = 0, min(self.n, other_hash.n)
        result = 0
        
        while left <= right:
            mid = (left + right) // 2
            
            if has_common_substring(mid):
                result = mid
                left = mid + 1
            else:
                right = mid - 1
        
        return result
```

### 2. 数学算法

~~~python
class PrimeSieve:
    """
    素数筛选算法
    """
    
    @staticmethod
    def sieve_of_eratosthenes(n):
        """
        埃拉托斯特尼筛法
        时间复杂度：O(n log log n)
        空间复杂度：O(n)
        """
        if n < 2:
            return []
        
        # 初始化标记数组，True表示是素数
        is_prime = [True] * (n + 1)
        is_prime[0] = is_prime[1] = False
        
        # 筛选过程
        for i in range(2, int(n**0.5) + 1):
            if is_prime[i]:
                # 标记i的所有倍数为合数
                for j in range(i * i, n + 1, i):
                    is_prime[j] = False
        
        # 收集所有素数
        primes = [i for i in range(2, n + 1) if is_prime[i]]
        return primes
    
    @staticmethod
    def linear_sieve(n):
        """
        线性筛法（欧拉筛）
        时间复杂度：O(n)
        空间复杂度：O(n)
        """
        if n < 2:
            return []
        
        is_prime = [True] * (n + 1)
        primes = []
        
        for i in range(2, n + 1):
            if is_prime[i]:
                primes.append(i)
            
            # 用已知素数筛选
            j = 0
            while j < len(primes) and i * primes[j] <= n:
                is_prime[i * primes[j]] = False
                # 保证每个合数只被最小质因子筛一次
                if i % primes[j] == 0:
                    break
                j += 1
        
        return primes
    
    @staticmethod
    def segmented_sieve(n):
        """
        分段筛法（处理大数范围）
        时间复杂度：O(n log log n)
        空间复杂度：O(√n)
        """
        if n < 2:
            return []
        
        # 先找出√n以内的素数
        limit = int(n**0.5) + 1
        base_primes = PrimeSieve.sieve_of_eratosthenes(limit)
        
        # 分段大小
        segment_size = max(limit, 32768)
        primes = []
        
        # 处理每个段
        for low in range(0, n + 1, segment_size):
            high = min(low + segment_size - 1, n)
            
            # 标记当前段
            is_prime_segment = [True] * (high - low + 1)
            
            # 用基础素数筛选当前段
            for p in base_primes:
                # 找到第一个需要标记的位置
                start = max(p * p, (low + p - 1) // p * p)
                
                for j in range(start, high + 1, p):
                    is_prime_segment[j - low] = False
            
            # 特殊处理第一段
            if low == 0:
                is_prime_segment[0] = is_prime_segment[1] = False
            
            # 收集素数
            for i in range(len(is_prime_segment)):
                if is_prime_segment[i]:
                    primes.append(low + i)
        
        return primes
    
    @staticmethod
    def is_prime(n):
        """
        素数判定（试除法优化）
        时间复杂度：O(√n)
        """
        if n <= 1:
            return False
        if n <= 3:
            return True
        if n % 2 == 0 or n % 3 == 0:
            return False
        
        # 检查6k±1形式的因子
        i = 5
        while i * i <= n:
            if n % i == 0 or n % (i + 2) == 0:
                return False
            i += 6
        
        return True
    
    @staticmethod
    def miller_rabin(n, k=5):
        """
        Miller-Rabin素性测试
        时间复杂度：O(k log³ n)
        k: 测试轮数，越大越准确
        """
        import random
        
        if n < 2:
            return False
        if n == 2 or n == 3:
            return True
        if n % 2 == 0:
            return False
        
        # 将n-1写成2^r * d的形式
        r, d = 0, n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        # 进行k轮测试
        for _ in range(k):
            a = random.randrange(2, n - 1)
            x = pow(a, d, n)  # a^d mod n
            
            if x == 1 or x == n - 1:
                continue
            
            for _ in range(r - 1):
                x = pow(x, 2, n)
                if x == n - 1:
                    break
            else:
                return False
        
        return True


class FastPower:
    """
    快速幂算法
    """
    
    @staticmethod
    def power_mod(base, exp, mod):
        """
        快速幂取模
        时间复杂度：O(log n)
        计算 base^exp % mod
        """
        result = 1
        base %= mod
        
        while exp > 0:
            # 如果指数是奇数
            if exp & 1:
                result = (result * base) % mod
            
            # 底数平方
            base = (base * base) % mod
            exp >>= 1
        
        return result
    
    @staticmethod
    def matrix_power(matrix, n):
        """
        矩阵快速幂
        时间复杂度：O(m³ log n) m为矩阵维度
        """
        size = len(matrix)
        
        # 初始化单位矩阵
        result = [[1 if i == j else 0 for j in range(size)] 
                  for i in range(size)]
        
        # 复制原矩阵
        base = [row[:] for row in matrix]
        
        while n > 0:
            if n & 1:
                result = FastPower._matrix_multiply(result, base)
            
            base = FastPower._matrix_multiply(base, base)
            n >>= 1
        
        return result
    
    @staticmethod
    def _matrix_multiply(A, B):
        """矩阵乘法"""
        n = len(A)
        C = [[0] * n for _ in range(n)]
        
        for i in range(n):
            for j in range(n):
                for k in range(n):
                    C[i][j] += A[i][k] * B[k][j]
        
        return C
    
    @staticmethod
    def fibonacci_matrix(n):
        """
        使用矩阵快速幂计算斐波那契数
        时间复杂度：O(log n)
        """
        if n <= 1:
            return n
        
        # 斐波那契矩阵
        matrix = [[1, 1], [1, 0]]
        
        # 计算矩阵的n-1次幂
        result = FastPower.matrix_power(matrix, n - 1)
        
        # F(n) = result[0][0]
        return result[0][0]
    
    @staticmethod
    def modular_inverse(a, m):
        """
        模逆元（使用费马小定理）
        前提：m是质数
        时间复杂度：O(log m)
        """
        # a^(-1) ≡ a^(m-2) (mod m)
        return FastPower.power_mod(a, m - 2, m)
    
    @staticmethod
    def extended_gcd(a, b):
        """
        扩展欧几里得算法
        返回 gcd(a,b) 和 x,y 使得 ax + by = gcd(a,b)
        """
        if b == 0:
            return a, 1, 0
        
        gcd, x1, y1 = FastPower.extended_gcd(b, a % b)
        x = y1
        y = x1 - (a // b) * y1
        
        return gcd, x, y


class MatrixOperations:
    """
    矩阵运算算法
    """
    
    @staticmethod
    def matrix_multiply(A, B):
        """
        标准矩阵乘法
        时间复杂度：O(n³)
        """
        rows_A, cols_A = len(A), len(A[0])
        rows_B, cols_B = len(B), len(B[0])
        
        if cols_A != rows_B:
            raise ValueError("矩阵维度不匹配")
        
        C = [[0] * cols_B for _ in range(rows_A)]
        
        for i in range(rows_A):
            for j in range(cols_B):
                for k in range(cols_A):
                    C[i][j] += A[i][k] * B[k][j]
        
        return C
    
    @staticmethod
    def matrix_transpose(matrix):
        """
        矩阵转置
        时间复杂度：O(mn)
        """
        rows, cols = len(matrix), len(matrix[0])
        return [[matrix[i][j] for i in range(rows)] for j in range(cols)]
    
    @staticmethod
    def gaussian_elimination(A, b):
        """
        高斯消元法解线性方程组
        时间复杂度：O(n³)
        """
        n = len(A)
        
        # 构造增广矩阵
        augmented = [A[i][:] + [b[i]] for i in range(n)]
        
        # 前向消元
        for i in range(n):
            # 选择主元（部分主元法）
            max_row = i
            for k in range(i + 1, n):
                if abs(augmented[k][i]) > abs(augmented[max_row][i]):
                    max_row = k
            
            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]
            
            # 如果主元为0，无解或无穷多解
            if abs(augmented[i][i]) < 1e-10:
                return None
            
            # 消元
            for k in range(i + 1, n):
                factor = augmented[k][i] / augmented[i][i]
                for j in range(i, n + 1):
                    augmented[k][j] -= factor * augmented[i][j]
        
        # 回代求解
        x = [0] * n
        for i in range(n - 1, -1, -1):
            x[i] = augmented[i][n]
            for j in range(i + 1, n):
                x[i] -= augmented[i][j] * x[j]
            x[i] /= augmented[i][i]
        
        return x
    
    @staticmethod
    def matrix_determinant(matrix):
        """
        计算矩阵行列式（LU分解法）
        时间复杂度：O(n³)
        """
        n = len(matrix)
        if n == 1:
            return matrix[0][0]
        
        # 复制矩阵避免修改原矩阵
        A = [row[:] for row in matrix]
        det = 1
        
        for i in range(n):
            # 找主元
            max_row = i
            for k in range(i + 1, n):
                if abs(A[k][i]) > abs(A[max_row][i]):
                    max_row = k
            
            # 交换行
            if i != max_row:
                A[i], A[max_row] = A[max_row], A[i]
                det *= -1  # 交换行会改变行列式符号
            
            # 如果主元为0，行列式为0
            if abs(A[i][i]) < 1e-10:
                return 0
            
            det *= A[i][i]
            
            # 消元
            for k in range(i + 1, n):
                factor = A[k][i] / A[i][i]
                for j in range(i + 1, n):
                    A[k][j] -= factor * A[i][j]
        
        return det
    
    @staticmethod
    def matrix_inverse(matrix):
        """
        矩阵求逆（高斯-约旦消元法）
        时间复杂度：O(n³)
        """
        n = len(matrix)
        
        # 构造增广矩阵 [A | I]
        augmented = []
        for i in range(n):
            row = matrix[i][:] + [0] * n
            row[n + i] = 1
            augmented.append(row)
        
        # 高斯-约旦消元
        for i in range(n):
            # 选择主元
            max_row = i
            for k in range(i + 1, n):
                if abs(augmented[k][i]) > abs(augmented[max_row][i]):
                    max_row = k
            
            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]
            
            # 检查是否可逆
            if abs(augmented[i][i]) < 1e-10:
                return None
            
            # 将主元变为1
            pivot = augmented[i][i]
            for j in range(2 * n):
                augmented[i][j] /= pivot
            
            # 消元
            for k in range(n):
                if k != i:
                    factor = augmented[k][i]
                    for j in range(2 * n):
                        augmented[k][j] -= factor * augmented[i][j]
        
        # 提取逆矩阵
        inverse = []
        for i in range(n):
            inverse.append(augmented[i][n:])
        
        return inverse


class ComputationalGeometry:
    """
    计算几何算法
    """
    
    @staticmethod
    def distance(p1, p2):
        """计算两点间距离"""
        return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5
    
    @staticmethod
    def cross_product(O, A, B):
        """
        计算向量OA和OB的叉积
        返回值 > 0: 逆时针
        返回值 < 0: 顺时针
        返回值 = 0: 共线
        """
        return (A[0] - O[0]) * (B[1] - O[1]) - (A[1] - O[1]) * (B[0] - O[0])
    
    @staticmethod
    def convex_hull_graham(points):
        """
        凸包算法（Graham扫描）
        时间复杂度：O(n log n)
        """
        n = len(points)
        if n < 3:
            return points
        
        # 找到最下方的点（y最小，如果相同则x最小）
        start = min(points, key=lambda p: (p[1], p[0]))
        
        # 按极角排序
        def polar_angle(p):
            import math
            dx, dy = p[0] - start[0], p[1] - start[1]
            return math.atan2(dy, dx)
        
        sorted_points = sorted(points, key=polar_angle)
        
        # Graham扫描
        hull = []
        for p in sorted_points:
            # 删除非左转的点
            while len(hull) > 1 and ComputationalGeometry.cross_product(
                hull[-2], hull[-1], p) <= 0:
                hull.pop()
            hull.append(p)
        
        return hull
    
    @staticmethod
    def convex_hull_jarvis(points):
        """
        凸包算法（Jarvis步进）
        时间复杂度：O(nh) h为凸包上的点数
        """
        n = len(points)
        if n < 3:
            return points
        
        # 找到最左边的点
        l = 0
        for i in range(1, n):
            if points[i][0] < points[l][0]:
                l = i
            elif points[i][0] == points[l][0] and points[i][1] < points[l][1]:
                l = i
        
        hull = []
        p = l
        
        while True:
            hull.append(points[p])
            
            # 找到最逆时针的点
            q = (p + 1) % n
            for i in range(n):
                if ComputationalGeometry.cross_product(
                    points[p], points[i], points[q]) > 0:
                    q = i
            
            p = q
            if p == l:  # 回到起点
                break
        
        return hull
    
    @staticmethod
    def point_in_polygon(point, polygon):
        """
        判断点是否在多边形内（射线法）
        时间复杂度：O(n)
        """
        x, y = point
        n = len(polygon)
        inside = False
        
        p1x, p1y = polygon[0]
        
        for i in range(1, n + 1):
            p2x, p2y = polygon[i % n]
            
            if y > min(p1y, p2y):
                if y <= max(p1y, p2y):
                    if x <= max(p1x, p2x):
                        if p1y != p2y:
                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                        if p1x == p2x or x <= xinters:
                            inside = not inside
            
            p1x, p1y = p2x, p2y
        
        return inside
    
    @staticmethod
    def line_intersection(p1, p2, p3, p4):
        """
        计算两条线段的交点
        返回交点坐标，如果不相交返回None
        """
        x1, y1 = p1
        x2, y2 = p2
        x3, y3 = p3
        x4, y4 = p4
        
        denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)
        
        if abs(denom) < 1e-10:
            return None  # 平行或共线
        
        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        u = -((x1 - x2) * (y1 - y3) - (y1 - y2) * (x1 - x3)) / denom
        
        if 0 <= t <= 1 and 0 <= u <= 1:
            x = x1 + t * (x2 - x1)
            y = y1 + t * (y2 - y1)
            return (x, y)
        
        return None
    
    @staticmethod
    def polygon_area(polygon):
        """
        计算多边形面积（鞋带公式）
        时间复杂度：O(n)
        """
        n = len(polygon)
        area = 0.0
        
        for i in range(n):
            j = (i + 1) % n
            area += polygon[i][0] * polygon[j][1]
            area -= polygon[j][0] * polygon[i][1]
        
        return abs(area) / 2.0
    
    @staticmethod
    def closest_pair_of_points(points):
        """
        平面最近点对（分治法）
        时间复杂度：O(n log n)
        """
        def brute_force(points):
            min_dist = float('inf')
            n = len(points)
            
            for i in range(n):
                for j in range(i + 1, n):
                    dist = ComputationalGeometry.distance(points[i], points[j])
                    min_dist = min(min_dist, dist)
            
            return min_dist
        
        def strip_closest(strip, d):
            min_dist = d
            strip.sort(key=lambda p: p[1])
            
            for i in range(len(strip)):
                j = i + 1
                while j < len(strip) and (strip[j][1] - strip[i][1]) < min_dist:
                    dist = ComputationalGeometry.distance(strip[i], strip[j])
                    min_dist = min(min_dist, dist)
                    j += 1
            
            return min_dist
        
        def closest_pair_recursive(px, py):
            n = len(px)
            
            if n <= 3:
                return brute_force(px)
            
            mid = n // 2
            midpoint = px[mid]
            
            pyl = [p for p in py if p[0] <= midpoint[0]]
            pyr = [p for p in py if p[0] > midpoint[0]]
            
            dl = closest_pair_recursive(px[:mid], pyl)
            dr = closest_pair_recursive(px[mid:], pyr)
            
            d = min(dl, dr)
            
            strip = [p for p in py if abs(p[0] - midpoint[0]) < d]
            
            return min(d, strip_closest(strip, d))
        
        px = sorted(points, key=lambda p: p[0])
        py = sorted(points, key=lambda p: p[1])
        
        return closest_pair_recursive(px, py)


class NumberTheory:
    """
    数论算法
    """
    
    @staticmethod
    def gcd(a, b):
        """
        最大公约数（欧几里得算法）
        时间复杂度：O(log min(a, b))
        """
        while b:
            a, b = b, a % b
        return a
    
    @staticmethod
    def lcm(a, b):
        """最小公倍数"""
        return abs(a * b) // NumberTheory.gcd(a, b)
    
    @staticmethod
    def chinese_remainder_theorem(remainders, moduli):
        """
        中国剩余定理
        求解同余方程组：x ≡ remainders[i] (mod moduli[i])
        时间复杂度：O(n²)
        """
        if len(remainders) != len(moduli):
            raise ValueError("输入长度不匹配")
        
        # 计算所有模数的乘积
        M = 1
        for m in moduli:
            M *= m
        
        x = 0
        
        for i in range(len(remainders)):
            Mi = M // moduli[i]
            
            # 求Mi关于moduli[i]的模逆元
            gcd, mi_inv, _ = FastPower.extended_gcd(Mi, moduli[i])
            
            if gcd != 1:
                raise ValueError("模数不互质")
            
            x += remainders[i] * Mi * mi_inv
        
        return x % M
    
    @staticmethod
    def euler_phi(n):
        """
        欧拉函数：计算小于等于n且与n互质的正整数个数
        时间复杂度：O(√n)
        """
        result = n
        p = 2
        
        while p * p <= n:
            if n % p == 0:
                # 去除因子p
                while n % p == 0:
                    n //= p
                # 更新结果
                result -= result // p
            p += 1
        
        if n > 1:
            result -= result // n
        
        return result
    
    @staticmethod
    def mobius(n):
        """
        莫比乌斯函数
        μ(n) = 1 如果n是偶数个不同素数的乘积
        μ(n) = -1 如果n是奇数个不同素数的乘积
        μ(n) = 0 如果n有平方因子
        """
        if n == 1:
            return 1
        
        # 分解质因数
        prime_factors = 0
        temp = n
        
        for p in range(2, int(n**0.5) + 1):
            if temp % p == 0:
                prime_factors += 1
                temp //= p
                
                # 检查是否有平方因子
                if temp % p == 0:
                    return 0
        
        if temp > 1:
            prime_factors += 1
        
        return -1 if prime_factors % 2 == 1 else 1
    
    @staticmethod
    def primitive_root(p):
        """
        找到质数p的原根
        时间复杂度：O(p log p)
        """
        if p == 2:
            return 1
        
        # 计算p-1的质因子
        phi = p - 1
        factors = []
        temp = phi
        
        for i in range(2, int(temp**0.5) + 1):
            if temp % i == 0:
                factors.append(i)
                while temp % i == 0:
                    temp //= i
        
        if temp > 1:
            factors.append(temp)
        
        # 测试每个可能的原根
        for g in range(2, p):
            is_primitive = True
            
            for factor in factors:
                if pow(g, phi // factor, p) == 1:
                    is_primitive = False
                    break
            
            if is_primitive:
                return g
        
        return None


### 3. 概率算法

```python
import random
import math

class MonteCarloAlgorithms:
    """
    蒙特卡洛算法（随机算法，可能返回错误结果）
    """
    
    @staticmethod
    def estimate_pi(n_samples):
        """
        估算π值
        时间复杂度：O(n)
        精度：O(1/√n)
        """
        inside_circle = 0
        
        for _ in range(n_samples):
            x = random.uniform(-1, 1)
            y = random.uniform(-1, 1)
            
            if x*x + y*y <= 1:
                inside_circle += 1
        
        # π/4 = 圆内点数 / 总点数
        return 4 * inside_circle / n_samples
    
    @staticmethod
    def monte_carlo_integration(f, a, b, n_samples):
        """
        蒙特卡洛积分
        估算函数f在[a,b]区间的定积分
        时间复杂度：O(n)
        """
        total = 0
        
        for _ in range(n_samples):
            x = random.uniform(a, b)
            total += f(x)
        
        return (b - a) * total / n_samples
    
    @staticmethod
    def random_sampling(population, k):
        """
        水塘抽样算法（Reservoir Sampling）
        从未知大小的流中随机抽取k个元素
        时间复杂度：O(n)
        空间复杂度：O(k)
        """
        reservoir = []
        
        for i, item in enumerate(population):
            if i < k:
                reservoir.append(item)
            else:
                # 以k/(i+1)的概率替换
                j = random.randint(0, i)
                if j < k:
                    reservoir[j] = item
        
        return reservoir
    
    @staticmethod
    def freivalds_algorithm(A, B, C, k=10):
        """
        Freivald算法：验证矩阵乘法 A×B = C
        时间复杂度：O(kn²)
        错误概率：(1/2)^k
        """
        n = len(A)
        
        for _ in range(k):
            # 生成随机向量
            r = [random.randint(0, 1) for _ in range(n)]
            
            # 计算 A × (B × r)
            Br = [sum(B[i][j] * r[j] for j in range(n)) for i in range(n)]
            ABr = [sum(A[i][j] * Br[j] for j in range(n)) for i in range(n)]
            
            # 计算 C × r
            Cr = [sum(C[i][j] * r[j] for j in range(n)) for i in range(n)]
            
            # 比较结果
            if ABr != Cr:
                return False
        
        return True
    
    @staticmethod
    def karger_min_cut(graph):
        """
        Karger最小割算法
        时间复杂度：O(n²)
        成功概率：至少1/n²
        """
        # 复制图
        vertices = list(graph.keys())
        edges = []
        
        for u in graph:
            for v in graph[u]:
                if u < v:  # 避免重复
                    edges.append((u, v))
        
        # 并查集
        parent = {v: v for v in vertices}
        
        def find(x):
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent[px] = py
        
        # 随机收缩边
        remaining_vertices = len(vertices)
        
        while remaining_vertices > 2:
            # 随机选择一条边
            u, v = random.choice(edges)
            
            if find(u) != find(v):
                union(u, v)
                remaining_vertices -= 1
        
        # 计算割的大小
        cut_size = 0
        for u, v in edges:
            if find(u) != find(v):
                cut_size += 1
        
        return cut_size
    
    @staticmethod
    def monte_carlo_tree_search(root, iterations=1000):
        """
        蒙特卡洛树搜索（简化版）
        用于游戏AI等决策问题
        """
        class MCTSNode:
            def __init__(self, state, parent=None):
                self.state = state
                self.parent = parent
                self.children = []
                self.visits = 0
                self.wins = 0
            
            def uct_value(self, c=1.41):
                if self.visits == 0:
                    return float('inf')
                
                exploitation = self.wins / self.visits
                exploration = c * math.sqrt(math.log(self.parent.visits) / self.visits)
                
                return exploitation + exploration
            
            def best_child(self):
                return max(self.children, key=lambda x: x.uct_value())
        
        # MCTS主循环
        for _ in range(iterations):
            # 1. 选择
            node = root
            while node.children and not node.state.is_terminal():
                node = node.best_child()
            
            # 2. 扩展
            if not node.state.is_terminal() and node.visits > 0:
                for action in node.state.get_actions():
                    child_state = node.state.apply_action(action)
                    child = MCTSNode(child_state, node)
                    node.children.append(child)
                
                node = random.choice(node.children)
            
            # 3. 模拟
            state = node.state.copy()
            while not state.is_terminal():
                action = random.choice(state.get_actions())
                state = state.apply_action(action)
            
            reward = state.get_reward()
            
            # 4. 反向传播
            while node:
                node.visits += 1
                node.wins += reward
                node = node.parent
        
        # 返回访问次数最多的子节点
        return max(root.children, key=lambda x: x.visits)


class LasVegasAlgorithms:
    """
    拉斯维加斯算法（随机算法，保证正确性）
    """
    
    @staticmethod
    def randomized_quicksort(arr):
        """
        随机化快速排序
        期望时间复杂度：O(n log n)
        最坏时间复杂度：O(n²)
        """
        def partition(arr, low, high):
            # 随机选择基准
            pivot_index = random.randint(low, high)
            arr[pivot_index], arr[high] = arr[high], arr[pivot_index]
            
            pivot = arr[high]
            i = low - 1
            
            for j in range(low, high):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[high] = arr[high], arr[i + 1]
            return i + 1
        
        def quicksort_helper(arr, low, high):
            if low < high:
                pi = partition(arr, low, high)
                quicksort_helper(arr, low, pi - 1)
                quicksort_helper(arr, pi + 1, high)
        
        quicksort_helper(arr, 0, len(arr) - 1)
        return arr
    
    @staticmethod
    def randomized_selection(arr, k):
        """
        随机化选择算法（找第k小元素）
        期望时间复杂度：O(n)
        """
        def partition(arr, low, high):
            pivot_index = random.randint(low, high)
            arr[pivot_index], arr[high] = arr[high], arr[pivot_index]
            
            pivot = arr[high]
            i = low - 1
            
            for j in range(low, high):
                if arr[j] <= pivot:
                    i += 1
                    arr[i], arr[j] = arr[j], arr[i]
            
            arr[i + 1], arr[high] = arr[high], arr[i + 1]
            return i + 1
        
        def select(arr, low, high, k):
            if low == high:
                return arr[low]
            
            pivot_index = partition(arr, low, high)
            
            if k == pivot_index:
                return arr[k]
            elif k < pivot_index:
                return select(arr, low, pivot_index - 1, k)
            else:
                return select(arr, pivot_index + 1, high, k)
        
        return select(arr, 0, len(arr) - 1, k - 1)
    
    @staticmethod
    def randomized_min_cut(graph, trials=100):
        """
        随机化最小割（多次运行Karger算法）
        成功概率：1 - (1 - 1/n²)^trials
        """
        min_cut = float('inf')
        
        for _ in range(trials):
            cut = MonteCarloAlgorithms.karger_min_cut(graph)
            min_cut = min(min_cut, cut)
        
        return min_cut
    
    @staticmethod
    def randomized_primality_test(n, k=5):
        """
        随机化素性测试（Miller-Rabin）
        时间复杂度：O(k log³ n)
        """
        return PrimeSieve.miller_rabin(n, k)
    
    @staticmethod
    def random_walk_2sat(clauses, n_vars, max_tries=100):
        """
        随机游走算法解决2-SAT问题
        期望时间复杂度：O(n²)
        """
        for _ in range(max_tries):
            # 随机初始化赋值
            assignment = [random.choice([True, False]) for _ in range(n_vars)]
            
            for _ in range(2 * n_vars * n_vars):
                # 检查是否满足所有子句
                unsatisfied_clauses = []
                
                for clause in clauses:
                    var1, neg1, var2, neg2 = clause
                    val1 = not assignment[var1] if neg1 else assignment[var1]
                    val2 = not assignment[var2] if neg2 else assignment[var2]
                    
                    if not (val1 or val2):
                        unsatisfied_clauses.append(clause)
                
                if not unsatisfied_clauses:
                    return assignment
                
                # 随机选择一个不满足的子句
                clause = random.choice(unsatisfied_clauses)
                var1, neg1, var2, neg2 = clause
                
                # 随机翻转其中一个变量
                if random.choice([True, False]):
                    assignment[var1] = not assignment[var1]
                else:
                    assignment[var2] = not assignment[var2]
        
        return None


class ProbabilisticDataStructures:
    """
    概率数据结构
    """
    
    @staticmethod
    def count_min_sketch(width, depth):
        """
        Count-Min Sketch
        用于频率估计
        """
        class CountMinSketch:
            def __init__(self, width, depth):
                self.width = width
                self.depth = depth
                self.table = [[0] * width for _ in range(depth)]
                self.hash_funcs = []
                
                # 生成独立的哈希函数
                for i in range(depth):
                    a = random.randint(1, 2**31 - 1)
                    b = random.randint(0, 2**31 - 1)
                    self.hash_funcs.append(lambda x, a=a, b=b: (a * hash(x) + b) % width)
            
            def add(self, item, count=1):
                """添加元素"""
                for i in range(self.depth):
                    j = self.hash_funcs[i](item)
                    self.table[i][j] += count
            
            def estimate(self, item):
                """估计频率"""
                min_count = float('inf')
                
                for i in range(self.depth):
                    j = self.hash_funcs[i](item)
                    min_count = min(min_count, self.table[i][j])
                
                return min_count
        
        return CountMinSketch(width, depth)
    
    @staticmethod
    def hyperloglog(m):
        """
        HyperLogLog算法
        用于基数估计（估计不同元素的数量）
        """
        class HyperLogLog:
            def __init__(self, m):
                self.m = m  # 必须是2的幂
                self.registers = [0] * m
                self.alpha = self._get_alpha(m)
            
            def _get_alpha(self, m):
                """获取修正常数"""
                if m == 16:
                    return 0.673
                elif m == 32:
                    return 0.697
                elif m == 64:
                    return 0.709
                else:
                    return 0.7213 / (1 + 1.079 / m)
            
            def _hash(self, item):
                """哈希函数"""
                return hash(str(item))
            
            def _rho(self, w):
                """计算前导零的个数+1"""
                if w == 0:
                    return 64
                
                rho = 1
                while (w & (1 << (64 - rho))) == 0 and rho <= 64:
                    rho += 1
                
                return rho
            
            def add(self, item):
                """添加元素"""
                x = self._hash(item)
                j = x & (self.m - 1)  # 前log(m)位作为桶索引
                w = x >> int(math.log2(self.m))  # 剩余位
                
                self.registers[j] = max(self.registers[j], self._rho(w))
            
            def count(self):
                """估计基数"""
                raw_estimate = self.alpha * (self.m ** 2) / sum(2 ** (-x) for x in self.registers)
                
                # 小范围修正
                if raw_estimate <= 2.5 * self.m:
                    zeros = self.registers.count(0)
                    if zeros != 0:
                        return self.m * math.log(self.m / zeros)
                
                # 大范围修正
                if raw_estimate <= (1/30) * (2**32):
                    return raw_estimate
                else:
                    return -(2**32) * math.log(1 - raw_estimate / (2**32))
        
        return HyperLogLog(m)


### 4. 并行算法

```python
import multiprocessing
import concurrent.futures
from functools import partial

class ParallelAlgorithms:
    """
    并行算法实现
    """
    
    @staticmethod
    def parallel_merge_sort(arr, num_processes=None):
        """
        并行归并排序
        时间复杂度：O(n log n / p) p为处理器数
        """
        if num_processes is None:
            num_processes = multiprocessing.cpu_count()
        
        def merge(left, right):
            """合并两个有序数组"""
            result = []
            i = j = 0
            
            while i < len(left) and j < len(right):
                if left[i] <= right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
            
            result.extend(left[i:])
            result.extend(right[j:])
            return result
        
        def merge_sort_sequential(arr):
            """顺序归并排序"""
            if len(arr) <= 1:
                return arr
            
            mid = len(arr) // 2
            left = merge_sort_sequential(arr[:mid])
            right = merge_sort_sequential(arr[mid:])
            
            return merge(left, right)
        
        # 当数组较小时使用顺序排序
        if len(arr) <= 10000 or num_processes == 1:
            return merge_sort_sequential(arr)
        
        # 分割数组
        chunk_size = len(arr) // num_processes
        chunks = []
        
        for i in range(num_processes):
            start = i * chunk_size
            end = start + chunk_size if i < num_processes - 1 else len(arr)
            chunks.append(arr[start:end])
        
        # 并行排序每个块
        with multiprocessing.Pool(num_processes) as pool:
            sorted_chunks = pool.map(merge_sort_sequential, chunks)
        
        # 合并排序后的块
        while len(sorted_chunks) > 1:
            merged_chunks = []
            
            for i in range(0, len(sorted_chunks), 2):
                if i + 1 < len(sorted_chunks):
                    merged = merge(sorted_chunks[i], sorted_chunks[i + 1])
                else:
                    merged = sorted_chunks[i]
                merged_chunks.append(merged)
            
            sorted_chunks = merged_chunks
        
        return sorted_chunks[0]
    
    @staticmethod
    def parallel_map_reduce(data, map_func, reduce_func, num_workers=None):
        """
        并行MapReduce框架
        """
        if num_workers is None:
            num_workers = multiprocessing.cpu_count()
        
        # Map阶段
        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:
            # 分割数据
            chunk_size = len(data) // num_workers
            chunks = []
            
            for i in range(num_workers):
                start = i * chunk_size
                end = start + chunk_size if i < num_workers - 1 else len(data)
                chunks.append(data[start:end])
            
            # 并行执行map
            map_results = list(executor.map(
                lambda chunk: [map_func(item) for item in chunk],
                chunks
            ))
        
        # 展平结果
        flat_results = []
        for chunk_result in map_results:
            flat_results.extend(chunk_result)
        
        # Reduce阶段
        result = flat_results[0]
        for item in flat_results[1:]:
            result = reduce_func(result, item)
        
        return result
    
    @staticmethod
    def parallel_matrix_multiply(A, B, num_processes=None):
        """
        并行矩阵乘法
        时间复杂度：O(n³ / p)
        """
        if num_processes is None:
            num_processes = multiprocessing.cpu_count()
        
        rows_A, cols_A = len(A), len(A[0])
        rows_B, cols_B = len(B), len(B[0])
        
        if cols_A != rows_B:
            raise ValueError("矩阵维度不匹配")
        
        def compute_row(i, A, B):
            """计算结果矩阵的第i行"""
            row = []
            for j in range(cols_B):
                total = 0
                for k in range(cols_A):
                    total += A[i][k] * B[k][j]
                row.append(total)
            return i, row
        
        # 并行计算每行
        with multiprocessing.Pool(num_processes) as pool:
            compute_func = partial(compute_row, A=A, B=B)
            results = pool.map(compute_func, range(rows_A))
        
        # 组装结果矩阵
        C = [[0] * cols_B for _ in range(rows_A)]
        for i, row in results:
            C[i] = row
        
        return C
    
    @staticmethod
    def parallel_prefix_sum(arr, num_processes=None):
        """
        并行前缀和（扫描）算法
        时间复杂度：O(n / p + log p)
        """
        if num_processes is None:
            num_processes = multiprocessing.cpu_count()
        
        n = len(arr)
        if n <= 1:
            return arr
        
        # 分块计算局部前缀和
        chunk_size = n // num_processes
        chunks = []
        
        for i in range(num_processes):
            start = i * chunk_size
            end = start + chunk_size if i < num_processes - 1 else n
            chunks.append((start, end))
        
        def compute_local_prefix(chunk_info):
            """计算局部前缀和"""
            start, end = chunk_info
            local_sum = 0
            local_prefix = []
            
            for i in range(start, end):
                local_sum += arr[i]
                local_prefix.append(local_sum)
            
            return local_prefix, local_sum
        
        # 并行计算每个块的前缀和
        with multiprocessing.Pool(num_processes) as pool:
            results = pool.map(compute_local_prefix, chunks)
        
        # 计算块间的偏移量
        block_sums = [result[1] for result in results]
        block_offsets = [0]
        
        for i in range(len(block_sums) - 1):
            block_offsets.append(block_offsets[-1] + block_sums[i])
        
        # 合并结果
        prefix_sum = []
        for i, (local_prefix, _) in enumerate(results):
            offset = block_offsets[i]
            for val in local_prefix:
                prefix_sum.append(val + offset)
        
        return prefix_sum
    
    @staticmethod
    def parallel_quicksort(arr, num_processes=None):
        """
        并行快速排序
        时间复杂度：O(n log n / p) 期望情况
        """
        if num_processes is None:
            num_processes = multiprocessing.cpu_count()
        
        def partition(arr):
            """分区操作"""
            if len(arr) <= 1:
                return arr, [], []
            
            pivot = arr[len(arr) // 2]
            left = [x for x in arr if x < pivot]
            middle = [x for x in arr if x == pivot]
            right = [x for x in arr if x > pivot]
            
            return left, middle, right
        
        def quicksort_sequential(arr):
            """顺序快速排序"""
            if len(arr) <= 1:
                return arr
            
            left, middle, right = partition(arr)
            return quicksort_sequential(left) + middle + quicksort_sequential(right)
        
        # 对于小数组使用顺序排序
        if len(arr) <= 10000:
            return quicksort_sequential(arr)
        
        # 分区
        left, middle, right = partition(arr)
        
        # 并行排序左右两部分
        with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:
            left_future = executor.submit(ParallelAlgorithms.parallel_quicksort, left, num_processes // 2)
            right_future = executor.submit(ParallelAlgorithms.parallel_quicksort, right, num_processes // 2)
            
            sorted_left = left_future.result()
            sorted_right = right_future.result()
        
        return sorted_left + middle + sorted_right


class GPUAlgorithms:
    """
    GPU并行算法示例（概念性实现）
    实际使用需要CUDA或OpenCL
    """
    
    @staticmethod
    def gpu_matrix_multiply_concept(A, B):
        """
        GPU矩阵乘法概念
        每个线程计算结果矩阵的一个元素
        """
        rows_A, cols_A = len(A), len(A[0])
        rows_B, cols_B = len(B), len(B[0])
        
        # 模拟GPU kernel
        def kernel(i, j, A, B):
            """计算C[i][j]"""
            total = 0
            for k in range(cols_A):
                total += A[i][k] * B[k][j]
            return total
        
        # 模拟并行执行
        C = [[0] * cols_B for _ in range(rows_A)]
        
        # 在实际GPU中，这些计算是并行的
        for i in range(rows_A):
            for j in range(cols_B):
                C[i][j] = kernel(i, j, A, B)
        
        return C
    
    @staticmethod
    def gpu_parallel_reduction_concept(arr):
        """
        GPU并行规约概念（如求和）
        使用树形规约
        """
        n = len(arr)
        temp = arr[:]
        
        # 模拟多轮规约
        stride = 1
        while stride < n:
            # 模拟并行执行
            new_temp = temp[:]
            
            for i in range(0, n, stride * 2):
                if i + stride < n:
                    new_temp[i] = temp[i] + temp[i + stride]
            
            temp = new_temp
            stride *= 2
        
        return temp[0]
    
    @staticmethod
    def gpu_histogram_concept(data, num_bins):
        """
        GPU直方图计算概念
        使用原子操作避免冲突
        """
        min_val = min(data)
        max_val = max(data)
        bin_width = (max_val - min_val) / num_bins
        
        # 初始化直方图
        histogram = [0] * num_bins
        
        # 模拟并行计算
        # 在实际GPU中使用原子加法
        for value in data:
            bin_index = int((value - min_val) / bin_width)
            if bin_index == num_bins:
                bin_index = num_bins - 1
            
            # 原子操作
            histogram[bin_index] += 1
        
        return histogram
~~~

## 第七部分：机器学习相关算法

### 1. 梯度下降与优化算法

```python
import numpy as np

class GradientDescent:
    """
    梯度下降优化算法
    """
    
    @staticmethod
    def gradient_descent(f, grad_f, x0, learning_rate=0.01, max_iter=1000, tol=1e-6):
        """
        基本梯度下降
        f: 目标函数
        grad_f: 梯度函数
        x0: 初始点
        """
        x = x0.copy()
        history = [x.copy()]
        
        for i in range(max_iter):
            # 计算梯度
            grad = grad_f(x)
            
            # 更新参数
            x_new = x - learning_rate * grad
            
            # 检查收敛
            if np.linalg.norm(x_new - x) < tol:
                break
            
            x = x_new
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def stochastic_gradient_descent(X, y, loss_grad, w0, learning_rate=0.01, 
                                   batch_size=1, epochs=100):
        """
        随机梯度下降
        X: 训练数据
        y: 标签
        loss_grad: 损失函数的梯度
        """
        n_samples = len(X)
        w = w0.copy()
        history = []
        
        for epoch in range(epochs):
            # 打乱数据
            indices = np.random.permutation(n_samples)
            
            for i in range(0, n_samples, batch_size):
                batch_indices = indices[i:i + batch_size]
                X_batch = X[batch_indices]
                y_batch = y[batch_indices]
                
                # 计算批量梯度
                grad = loss_grad(X_batch, y_batch, w)
                
                # 更新权重
                w -= learning_rate * grad
            
            history.append(w.copy())
        
        return w, history
    
    @staticmethod
    def momentum_gradient_descent(f, grad_f, x0, learning_rate=0.01, 
                                 momentum=0.9, max_iter=1000):
        """
        动量梯度下降
        """
        x = x0.copy()
        velocity = np.zeros_like(x)
        history = [x.copy()]
        
        for i in range(max_iter):
            # 计算梯度
            grad = grad_f(x)
            
            # 更新速度
            velocity = momentum * velocity - learning_rate * grad
            
            # 更新参数
            x += velocity
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def nesterov_accelerated_gradient(f, grad_f, x0, learning_rate=0.01, 
                                     momentum=0.9, max_iter=1000):
        """
        Nesterov加速梯度下降
        """
        x = x0.copy()
        velocity = np.zeros_like(x)
        history = [x.copy()]
        
        for i in range(max_iter):
            # 预测位置
            x_ahead = x + momentum * velocity
            
            # 在预测位置计算梯度
            grad = grad_f(x_ahead)
            
            # 更新速度和位置
            velocity = momentum * velocity - learning_rate * grad
            x += velocity
            
            history.append(x.copy())
        
        return x, history


class AdaptiveOptimizers:
    """
    自适应优化算法
    """
    
    @staticmethod
    def adagrad(grad_f, x0, learning_rate=0.01, epsilon=1e-8, max_iter=1000):
        """
        AdaGrad优化器
        自适应调整学习率
        """
        x = x0.copy()
        accumulated_grad = np.zeros_like(x)
        history = [x.copy()]
        
        for i in range(max_iter):
            # 计算梯度
            grad = grad_f(x)
            
            # 累积梯度平方
            accumulated_grad += grad ** 2
            
            # 自适应学习率更新
            x -= learning_rate * grad / (np.sqrt(accumulated_grad) + epsilon)
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def rmsprop(grad_f, x0, learning_rate=0.01, decay_rate=0.9, 
                epsilon=1e-8, max_iter=1000):
        """
        RMSProp优化器
        """
        x = x0.copy()
        squared_grad = np.zeros_like(x)
        history = [x.copy()]
        
        for i in range(max_iter):
            # 计算梯度
            grad = grad_f(x)
            
            # 指数移动平均
            squared_grad = decay_rate * squared_grad + (1 - decay_rate) * grad ** 2
            
            # 更新参数
            x -= learning_rate * grad / (np.sqrt(squared_grad) + epsilon)
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def adam(grad_f, x0, learning_rate=0.001, beta1=0.9, beta2=0.999, 
             epsilon=1e-8, max_iter=1000):
        """
        Adam优化器
        结合动量和RMSProp
        """
        x = x0.copy()
        m = np.zeros_like(x)  # 一阶矩估计
        v = np.zeros_like(x)  # 二阶矩估计
        history = [x.copy()]
        
        for t in range(1, max_iter + 1):
            # 计算梯度
            grad = grad_f(x)
            
            # 更新一阶矩估计
            m = beta1 * m + (1 - beta1) * grad
            
            # 更新二阶矩估计
            v = beta2 * v + (1 - beta2) * grad ** 2
            
            # 偏差修正
            m_hat = m / (1 - beta1 ** t)
            v_hat = v / (1 - beta2 ** t)
            
            # 更新参数
            x -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def adamw(grad_f, x0, learning_rate=0.001, beta1=0.9, beta2=0.999, 
              epsilon=1e-8, weight_decay=0.01, max_iter=1000):
        """
        AdamW优化器（带权重衰减）
        """
        x = x0.copy()
        m = np.zeros_like(x)
        v = np.zeros_like(x)
        history = [x.copy()]
        
        for t in range(1, max_iter + 1):
            # 计算梯度
            grad = grad_f(x)
            
            # 权重衰减
            grad += weight_decay * x
            
            # Adam更新
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad ** 2
            
            m_hat = m / (1 - beta1 ** t)
            v_hat = v / (1 - beta2 ** t)
            
            x -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)
            
            history.append(x.copy())
        
        return x, history


class SecondOrderOptimizers:
    """
    二阶优化算法
    """
    
    @staticmethod
    def newton_method(f, grad_f, hess_f, x0, max_iter=100, tol=1e-6):
        """
        牛顿法
        需要二阶导数（Hessian矩阵）
        时间复杂度：O(n³) per iteration
        """
        x = x0.copy()
        history = [x.copy()]
        
        for i in range(max_iter):
            # 计算梯度和Hessian
            grad = grad_f(x)
            hess = hess_f(x)
            
            # 求解牛顿方向
            try:
                direction = np.linalg.solve(hess, -grad)
            except np.linalg.LinAlgError:
                # Hessian奇异，使用梯度下降
                direction = -grad
            
            # 更新参数
            x += direction
            
            # 检查收敛
            if np.linalg.norm(grad) < tol:
                break
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def quasi_newton_bfgs(f, grad_f, x0, max_iter=100):
        """
        拟牛顿法（BFGS）
        不需要显式计算Hessian
        """
        n = len(x0)
        x = x0.copy()
        H = np.eye(n)  # 初始化为单位矩阵
        history = [x.copy()]
        
        grad = grad_f(x)
        
        for i in range(max_iter):
            # 计算搜索方向
            direction = -H @ grad
            
            # 线搜索确定步长
            alpha = SecondOrderOptimizers._line_search(f, grad_f, x, direction)
            
            # 更新位置
            s = alpha * direction
            x_new = x + s
            
            # 计算梯度差
            grad_new = grad_f(x_new)
            y = grad_new - grad
            
            # BFGS更新公式
            rho = 1.0 / (y @ s)
            I = np.eye(n)
            H = (I - rho * np.outer(s, y)) @ H @ (I - rho * np.outer(y, s)) + rho * np.outer(s, s)
            
            x = x_new
            grad = grad_new
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def _line_search(f, grad_f, x, direction, alpha=1.0, c1=1e-4, c2=0.9):
        """
        Wolfe条件线搜索
        """
        # Armijo条件和Wolfe条件
        while True:
            if f(x + alpha * direction) <= f(x) + c1 * alpha * (grad_f(x) @ direction):
                if grad_f(x + alpha * direction) @ direction >= c2 * (grad_f(x) @ direction):
                    break
            alpha *= 0.5
            
            if alpha < 1e-8:
                break
        
        return alpha
    
    @staticmethod
    def conjugate_gradient(A, b, x0=None, max_iter=None, tol=1e-6):
        """
        共轭梯度法
        求解线性方程组 Ax = b
        时间复杂度：O(n²) per iteration
        """
        n = len(b)
        if x0 is None:
            x = np.zeros(n)
        else:
            x = x0.copy()
        
        if max_iter is None:
            max_iter = n
        
        r = b - A @ x
        p = r.copy()
        r_norm_sq = r @ r
        
        history = [x.copy()]
        
        for i in range(max_iter):
            if r_norm_sq < tol ** 2:
                break
            
            Ap = A @ p
            alpha = r_norm_sq / (p @ Ap)
            x += alpha * p
            r -= alpha * Ap
            
            r_norm_sq_new = r @ r
            beta = r_norm_sq_new / r_norm_sq
            p = r + beta * p
            
            r_norm_sq = r_norm_sq_new
            history.append(x.copy())
        
        return x, history


class ConstrainedOptimization:
    """
    约束优化算法
    """
    
    @staticmethod
    def projected_gradient_descent(f, grad_f, projection, x0, 
                                  learning_rate=0.01, max_iter=1000):
        """
        投影梯度下降
        用于约束优化问题
        """
        x = x0.copy()
        history = [x.copy()]
        
        for i in range(max_iter):
            # 梯度下降步
            grad = grad_f(x)
            x_temp = x - learning_rate * grad
            
            # 投影到可行域
            x = projection(x_temp)
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def frank_wolfe(f, grad_f, constraint_set, x0, max_iter=1000):
        """
        Frank-Wolfe算法（条件梯度法）
        用于凸约束优化
        """
        x = x0.copy()
        history = [x.copy()]
        
        for k in range(max_iter):
            # 计算梯度
            grad = grad_f(x)
            
            # 线性最小化步骤
            s = constraint_set.linear_minimization_oracle(-grad)
            
            # 计算步长
            gamma = 2.0 / (k + 2)  # 可以使用线搜索
            
            # 更新
            x = (1 - gamma) * x + gamma * s
            
            history.append(x.copy())
        
        return x, history
    
    @staticmethod
    def augmented_lagrangian(f, grad_f, h, grad_h, x0, rho=1.0, max_iter=100):
        """
        增广拉格朗日方法
        求解等式约束优化问题
        min f(x) s.t. h(x) = 0
        """
        x = x0.copy()
        lambda_val = np.zeros(len(h(x0)))  # 拉格朗日乘子
        history = []
        
        for outer_iter in range(max_iter):
            # 定义增广拉格朗日函数
            def augmented_f(x):
                return f(x) + lambda_val @ h(x) + 0.5 * rho * np.linalg.norm(h(x)) ** 2
            
            def augmented_grad_f(x):
                return grad_f(x) + grad_h(x).T @ (lambda_val + rho * h(x))
            
            # 无约束优化子问题
            x, _ = GradientDescent.gradient_descent(
                augmented_f, augmented_grad_f, x, max_iter=50
            )
            
            # 更新拉格朗日乘子
            lambda_val += rho * h(x)
            
            history.append(x.copy())
            
            # 检查约束违反
            if np.linalg.norm(h(x)) < 1e-6:
                break
        
        return x, history
```

### 2. 聚类算法

```python
class KMeans:
    """
    K-Means聚类算法
    """
    
    def __init__(self, n_clusters=3, max_iter=300, tol=1e-4, init='random'):
        self.n_clusters = n_clusters
        self.max_iter = max_iter
        self.tol = tol
        self.init = init
        self.centers = None
        self.labels = None
        self.inertia = None
    
    def fit(self, X):
        """
        训练K-Means模型
        时间复杂度：O(nkt) n:样本数, k:簇数, t:迭代次数
        """
        n_samples = len(X)
        
        # 初始化聚类中心
        if self.init == 'random':
            indices = np.random.choice(n_samples, self.n_clusters, replace=False)
            self.centers = X[indices].copy()
        elif self.init == 'k-means++':
            self.centers = self._kmeans_plus_plus_init(X)
        
        # 迭代优化
        for iteration in range(self.max_iter):
            # 分配样本到最近的中心
            self.labels = self._assign_clusters(X)
            
            # 更新聚类中心
            new_centers = self._update_centers(X)
            
            # 检查收敛
            if np.allclose(self.centers, new_centers, atol=self.tol):
                break
            
            self.centers = new_centers
        
        # 计算惯性（损失函数值）
        self.inertia = self._compute_inertia(X)
        
        return self
    
    def _kmeans_plus_plus_init(self, X):
        """
        K-Means++初始化
        更好的初始中心选择
        """
        n_samples = len(X)
        centers = []
        
        # 随机选择第一个中心
        first_center = X[np.random.randint(n_samples)]
        centers.append(first_center)
        
        # 选择剩余的中心
        for _ in range(1, self.n_clusters):
            # 计算每个点到最近中心的距离
            distances = np.array([
                min(np.linalg.norm(x - c) ** 2 for c in centers)
                for x in X
            ])
            
            # 按概率选择下一个中心
            probabilities = distances / distances.sum()
            cumulative_probs = probabilities.cumsum()
            r = np.random.rand()
            
            for i, p in enumerate(cumulative_probs):
                if r < p:
                    centers.append(X[i])
                    break
        
        return np.array(centers)
    
    def _assign_clusters(self, X):
        """分配样本到最近的聚类中心"""
        distances = np.zeros((len(X), self.n_clusters))
        
        for i, center in enumerate(self.centers):
            distances[:, i] = np.linalg.norm(X - center, axis=1)
        
        return np.argmin(distances, axis=1)
    
    def _update_centers(self, X):
        """更新聚类中心"""
        new_centers = np.zeros_like(self.centers)
        
        for k in range(self.n_clusters):
            mask = self.labels == k
            if np.any(mask):
                new_centers[k] = X[mask].mean(axis=0)
            else:
                # 如果簇为空，保持原中心
                new_centers[k] = self.centers[k]
        
        return new_centers
    
    def _compute_inertia(self, X):
        """计算惯性（所有样本到其聚类中心的距离平方和）"""
        inertia = 0
        for i, x in enumerate(X):
            inertia += np.linalg.norm(x - self.centers[self.labels[i]]) ** 2
        return inertia
    
    def predict(self, X):
        """预测新样本的聚类标签"""
        return self._assign_clusters(X)
    
    def elbow_method(self, X, max_k=10):
        """
        肘部法则确定最佳聚类数
        """
        inertias = []
        
        for k in range(1, max_k + 1):
            kmeans = KMeans(n_clusters=k)
            kmeans.fit(X)
            inertias.append(kmeans.inertia)
        
        return inertias


class DBSCAN:
    """
    DBSCAN密度聚类算法
    """
    
    def __init__(self, eps=0.5, min_samples=5):
        self.eps = eps
        self.min_samples = min_samples
        self.labels = None
        self.core_points = None
    
    def fit(self, X):
        """
        训练DBSCAN模型
        时间复杂度：O(n²) 最坏情况，O(n log n) 使用空间索引
        """
        n_samples = len(X)
        self.labels = np.full(n_samples, -1)  # -1表示噪声点
        self.core_points = []
        
        cluster_id = 0
        
        for i in range(n_samples):
            # 跳过已处理的点
            if self.labels[i] != -1:
                continue
            
            # 找到邻居
            neighbors = self._get_neighbors(X, i)
            
            if len(neighbors) < self.min_samples:
                # 噪声点
                continue
            
            # 核心点，开始新的簇
            self.core_points.append(i)
            self._expand_cluster(X, i, neighbors, cluster_id)
            cluster_id += 1
        
        return self
    
    def _get_neighbors(self, X, point_idx):
        """获取点的ε-邻域"""
        distances = np.linalg.norm(X - X[point_idx], axis=1)
        return np.where(distances <= self.eps)[0]
    
    def _expand_cluster(self, X, point_idx, neighbors, cluster_id):
        """扩展簇"""
        self.labels[point_idx] = cluster_id
        
        i = 0
        while i < len(neighbors):
            neighbor_idx = neighbors[i]
            
            if self.labels[neighbor_idx] == -1:
                # 噪声点变为边界点
                self.labels[neighbor_idx] = cluster_id
            elif self.labels[neighbor_idx] == -1:
                # 未访问的点
                self.labels[neighbor_idx] = cluster_id
                
                # 获取邻居的邻居
                neighbor_neighbors = self._get_neighbors(X, neighbor_idx)
                
                if len(neighbor_neighbors) >= self.min_samples:
                    # 核心点，扩展邻居集合
                    self.core_points.append(neighbor_idx)
                    neighbors = np.concatenate([neighbors, neighbor_neighbors])
                    neighbors = np.unique(neighbors)
            
            i += 1
    
    def predict(self, X):
        """
        预测新样本（基于最近的核心点）
        """
        if self.core_points is None:
            raise ValueError("模型未训练")
        
        predictions = []
        
        for x in X:
            min_dist = float('inf')
            closest_cluster = -1
            
            for core_point in self.core_points:
                dist = np.linalg.norm(x - X[core_point])
                if dist < min_dist and dist <= self.eps:
                    min_dist = dist
                    closest_cluster = self.labels[core_point]
            
            predictions.append(closest_cluster)
        
        return np.array(predictions)


class HierarchicalClustering:
    """
    层次聚类算法
    """
    
    def __init__(self, n_clusters=2, linkage='single'):
        self.n_clusters = n_clusters
        self.linkage = linkage
        self.labels = None
        self.linkage_matrix = None
    
    def fit(self, X):
        """
        训练层次聚类模型
        时间复杂度：O(n³) 朴素实现，O(n² log n) 优化实现
        """
        n_samples = len(X)
        
        # 初始化：每个样本是一个簇
        clusters = [[i] for i in range(n_samples)]
        distances = self._compute_distance_matrix(X)
        
        # 记录合并历史
        self.linkage_matrix = []
        
        # 凝聚过程
        cluster_id = n_samples
        
        while len(clusters) > self.n_clusters:
            # 找到最近的两个簇
            min_dist = float('inf')
            merge_i, merge_j = 0, 1
            
            for i in range(len(clusters)):
                for j in range(i + 1, len(clusters)):
                    dist = self._cluster_distance(
                        clusters[i], clusters[j], distances
                    )
                    
                    if dist < min_dist:
                        min_dist = dist
                        merge_i, merge_j = i, j
            
            # 合并簇
            new_cluster = clusters[merge_i] + clusters[merge_j]
            
            # 记录合并
            self.linkage_matrix.append([
                min(clusters[merge_i]),
                min(clusters[merge_j]),
                min_dist,
                len(new_cluster)
            ])
            
            # 更新簇列表
            clusters.append(new_cluster)
            clusters.pop(max(merge_i, merge_j))
            clusters.pop(min(merge_i, merge_j))
            
            cluster_id += 1
        
        # 生成标签
        self.labels = np.zeros(n_samples, dtype=int)
        for cluster_idx, cluster in enumerate(clusters):
            for sample_idx in cluster:
                self.labels[sample_idx] = cluster_idx
        
        return self
    
    def _compute_distance_matrix(self, X):
        """计算距离矩阵"""
        n_samples = len(X)
        distances = np.zeros((n_samples, n_samples))
        
        for i in range(n_samples):
            for j in range(i + 1, n_samples):
                dist = np.linalg.norm(X[i] - X[j])
                distances[i, j] = distances[j, i] = dist
        
        return distances
    
    def _cluster_distance(self, cluster1, cluster2, distances):
        """计算两个簇之间的距离"""
        if self.linkage == 'single':
            # 最短距离
            return min(
                distances[i, j]
                for i in cluster1
                for j in cluster2
            )
        elif self.linkage == 'complete':
            # 最长距离
            return max(
                distances[i, j]
                for i in cluster1
                for j in cluster2
            )
        elif self.linkage == 'average':
            # 平均距离
            total = sum(
                distances[i, j]
                for i in cluster1
                for j in cluster2
            )
            return total / (len(cluster1) * len(cluster2))
        elif self.linkage == 'ward':
            # Ward距离（最小化簇内方差）
            # 简化实现，实际应使用Lance-Williams公式
            return self._ward_distance(cluster1, cluster2, distances)
    
    def _ward_distance(self, cluster1, cluster2, distances):
        """Ward链接距离"""
        n1, n2 = len(cluster1), len(cluster2)
        
        # 计算合并后的方差增量
        within_cluster1 = sum(
            distances[i, j] ** 2
            for i in cluster1
            for j in cluster1
        ) / (2 * n1)
        
        within_cluster2 = sum(
            distances[i, j] ** 2
            for i in cluster2
            for j in cluster2
        ) / (2 * n2)
        
        within_merged = sum(
            distances[i, j] ** 2
            for i in cluster1 + cluster2
            for j in cluster1 + cluster2
        ) / (2 * (n1 + n2))
        
        return within_merged - within_cluster1 - within_cluster2


class SpectralClustering:
    """
    谱聚类算法
    """
    
    def __init__(self, n_clusters=2, sigma=1.0):
        self.n_clusters = n_clusters
        self.sigma = sigma
        self.labels = None
    
    def fit(self, X):
        """
        训练谱聚类模型
        时间复杂度：O(n³) 主要在特征值分解
        """
        n_samples = len(X)
        
        # 构建相似度矩阵（高斯核）
        W = self._build_similarity_matrix(X)
        
        # 计算度矩阵
        D = np.diag(W.sum(axis=1))
        
        # 计算拉普拉斯矩阵
        L = D - W
        
        # 计算归一化拉普拉斯矩阵
        D_sqrt_inv = np.diag(1.0 / np.sqrt(D.diagonal()))
        L_norm = D_sqrt_inv @ L @ D_sqrt_inv
        
        # 特征值分解
        eigenvalues, eigenvectors = np.linalg.eigh(L_norm)
        
        # 选择前k个最小特征值对应的特征向量
        idx = eigenvalues.argsort()[:self.n_clusters]
        embedding = eigenvectors[:, idx]
        
        # 归一化行向量
        row_norms = np.linalg.norm(embedding, axis=1, keepdims=True)
        embedding /= row_norms
        
        # 在嵌入空间中进行K-means聚类
        kmeans = KMeans(n_clusters=self.n_clusters)
        kmeans.fit(embedding)
        self.labels = kmeans.labels
        
        return self
    
    def _build_similarity_matrix(self, X):
        """构建相似度矩阵"""
        n_samples = len(X)
        W = np.zeros((n_samples, n_samples))
        
        for i in range(n_samples):
            for j in range(i + 1, n_samples):
                # 高斯核
                dist_sq = np.linalg.norm(X[i] - X[j]) ** 2
                similarity = np.exp(-dist_sq / (2 * self.sigma ** 2))
                W[i, j] = W[j, i] = similarity
        
        return W
```

### 3. 决策树与随机森林

```python
class DecisionTree:
    """
    决策树（分类和回归）
    """
    
    def __init__(self, max_depth=None, min_samples_split=2, 
                 min_samples_leaf=1, criterion='gini'):
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.min_samples_leaf = min_samples_leaf
        self.criterion = criterion
        self.root = None
        self.n_features = None
        self.n_classes = None
    
    def fit(self, X, y):
        """
        训练决策树
        时间复杂度：O(n·m·log(n)) n为样本数，m为特征数
        """
        self.n_features = X.shape[1]
        
        # 分类任务
        if self.criterion in ['gini', 'entropy']:
            self.n_classes = len(np.unique(y))
        
        # 构建决策树
        self.root = self._build_tree(X, y, depth=0)
        
        return self
    
    def _build_tree(self, X, y, depth):
        """递归构建决策树"""
        n_samples = len(y)
        
        # 创建节点
        node = DecisionTreeNode()
        node.samples = n_samples
        
        # 计算当前节点的不纯度
        if self.criterion in ['gini', 'entropy']:
            node.impurity = self._calculate_impurity(y)
            node.value = self._get_leaf_value_classification(y)
        else:  # mse
            node.impurity = self._calculate_mse(y)
            node.value = self._get_leaf_value_regression(y)
        
        # 停止条件
        if (self.max_depth is not None and depth >= self.max_depth) or \
           n_samples < self.min_samples_split or \
           node.impurity == 0:
            return node
        
        # 寻找最佳分裂
        best_feature, best_threshold = self._find_best_split(X, y)
        
        if best_feature is None:
            return node
        
        # 分裂数据
        left_idx = X[:, best_feature] <= best_threshold
        right_idx = ~left_idx
        
        # 检查最小叶子节点样本数
        if np.sum(left_idx) < self.min_samples_leaf or \
           np.sum(right_idx) < self.min_samples_leaf:
            return node
        
        # 记录分裂信息
        node.feature = best_feature
        node.threshold = best_threshold
        
        # 递归构建子树
        node.left = self._build_tree(X[left_idx], y[left_idx], depth + 1)
        node.right = self._build_tree(X[right_idx], y[right_idx], depth + 1)
        
        return node
    
    def _calculate_impurity(self, y):
        """计算不纯度"""
        n_samples = len(y)
        if n_samples == 0:
            return 0
        
        # 计算类别比例
        _, counts = np.unique(y, return_counts=True)
        proportions = counts / n_samples
        
        if self.criterion == 'gini':
            # 基尼不纯度
            return 1 - np.sum(proportions ** 2)
        elif self.criterion == 'entropy':
            # 信息熵
            entropy = 0
            for p in proportions:
                if p > 0:
                    entropy -= p * np.log2(p)
            return entropy
    
    def _calculate_mse(self, y):
        """计算均方误差"""
        if len(y) == 0:
            return 0
        return np.var(y)
    
    def _find_best_split(self, X, y):
        """寻找最佳分裂点"""
        best_gain = -float('inf')
        best_feature = None
        best_threshold = None
        
        n_samples = len(y)
        
        # 计算父节点的不纯度
        if self.criterion in ['gini', 'entropy']:
            parent_impurity = self._calculate_impurity(y)
        else:
            parent_impurity = self._calculate_mse(y)
        
        # 遍历所有特征
        for feature in range(self.n_features):
            # 获取特征的唯一值作为候选阈值
            thresholds = np.unique(X[:, feature])
            
            # 遍历所有可能的阈值
            for threshold in thresholds[:-1]:  # 不需要最后一个
                # 分裂数据
                left_idx = X[:, feature] <= threshold
                right_idx = ~left_idx
                
                n_left = np.sum(left_idx)
                n_right = np.sum(right_idx)
                
                # 跳过会产生空子节点的分裂
                if n_left == 0 or n_right == 0:
                    continue
                
                # 计算子节点的不纯度
                if self.criterion in ['gini', 'entropy']:
                    left_impurity = self._calculate_impurity(y[left_idx])
                    right_impurity = self._calculate_impurity(y[right_idx])
                else:
                    left_impurity = self._calculate_mse(y[left_idx])
                    right_impurity = self._calculate_mse(y[right_idx])
                
                # 计算信息增益
                weighted_impurity = (n_left / n_samples) * left_impurity + \
                                  (n_right / n_samples) * right_impurity
                gain = parent_impurity - weighted_impurity
                
                # 更新最佳分裂
                if gain > best_gain:
                    best_gain = gain
                    best_feature = feature
                    best_threshold = threshold
        
        return best_feature, best_threshold
    
    def _get_leaf_value_classification(self, y):
        """获取分类任务的叶节点值（众数）"""
        if len(y) == 0:
            return 0
        values, counts = np.unique(y, return_counts=True)
        return values[np.argmax(counts)]
    
    def _get_leaf_value_regression(self, y):
        """获取回归任务的叶节点值（均值）"""
        if len(y) == 0:
            return 0
        return np.mean(y)
    
    def predict(self, X):
        """预测"""
        return np.array([self._predict_sample(x) for x in X])
    
    def _predict_sample(self, x):
        """预测单个样本"""
        node = self.root
        
        while node.left is not None:
            if x[node.feature] <= node.threshold:
                node = node.left
            else:
                node = node.right
        
        return node.value
    
    def predict_proba(self, X):
        """预测概率（仅分类任务）"""
        if self.criterion not in ['gini', 'entropy']:
            raise ValueError("predict_proba仅支持分类任务")
        
        return np.array([self._predict_proba_sample(x) for x in X])
    
    def _predict_proba_sample(self, x):
        """预测单个样本的概率"""
        node = self.root
        
        # 遍历到叶节点
        while node.left is not None:
            if x[node.feature] <= node.threshold:
                node = node.left
            else:
                node = node.right
        
        # 返回类别概率（这里简化处理）
        proba = np.zeros(self.n_classes)
        proba[int(node.value)] = 1.0
        return proba
    
    def get_feature_importance(self):
        """计算特征重要性"""
        importance = np.zeros(self.n_features)
        
        def traverse(node, samples):
            if node.left is None:
                return
            
            # 计算信息增益
            gain = node.impurity * samples
            gain -= node.left.impurity * node.left.samples
            gain -= node.right.impurity * node.right.samples
            
            importance[node.feature] += gain
            
            traverse(node.left, node.left.samples)
            traverse(node.right, node.right.samples)
        
        if self.root is not None:
            traverse(self.root, self.root.samples)
        
        # 归一化
        if np.sum(importance) > 0:
            importance /= np.sum(importance)
        
        return importance


class RandomForest:
    """
    随机森林算法
    """
    
    def __init__(self, n_estimators=100, max_depth=None, 
                 min_samples_split=2, min_samples_leaf=1,
                 max_features='sqrt', bootstrap=True,
                 criterion='gini', random_state=None):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.min_samples_leaf = min_samples_leaf
        self.max_features = max_features
        self.bootstrap = bootstrap
        self.criterion = criterion
        self.random_state = random_state
        self.trees = []
        self.feature_indices = []
    
    def fit(self, X, y):
        """
        训练随机森林
        时间复杂度：O(n·m·log(n)·k) k为树的数量
        """
        n_samples, n_features = X.shape
        
        # 设置随机种子
        if self.random_state is not None:
            np.random.seed(self.random_state)
        
        # 确定每棵树使用的特征数
        if self.max_features == 'sqrt':
            max_features = int(np.sqrt(n_features))
        elif self.max_features == 'log2':
            max_features = int(np.log2(n_features))
        elif isinstance(self.max_features, int):
            max_features = self.max_features
        else:
            max_features = n_features
        
        # 训练多棵决策树
        for i in range(self.n_estimators):
            # Bootstrap采样
            if self.bootstrap:
                indices = np.random.choice(n_samples, n_samples, replace=True)
                X_sample = X[indices]
                y_sample = y[indices]
            else:
                X_sample = X
                y_sample = y
            
            # 随机选择特征
            feature_indices = np.random.choice(
                n_features, max_features, replace=False
            )
            self.feature_indices.append(feature_indices)
            
            # 训练决策树
            tree = DecisionTree(
                max_depth=self.max_depth,
                min_samples_split=self.min_samples_split,
                min_samples_leaf=self.min_samples_leaf,
                criterion=self.criterion
            )
            
            tree.fit(X_sample[:, feature_indices], y_sample)
            self.trees.append(tree)
        
        return self
    
    def predict(self, X):
        """
        预测
        分类：投票
        回归：平均
        """
        predictions = []
        
        for tree, features in zip(self.trees, self.feature_indices):
            pred = tree.predict(X[:, features])
            predictions.append(pred)
        
        predictions = np.array(predictions)
        
        if self.criterion in ['gini', 'entropy']:
            # 分类：投票
            final_predictions = []
            for i in range(X.shape[0]):
                votes = predictions[:, i]
                values, counts = np.unique(votes, return_counts=True)
                final_predictions.append(values[np.argmax(counts)])
            return np.array(final_predictions)
        else:
            # 回归：平均
            return np.mean(predictions, axis=0)
    
    def predict_proba(self, X):
        """预测概率（仅分类）"""
        if self.criterion not in ['gini', 'entropy']:
            raise ValueError("predict_proba仅支持分类任务")
        
        # 收集所有树的预测概率
        all_proba = []
        
        for tree, features in zip(self.trees, self.feature_indices):
            proba = tree.predict_proba(X[:, features])
            all_proba.append(proba)
        
        # 平均概率
        return np.mean(all_proba, axis=0)
    
    def get_feature_importance(self):
        """
        计算特征重要性
        平均所有树的特征重要性
        """
        n_features = len(self.feature_indices[0])
        importance = np.zeros(n_features)
        
        for tree, features in zip(self.trees, self.feature_indices):
            tree_importance = tree.get_feature_importance()
            for i, feat_idx in enumerate(features):
                importance[feat_idx] += tree_importance[i]
        
        # 归一化
        importance /= self.n_estimators
        return importance
    
    def oob_score(self, X, y):
        """
        计算袋外误差（Out-of-Bag Error）
        仅在bootstrap=True时可用
        """
        if not self.bootstrap:
            raise ValueError("OOB score需要bootstrap=True")
        
        n_samples = X.shape[0]
        oob_predictions = [[] for _ in range(n_samples)]
        
        # 重新训练并记录OOB样本
        for i in range(self.n_estimators):
            # Bootstrap采样
            indices = np.random.choice(n_samples, n_samples, replace=True)
            oob_indices = np.setdiff1d(np.arange(n_samples), indices)
            
            if len(oob_indices) == 0:
                continue
            
            # 使用第i棵树预测OOB样本
            tree = self.trees[i]
            features = self.feature_indices[i]
            
            oob_pred = tree.predict(X[oob_indices][:, features])
            
            for idx, pred in zip(oob_indices, oob_pred):
                oob_predictions[idx].append(pred)
        
        # 计算OOB误差
        correct = 0
        total = 0
        
        for i in range(n_samples):
            if len(oob_predictions[i]) > 0:
                # 投票或平均
                if self.criterion in ['gini', 'entropy']:
                    values, counts = np.unique(oob_predictions[i], return_counts=True)
                    pred = values[np.argmax(counts)]
                else:
                    pred = np.mean(oob_predictions[i])
                
                if self.criterion in ['gini', 'entropy']:
                    correct += (pred == y[i])
                else:
                    correct += (pred - y[i]) ** 2
                
                total += 1
        
        if self.criterion in ['gini', 'entropy']:
            return correct / total if total > 0 else 0
        else:
            return 1 - (correct / total) if total > 0 else 0


class ExtraTreesClassifier:
    """
    极端随机树（Extra Trees）
    在随机森林基础上增加了分裂点的随机性
    """
    
    def __init__(self, n_estimators=100, max_depth=None,
                 min_samples_split=2, min_samples_leaf=1,
                 max_features='sqrt', criterion='gini'):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.min_samples_leaf = min_samples_leaf
        self.max_features = max_features
        self.criterion = criterion
        self.trees = []
    
    def fit(self, X, y):
        """训练极端随机树"""
        n_samples, n_features = X.shape
        
        # 确定特征数
        if self.max_features == 'sqrt':
            max_features = int(np.sqrt(n_features))
        elif self.max_features == 'log2':
            max_features = int(np.log2(n_features))
        else:
            max_features = n_features
        
        # 训练多棵树
        for _ in range(self.n_estimators):
            tree = self._build_extra_tree(X, y, max_features)
            self.trees.append(tree)
        
        return self
    
    def _build_extra_tree(self, X, y, max_features):
        """构建一棵极端随机树"""
        # 这里简化实现，实际应该修改DecisionTree的分裂逻辑
        tree = DecisionTree(
            max_depth=self.max_depth,
            min_samples_split=self.min_samples_split,
            min_samples_leaf=self.min_samples_leaf,
            criterion=self.criterion
        )
        
        # 随机选择特征子集
        n_features = X.shape[1]
        feature_indices = np.random.choice(
            n_features, max_features, replace=False
        )
        
        tree.fit(X[:, feature_indices], y)
        tree.feature_indices = feature_indices
        
        return tree
    
    def predict(self, X):
        """预测"""
        predictions = []
        
        for tree in self.trees:
            pred = tree.predict(X[:, tree.feature_indices])
            predictions.append(pred)
        
        # 投票
        predictions = np.array(predictions)
        final_predictions = []
        
        for i in range(X.shape[0]):
            votes = predictions[:, i]
            values, counts = np.unique(votes, return_counts=True)
            final_predictions.append(values[np.argmax(counts)])
        
        return np.array(final_predictions)

```

### 4. 神经网络基础

```python
class Activation:
    """
    激活函数集合
    """
    
    @staticmethod
    def sigmoid(x):
        """Sigmoid激活函数"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    @staticmethod
    def sigmoid_derivative(x):
        """Sigmoid导数"""
        s = Activation.sigmoid(x)
        return s * (1 - s)
    
    @staticmethod
    def tanh(x):
        """Tanh激活函数"""
        return np.tanh(x)
    
    @staticmethod
    def tanh_derivative(x):
        """Tanh导数"""
        return 1 - np.tanh(x) ** 2
    
    @staticmethod
    def relu(x):
        """ReLU激活函数"""
        return np.maximum(0, x)
    
    @staticmethod
    def relu_derivative(x):
        """ReLU导数"""
        return (x > 0).astype(float)
    
    @staticmethod
    def leaky_relu(x, alpha=0.01):
        """Leaky ReLU激活函数"""
        return np.where(x > 0, x, alpha * x)
    
    @staticmethod
    def leaky_relu_derivative(x, alpha=0.01):
        """Leaky ReLU导数"""
        return np.where(x > 0, 1, alpha)
    
    @staticmethod
    def softmax(x):
        """Softmax激活函数"""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)


class Layer:
    """神经网络层基类"""
    
    def forward(self, input):
        """前向传播"""
        raise NotImplementedError
    
    def backward(self, grad_output):
        """反向传播"""
        raise NotImplementedError
    
    def update(self, learning_rate):
        """更新参数"""
        pass


class Dense(Layer):
    """
    全连接层
    """
    
    def __init__(self, input_size, output_size, use_bias=True):
        self.input_size = input_size
        self.output_size = output_size
        self.use_bias = use_bias
        
        # Xavier初始化
        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size)
        self.bias = np.zeros((1, output_size)) if use_bias else None
        
        # 存储用于反向传播
        self.input = None
        self.grad_weights = None
        self.grad_bias = None
    
    def forward(self, input):
        """
        前向传播
        input: (batch_size, input_size)
        output: (batch_size, output_size)
        """
        self.input = input
        output = np.dot(input, self.weights)
        
        if self.use_bias:
            output += self.bias
        
        return output
    
    def backward(self, grad_output):
        """
        反向传播
        grad_output: (batch_size, output_size)
        返回: (batch_size, input_size)
        """
        # 计算权重梯度
        self.grad_weights = np.dot(self.input.T, grad_output)
        
        # 计算偏置梯度
        if self.use_bias:
            self.grad_bias = np.sum(grad_output, axis=0, keepdims=True)
        
        # 计算输入梯度
        grad_input = np.dot(grad_output, self.weights.T)
        
        return grad_input
    
    def update(self, learning_rate):
        """更新参数"""
        self.weights -= learning_rate * self.grad_weights
        
        if self.use_bias:
            self.bias -= learning_rate * self.grad_bias


class ActivationLayer(Layer):
    """激活函数层"""
    
    def __init__(self, activation='relu'):
        self.activation = activation
        self.input = None
        
        # 设置激活函数和导数
        if activation == 'relu':
            self.activate = Activation.relu
            self.derivative = Activation.relu_derivative
        elif activation == 'sigmoid':
            self.activate = Activation.sigmoid
            self.derivative = Activation.sigmoid_derivative
        elif activation == 'tanh':
            self.activate = Activation.tanh
            self.derivative = Activation.tanh_derivative
        else:
            raise ValueError(f"不支持的激活函数: {activation}")
    
    def forward(self, input):
        """前向传播"""
        self.input = input
        return self.activate(input)
    
    def backward(self, grad_output):
        """反向传播"""
        return grad_output * self.derivative(self.input)


class Dropout(Layer):
    """Dropout层"""
    
    def __init__(self, dropout_rate=0.5):
        self.dropout_rate = dropout_rate
        self.mask = None
        self.training = True
    
    def forward(self, input):
        """前向传播"""
        if self.training:
            # 训练时随机丢弃
            self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=input.shape)
            return input * self.mask / (1 - self.dropout_rate)
        else:
            # 测试时直接返回
            return input
    
    def backward(self, grad_output):
        """反向传播"""
        if self.training:
            return grad_output * self.mask / (1 - self.dropout_rate)
        else:
            return grad_output


class BatchNormalization(Layer):
    """批归一化层"""
    
    def __init__(self, num_features, eps=1e-5, momentum=0.9):
        self.num_features = num_features
        self.eps = eps
        self.momentum = momentum
        
        # 可学习参数
        self.gamma = np.ones((1, num_features))
        self.beta = np.zeros((1, num_features))
        
        # 运行时统计量
        self.running_mean = np.zeros((1, num_features))
        self.running_var = np.ones((1, num_features))
        
        # 用于反向传播
        self.input = None
        self.normalized = None
        self.batch_mean = None
        self.batch_var = None
        
        # 梯度
        self.grad_gamma = None
        self.grad_beta = None
        
        self.training = True
    
    def forward(self, input):
        """前向传播"""
        self.input = input
        
        if self.training:
            # 计算批次统计量
            self.batch_mean = np.mean(input, axis=0, keepdims=True)
            self.batch_var = np.var(input, axis=0, keepdims=True)
            
            # 更新运行时统计量
            self.running_mean = (self.momentum * self.running_mean + 
                               (1 - self.momentum) * self.batch_mean)
            self.running_var = (self.momentum * self.running_var + 
                              (1 - self.momentum) * self.batch_var)
            
            # 归一化
            self.normalized = (input - self.batch_mean) / np.sqrt(self.batch_var + self.eps)
        else:
            # 使用运行时统计量
            self.normalized = (input - self.running_mean) / np.sqrt(self.running_var + self.eps)
        
        # 缩放和偏移
        output = self.gamma * self.normalized + self.beta
        
        return output
    
    def backward(self, grad_output):
        """反向传播"""
        batch_size = grad_output.shape[0]
        
        # 计算参数梯度
        self.grad_gamma = np.sum(grad_output * self.normalized, axis=0, keepdims=True)
        self.grad_beta = np.sum(grad_output, axis=0, keepdims=True)
        
        # 计算归一化梯度
        grad_normalized = grad_output * self.gamma
        
        # 计算方差梯度
        grad_var = np.sum(grad_normalized * (self.input - self.batch_mean) * 
                         -0.5 * (self.batch_var + self.eps) ** -1.5, 
                         axis=0, keepdims=True)
        
        # 计算均值梯度
        grad_mean = (np.sum(grad_normalized * -1 / np.sqrt(self.batch_var + self.eps), 
                          axis=0, keepdims=True) +
                    grad_var * np.sum(-2 * (self.input - self.batch_mean), 
                                     axis=0, keepdims=True) / batch_size)
        
        # 计算输入梯度
        grad_input = (grad_normalized / np.sqrt(self.batch_var + self.eps) +
                     grad_var * 2 * (self.input - self.batch_mean) / batch_size +
                     grad_mean / batch_size)
        
        return grad_input
    
    def update(self, learning_rate):
        """更新参数"""
        self.gamma -= learning_rate * self.grad_gamma
        self.beta -= learning_rate * self.grad_beta


class NeuralNetwork:
    """
    简单的神经网络实现
    """
    
    def __init__(self):
        self.layers = []
        self.loss_function = None
    
    def add(self, layer):
        """添加层"""
        self.layers.append(layer)
    
    def compile(self, loss='mse', optimizer='sgd'):
        """编译模型"""
        if loss == 'mse':
            self.loss_function = self._mse_loss
        elif loss == 'cross_entropy':
            self.loss_function = self._cross_entropy_loss
        else:
            raise ValueError(f"不支持的损失函数: {loss}")
        
        self.optimizer = optimizer
    
    def forward(self, X):
        """前向传播"""
        output = X
        
        for layer in self.layers:
            output = layer.forward(output)
        
        return output
    
    def backward(self, grad_output):
        """反向传播"""
        for layer in reversed(self.layers):
            grad_output = layer.backward(grad_output)
        
        return grad_output
    
    def fit(self, X, y, epochs=100, batch_size=32, learning_rate=0.01, 
            validation_data=None, verbose=True):
        """训练模型"""
        n_samples = X.shape[0]
        
        for epoch in range(epochs):
            # 打乱数据
            indices = np.random.permutation(n_samples)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            
            # 批次训练
            total_loss = 0
            n_batches = 0
            
            for i in range(0, n_samples, batch_size):
                batch_X = X_shuffled[i:i + batch_size]
                batch_y = y_shuffled[i:i + batch_size]
                
                # 前向传播
                predictions = self.forward(batch_X)
                
                # 计算损失
                loss, grad = self.loss_function(predictions, batch_y)
                total_loss += loss * batch_X.shape[0]
                n_batches += batch_X.shape[0]
                
                # 反向传播
                self.backward(grad)
                
                # 更新参数
                for layer in self.layers:
                    layer.update(learning_rate)
            
            # 计算平均损失
            avg_loss = total_loss / n_batches
            
            # 验证集评估
            if validation_data is not None and verbose:
                val_X, val_y = validation_data
                val_predictions = self.predict(val_X)
                val_loss, _ = self.loss_function(val_predictions, val_y)
                
                print(f"Epoch {epoch + 1}/{epochs} - "
                      f"loss: {avg_loss:.4f} - val_loss: {val_loss:.4f}")
            elif verbose:
                print(f"Epoch {epoch + 1}/{epochs} - loss: {avg_loss:.4f}")
    
    def predict(self, X):
        """预测"""
        # 设置为评估模式
        for layer in self.layers:
            if hasattr(layer, 'training'):
                layer.training = False
        
        predictions = self.forward(X)
        
        # 恢复训练模式
        for layer in self.layers:
            if hasattr(layer, 'training'):
                layer.training = True
        
        return predictions
    
    def _mse_loss(self, predictions, targets):
        """均方误差损失"""
        loss = np.mean((predictions - targets) ** 2)
        grad = 2 * (predictions - targets) / targets.shape[0]
        return loss, grad
    
    def _cross_entropy_loss(self, predictions, targets):
        """交叉熵损失"""
        # 假设predictions已经过softmax
        batch_size = predictions.shape[0]
        
        # 防止log(0)
        eps = 1e-7
        predictions = np.clip(predictions, eps, 1 - eps)
        
        # 计算损失
        loss = -np.sum(targets * np.log(predictions)) / batch_size
        
        # 计算梯度
        grad = (predictions - targets) / batch_size
        
        return loss, grad


class CNN:
    """
    卷积神经网络基础实现
    """
    
    class Conv2D(Layer):
        """二维卷积层"""
        
        def __init__(self, in_channels, out_channels, kernel_size=3, 
                     stride=1, padding=0):
            self.in_channels = in_channels
            self.out_channels = out_channels
            self.kernel_size = kernel_size
            self.stride = stride
            self.padding = padding
            
            # 初始化卷积核
            self.kernels = np.random.randn(
                out_channels, in_channels, kernel_size, kernel_size
            ) * np.sqrt(2.0 / (in_channels * kernel_size * kernel_size))
            
            self.bias = np.zeros((out_channels, 1))
            
            # 梯度
            self.grad_kernels = None
            self.grad_bias = None
            self.input = None
        
        def forward(self, input):
            """
            前向传播
            input: (batch_size, in_channels, height, width)
            """
            self.input = input
            batch_size, _, height, width = input.shape
            
            # 计算输出尺寸
            out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1
            out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1
            
            # 填充
            if self.padding > 0:
                input_padded = np.pad(
                    input, 
                    ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)),
                    mode='constant'
                )
            else:
                input_padded = input
            
            # 卷积操作
            output = np.zeros((batch_size, self.out_channels, out_height, out_width))
            
            for b in range(batch_size):
                for oc in range(self.out_channels):
                    for h in range(out_height):
                        for w in range(out_width):
                            h_start = h * self.stride
                            h_end = h_start + self.kernel_size
                            w_start = w * self.stride
                            w_end = w_start + self.kernel_size
                            
                            receptive_field = input_padded[b, :, h_start:h_end, w_start:w_end]
                            output[b, oc, h, w] = np.sum(
                                receptive_field * self.kernels[oc]
                            ) + self.bias[oc]
            
            return output
        
        def backward(self, grad_output):
            """反向传播"""
            batch_size, _, height, width = self.input.shape
            _, _, out_height, out_width = grad_output.shape
            
            # 初始化梯度
            self.grad_kernels = np.zeros_like(self.kernels)
            self.grad_bias = np.zeros_like(self.bias)
            grad_input = np.zeros_like(self.input)
            
            # 填充输入
            if self.padding > 0:
                input_padded = np.pad(
                    self.input,
                    ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)),
                    mode='constant'
                )
                grad_input_padded = np.pad(
                    grad_input,
                    ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)),
                    mode='constant'
                )
            else:
                input_padded = self.input
                grad_input_padded = grad_input
            
            # 计算梯度
            for b in range(batch_size):
                for oc in range(self.out_channels):
                    for h in range(out_height):
                        for w in range(out_width):
                            h_start = h * self.stride
                            h_end = h_start + self.kernel_size
                            w_start = w * self.stride
                            w_end = w_start + self.kernel_size
                            
                            # 卷积核梯度
                            self.grad_kernels[oc] += (
                                grad_output[b, oc, h, w] * 
                                input_padded[b, :, h_start:h_end, w_start:w_end]
                            )
                            
                            # 输入梯度
                            grad_input_padded[b, :, h_start:h_end, w_start:w_end] += (
                                grad_output[b, oc, h, w] * self.kernels[oc]
                            )
                    
                    # 偏置梯度
                    self.grad_bias[oc] += np.sum(grad_output[b, oc])
            
            # 去除填充
            if self.padding > 0:
                grad_input = grad_input_padded[:, :, self.padding:-self.padding, self.padding:-self.padding]
            else:
                grad_input = grad_input_padded
            
            return grad_input
        
        def update(self, learning_rate):
            """更新参数"""
            self.kernels -= learning_rate * self.grad_kernels
            self.bias -= learning_rate * self.grad_bias
    
    class MaxPool2D(Layer):
        """二维最大池化层"""
        
        def __init__(self, pool_size=2, stride=None):
            self.pool_size = pool_size
            self.stride = stride if stride is not None else pool_size
            self.input = None
            self.max_indices = None
        
        def forward(self, input):
            """前向传播"""
            self.input = input
            batch_size, channels, height, width = input.shape
            
            # 计算输出尺寸
            out_height = (height - self.pool_size) // self.stride + 1
            out_width = (width - self.pool_size) // self.stride + 1
            
            output = np.zeros((batch_size, channels, out_height, out_width))
            self.max_indices = np.zeros((batch_size, channels, out_height, out_width, 2), dtype=int)
            
            for b in range(batch_size):
                for c in range(channels):
                    for h in range(out_height):
                        for w in range(out_width):
                            h_start = h * self.stride
                            h_end = h_start + self.pool_size
                            w_start = w * self.stride
                            w_end = w_start + self.pool_size
                            
                            pool_region = input[b, c, h_start:h_end, w_start:w_end]
                            max_val = np.max(pool_region)
                            output[b, c, h, w] = max_val
                            
                            # 记录最大值位置
                            max_pos = np.unravel_index(
                                np.argmax(pool_region), pool_region.shape
                            )
                            self.max_indices[b, c, h, w] = [
                                h_start + max_pos[0], 
                                w_start + max_pos[1]
                            ]
            
            return output
        
        def backward(self, grad_output):
            """反向传播"""
            grad_input = np.zeros_like(self.input)
            batch_size, channels, out_height, out_width = grad_output.shape
            
            for b in range(batch_size):
                for c in range(channels):
                    for h in range(out_height):
                        for w in range(out_width):
                            # 将梯度传递到最大值位置
                            max_h, max_w = self.max_indices[b, c, h, w]
                            grad_input[b, c, max_h, max_w] += grad_output[b, c, h, w]
            
            return grad_input
```

### 5. 向量检索

```python
class LSH:
    """
    局部敏感哈希（Locality Sensitive Hashing）
    用于高维向量的近似最近邻搜索
    """
    
    def __init__(self, n_dimensions, n_hash_tables=10, n_hash_functions=8):
        self.n_dimensions = n_dimensions
        self.n_hash_tables = n_hash_tables
        self.n_hash_functions = n_hash_functions
        
        # 初始化哈希表
        self.hash_tables = [{} for _ in range(n_hash_tables)]
        
        # 生成随机投影向量
        self.random_projections = []
        for i in range(n_hash_tables):
            # 每个哈希表有n_hash_functions个随机投影
            projections = np.random.randn(n_hash_functions, n_dimensions)
            # 归一化
            projections = projections / np.linalg.norm(projections, axis=1, keepdims=True)
            self.random_projections.append(projections)
    
    def _hash(self, vector, table_idx):
        """
        计算向量的哈希值
        使用随机投影 + 符号函数
        """
        projections = self.random_projections[table_idx]
        # 计算投影
        projected = np.dot(projections, vector)
        # 取符号作为哈希值
        hash_vals = (projected > 0).astype(int)
        # 转换为字符串作为字典键
        return ''.join(map(str, hash_vals))
    
    def index(self, vectors, ids=None):
        """
        索引向量集合
        vectors: (n_vectors, n_dimensions)
        ids: 向量的标识符列表
        """
        n_vectors = len(vectors)
        
        if ids is None:
            ids = list(range(n_vectors))
        
        # 将每个向量添加到所有哈希表
        for i, (vector, vec_id) in enumerate(zip(vectors, ids)):
            for table_idx in range(self.n_hash_tables):
                hash_key = self._hash(vector, table_idx)
                
                if hash_key not in self.hash_tables[table_idx]:
                    self.hash_tables[table_idx][hash_key] = []
                
                self.hash_tables[table_idx][hash_key].append((vec_id, vector))
    
    def query(self, query_vector, k=5):
        """
        查询最近邻
        返回k个最近邻的ID和距离
        """
        candidates = set()
        
        # 从所有哈希表收集候选
        for table_idx in range(self.n_hash_tables):
            hash_key = self._hash(query_vector, table_idx)
            
            if hash_key in self.hash_tables[table_idx]:
                for vec_id, vector in self.hash_tables[table_idx][hash_key]:
                    candidates.add((vec_id, tuple(vector)))
        
        # 计算精确距离并排序
        distances = []
        for vec_id, vector in candidates:
            dist = np.linalg.norm(query_vector - np.array(vector))
            distances.append((vec_id, dist))
        
        # 返回top-k
        distances.sort(key=lambda x: x[1])
        return distances[:k]


class KDTree:
    """
    KD树实现
    用于低维空间的精确最近邻搜索
    """
    
    class Node:
        def __init__(self, point, idx, axis, left=None, right=None):
            self.point = point
            self.idx = idx
            self.axis = axis
            self.left = left
            self.right = right
    
    def __init__(self, k=2):
        self.k = k  # 维度
        self.root = None
    
    def build(self, points, indices=None):
        """
        构建KD树
        时间复杂度：O(n log n)
        """
        if indices is None:
            indices = list(range(len(points)))
        
        self.root = self._build_recursive(points, indices, depth=0)
    
    def _build_recursive(self, points, indices, depth):
        """递归构建KD树"""
        if not indices:
            return None
        
        # 选择分割轴
        axis = depth % self.k
        
        # 按当前轴排序
        sorted_indices = sorted(indices, key=lambda i: points[i][axis])
        
        # 选择中位数作为分割点
        median_idx = len(sorted_indices) // 2
        median_point_idx = sorted_indices[median_idx]
        
        # 创建节点
        node = self.Node(
            points[median_point_idx],
            median_point_idx,
            axis
        )
        
        # 递归构建子树
        node.left = self._build_recursive(
            points, sorted_indices[:median_idx], depth + 1
        )
        node.right = self._build_recursive(
            points, sorted_indices[median_idx + 1:], depth + 1
        )
        
        return node
    
    def nearest_neighbor(self, query_point):
        """
        查找最近邻
        时间复杂度：平均O(log n)，最坏O(n)
        """
        if self.root is None:
            return None, float('inf')
        
        best = [None, float('inf')]  # [index, distance]
        
        def search(node, depth=0):
            if node is None:
                return
            
            # 计算当前节点的距离
            dist = np.linalg.norm(np.array(query_point) - np.array(node.point))
            
            if dist < best[1]:
                best[0] = node.idx
                best[1] = dist
            
            # 决定先搜索哪个子树
            axis = depth % self.k
            diff = query_point[axis] - node.point[axis]
            
            if diff <= 0:
                search(node.left, depth + 1)
                # 检查是否需要搜索另一边
                if abs(diff) < best[1]:
                    search(node.right, depth + 1)
            else:
                search(node.right, depth + 1)
                if abs(diff) < best[1]:
                    search(node.left, depth + 1)
        
        search(self.root)
        return best[0], best[1]
    
    def k_nearest_neighbors(self, query_point, k):
        """
        查找k个最近邻
        使用优先队列维护top-k
        """
        import heapq
        
        if self.root is None:
            return []
        
        # 使用最大堆维护k个最近邻
        heap = []  # (-distance, index)
        
        def search(node, depth=0):
            if node is None:
                return
            
            # 计算距离
            dist = np.linalg.norm(np.array(query_point) - np.array(node.point))
            
            # 更新堆
            if len(heap) < k:
                heapq.heappush(heap, (-dist, node.idx))
            elif dist < -heap[0][0]:
                heapq.heapreplace(heap, (-dist, node.idx))
            
            # 决定搜索顺序
            axis = depth % self.k
            diff = query_point[axis] - node.point[axis]
            
            if diff <= 0:
                search(node.left, depth + 1)
                if len(heap) < k or abs(diff) < -heap[0][0]:
                    search(node.right, depth + 1)
            else:
                search(node.right, depth + 1)
                if len(heap) < k or abs(diff) < -heap[0][0]:
                    search(node.left, depth + 1)
        
        search(self.root)
        
        # 返回结果
        result = [(idx, -dist) for dist, idx in heap]
        result.sort(key=lambda x: x[1])
        return result


class HNSW:
    """
    分层可导航小世界图（Hierarchical Navigable Small World）
    高效的近似最近邻搜索
    """
    
    def __init__(self, dim, max_m=16, ef_construction=200, m_l=1.0, seed=0):
        self.dim = dim
        self.max_m = max_m  # 每个节点的最大连接数
        self.max_m0 = max_m * 2  # 第0层的最大连接数
        self.m_l = m_l  # 层级乘数
        self.ef_construction = ef_construction  # 构建时的动态列表大小
        self.ef = ef_construction  # 搜索时的动态列表大小
        
        self.level_multiplier = 1 / np.log(m_l)
        self.nodes = []  # 存储所有节点
        self.graph = {}  # 邻接表 {node_id: {level: [neighbors]}}
        self.entry_point = None
        
        np.random.seed(seed)
    
    def _get_random_level(self):
        """随机选择节点层级"""
        return int(-np.log(np.random.uniform()) * self.level_multiplier)
    
    def _distance(self, a, b):
        """计算欧氏距离"""
        return np.linalg.norm(a - b)
    
    def _search_layer(self, query, entry_points, num_closest, layer):
        """
        在指定层搜索最近邻
        返回num_closest个最近邻
        """
        visited = set()
        candidates = []
        w = []
        
        # 初始化候选集和结果集
        for point in entry_points:
            dist = self._distance(query, self.nodes[point])
            heapq.heappush(candidates, (-dist, point))
            heapq.heappush(w, (dist, point))
            visited.add(point)
        
        while candidates:
            # 获取最近的候选
            lowerBound, c = heapq.heappop(candidates)
            
            # 如果比结果集中最远的还远，停止搜索
            if -lowerBound > w[0][0]:
                break
            
            # 检查c的邻居
            neighbors = self.graph.get(c, {}).get(layer, [])
            for neighbor in neighbors:
                if neighbor not in visited:
                    visited.add(neighbor)
                    dist = self._distance(query, self.nodes[neighbor])
                    
                    if dist < w[0][0] or len(w) < num_closest:
                        heapq.heappush(candidates, (-dist, neighbor))
                        heapq.heappush(w, (dist, neighbor))
                        
                        # 保持结果集大小
                        if len(w) > num_closest:
                            heapq.heappop(w)
        
        # 返回结果
        return [idx for _, idx in w]
    
    def insert(self, data, idx=None):
        """插入新节点"""
        if idx is None:
            idx = len(self.nodes)
        
        self.nodes.append(data)
        
        if self.entry_point is None:
            self.entry_point = idx
            self.graph[idx] = {}
            return
        
        # 分配层级
        level = self._get_random_level()
        
        # 搜索最近邻
        nearest = []
        
        # 从顶层向下搜索
        curr_nearest = [self.entry_point]
        for lc in range(self._get_level(self.entry_point), level, -1):
            curr_nearest = self._search_layer(data, curr_nearest, 1, lc)
        
        # 在目标层级及以下搜索
        for lc in range(level, -1, -1):
            candidates = self._search_layer(
                data, curr_nearest, self.ef_construction, lc
            )
            
            # 选择M个最近邻
            m = self.max_m if lc > 0 else self.max_m0
            
            # 启发式选择邻居
            neighbors = self._get_neighbors_heuristic(candidates, m)
            
            # 建立双向连接
            if idx not in self.graph:
                self.graph[idx] = {}
            self.graph[idx][lc] = neighbors
            
            for neighbor in neighbors:
                if neighbor not in self.graph:
                    self.graph[neighbor] = {}
                if lc not in self.graph[neighbor]:
                    self.graph[neighbor][lc] = []
                
                self.graph[neighbor][lc].append(idx)
                
                # 修剪邻居的连接
                max_m = self.max_m if lc > 0 else self.max_m0
                if len(self.graph[neighbor][lc]) > max_m:
                    # 修剪连接
                    prune_list = self._get_neighbors_heuristic(
                        self.graph[neighbor][lc], max_m
                    )
                    self.graph[neighbor][lc] = prune_list
            
            curr_nearest = candidates
        
        # 更新入口点
        if level > self._get_level(self.entry_point):
            self.entry_point = idx
    
    def _get_level(self, idx):
        """获取节点的最高层级"""
        return max(self.graph.get(idx, {}).keys()) if idx in self.graph else 0
    
    def _get_neighbors_heuristic(self, candidates, m):
        """启发式选择邻居"""
        # 简化版：选择最近的m个
        candidates_with_dist = []
        for c in candidates:
            if c < len(self.nodes):
                dist = self._distance(self.nodes[candidates[0]], self.nodes[c])
                candidates_with_dist.append((dist, c))
        
        candidates_with_dist.sort(key=lambda x: x[0])
        
        return [idx for _, idx in candidates_with_dist[:m]]
    
    def search(self, query, k):
        """搜索k个最近邻"""
        if self.entry_point is None:
            return []
        
        # 从顶层向下搜索
        curr_nearest = [self.entry_point]
        
        for lc in range(self._get_level(self.entry_point), 0, -1):
            curr_nearest = self._search_layer(query, curr_nearest, 1, lc)
        
        # 在第0层搜索
        curr_nearest = self._search_layer(query, curr_nearest, max(self.ef, k), 0)
        
        # 返回k个最近邻
        result = []
        for idx in curr_nearest[:k]:
            dist = self._distance(query, self.nodes[idx])
            result.append((idx, dist))
        
        result.sort(key=lambda x: x[1])
        return result[:k]
```

## 第八部分：应用实践

### 1. AI改卷系统中的应用

```python
class AIGradingSystem:
    """
    AI改卷系统的核心算法实现
    """
    
    def __init__(self):
        self.text_processor = TextProcessor()
        self.feature_extractor = FeatureExtractor()
        self.grading_model = GradingModel()
        self.similarity_checker = SimilarityChecker()
    
    class TextProcessor:
        """文本预处理模块"""
        
        def __init__(self):
            self.vocab = {}
            self.stop_words = self._load_stop_words()
        
        def _load_stop_words(self):
            """加载停用词"""
            # 简化版停用词列表
            return set(['的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这'])
        
        def tokenize(self, text):
            """
            中文分词（简化版）
            实际应用中应使用jieba等分词工具
            """
            # 简单的单字分词
            tokens = []
            for char in text:
                if char.strip() and char not in self.stop_words:
                    tokens.append(char)
            return tokens
        
        def build_vocabulary(self, documents):
            """构建词汇表"""
            word_freq = {}
            
            for doc in documents:
                tokens = self.tokenize(doc)
                for token in tokens:
                    word_freq[token] = word_freq.get(token, 0) + 1
            
            # 按频率排序，取前N个
            sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
            
            self.vocab = {word: idx for idx, (word, _) in enumerate(sorted_words)}
            return self.vocab
        
        def text_to_vector(self, text):
            """将文本转换为向量"""
            tokens = self.tokenize(text)
            vector = np.zeros(len(self.vocab))
            
            for token in tokens:
                if token in self.vocab:
                    vector[self.vocab[token]] += 1
            
            # TF-IDF权重（简化版）
            if np.sum(vector) > 0:
                vector = vector / np.sum(vector)
            
            return vector
    
    class FeatureExtractor:
        """特征提取模块"""
        
        def extract_features(self, text, answer_key=None):
            """
            提取答案特征
            包括：长度、关键词覆盖率、语义相似度等
            """
            features = []
            
            # 1. 长度特征
            length = len(text)
            features.append(length)
            
            # 2. 标点符号特征
            punctuation_count = sum(1 for char in text if char in '。，！？；：')
            features.append(punctuation_count)
            
            # 3. 如果有标准答案，计算关键词覆盖率
            if answer_key:
                key_words = set(answer_key.split())
                answer_words = set(text.split())
                
                if len(key_words) > 0:
                    coverage = len(key_words & answer_words) / len(key_words)
                else:
                    coverage = 0
                
                features.append(coverage)
            
            # 4. 答案完整性（是否包含必要的答题要素）
            completeness_score = self._check_completeness(text)
            features.append(completeness_score)
            
            return np.array(features)
        
        def _check_completeness(self, text):
            """检查答案完整性"""
            # 简化版：检查是否包含因果关系词
            cause_words = ['因为', '由于', '因此', '所以', '导致']
            score = 0
            
            for word in cause_words:
                if word in text:
                    score += 0.2
            
            return min(score, 1.0)
        
        def extract_semantic_features(self, text, reference_embeddings=None):
            """
            提取语义特征
            使用词嵌入等技术
            """
            # 简化版：使用随机初始化的词嵌入
            embedding_dim = 100
            words = text.split()
            
            # 模拟词嵌入
            embeddings = []
            for word in words:
                # 使用word的hash值作为种子生成固定的随机向量
                np.random.seed(hash(word) % 2**32)
                embedding = np.random.randn(embedding_dim)
                embeddings.append(embedding)
            
            if embeddings:
                # 平均池化
                text_embedding = np.mean(embeddings, axis=0)
            else:
                text_embedding = np.zeros(embedding_dim)
            
            return text_embedding
    
    class GradingModel:
        """评分模型"""
        
        def __init__(self):
            self.weights = None
            self.bias = None
            self.scaler = None
        
        def train(self, features, scores):
            """
            训练评分模型
            使用简单的线性回归
            """
            # 特征标准化
            self.scaler = StandardScaler()
            features_scaled = self.scaler.fit_transform(features)
            
            # 添加偏置项
            X = np.column_stack([features_scaled, np.ones(len(features))])
            
            # 使用最小二乘法
            self.weights = np.linalg.lstsq(X, scores, rcond=None)[0]
            
            return self
        
        def predict(self, features):
            """预测分数"""
            if self.weights is None:
                raise ValueError("模型未训练")
            
            # 特征标准化
            features_scaled = self.scaler.transform(features.reshape(1, -1))
            
            # 添加偏置项
            X = np.column_stack([features_scaled, np.ones(1)])
            
            # 预测
            score = np.dot(X, self.weights)[0]
            
            # 限制在合理范围内
            return np.clip(score, 0, 100)
        
        class StandardScaler:
            """标准化器"""
            def __init__(self):
                self.mean = None
                self.std = None
            
            def fit_transform(self, X):
                self.mean = np.mean(X, axis=0)
                self.std = np.std(X, axis=0) + 1e-8
                return (X - self.mean) / self.std
            
            def transform(self, X):
                return (X - self.mean) / self.std
    
    class SimilarityChecker:
        """相似度检测模块（检测抄袭）"""
        
        def __init__(self):
            self.shingle_size = 3
            self.threshold = 0.8
        
        def create_shingles(self, text):
            """创建文本的shingle集合"""
            shingles = set()
            
            for i in range(len(text) - self.shingle_size + 1):
                shingle = text[i:i + self.shingle_size]
                shingles.add(shingle)
            
            return shingles
        
        def jaccard_similarity(self, text1, text2):
            """计算Jaccard相似度"""
            shingles1 = self.create_shingles(text1)
            shingles2 = self.create_shingles(text2)
            
            if not shingles1 and not shingles2:
                return 1.0
            
            intersection = len(shingles1 & shingles2)
            union = len(shingles1 | shingles2)
            
            return intersection / union if union > 0 else 0
        
        def check_plagiarism(self, submissions):
            """
            检测抄袭
            返回相似度矩阵和可疑配对
            """
            n = len(submissions)
            similarity_matrix = np.zeros((n, n))
            suspicious_pairs = []
            
            for i in range(n):
                for j in range(i + 1, n):
                    sim = self.jaccard_similarity(submissions[i], submissions[j])
                    similarity_matrix[i][j] = sim
                    similarity_matrix[j][i] = sim
                    
                    if sim > self.threshold:
                        suspicious_pairs.append((i, j, sim))
            
            return similarity_matrix, suspicious_pairs
    
    def grade_submission(self, submission, answer_key=None, reference_answers=None):
        """
        对单个提交进行评分
        """
        # 1. 文本预处理
        processed_text = submission.strip()
        
        # 2. 特征提取
        features = self.feature_extractor.extract_features(processed_text, answer_key)
        
        # 3. 语义特征
        semantic_features = self.feature_extractor.extract_semantic_features(processed_text)
        
        # 4. 如果有参考答案，计算相似度
        if reference_answers:
            similarities = []
            for ref in reference_answers:
                ref_embedding = self.feature_extractor.extract_semantic_features(ref)
                # 余弦相似度
                sim = np.dot(semantic_features, ref_embedding) / (
                    np.linalg.norm(semantic_features) * np.linalg.norm(ref_embedding) + 1e-8
                )
                similarities.append(sim)
            
            max_similarity = max(similarities) if similarities else 0
            features = np.append(features, max_similarity)
        
        # 5. 预测分数
        score = self.grading_model.predict(features)
        
        # 6. 生成反馈
        feedback = self._generate_feedback(processed_text, score, features)
        
        return {
            'score': score,
            'feedback': feedback,
            'features': features
        }
    
    def _generate_feedback(self, text, score, features):
        """生成评分反馈"""
        feedback = []
        
        # 基于特征生成反馈
        if features[0] < 50:  # 长度特征
            feedback.append("答案过于简短，建议展开论述")
        elif features[0] > 500:
            feedback.append("答案过长，建议精简表达")
        
        if features[1] < 2:  # 标点符号
            feedback.append("建议使用适当的标点符号，使答案更加清晰")
        
        if len(features) > 2 and features[2] < 0.5:  # 关键词覆盖
            feedback.append("答案缺少一些关键要点，请确保涵盖所有重要内容")
        
        if len(features) > 3 and features[3] < 0.5:  # 完整性
            feedback.append("答案结构不够完整，建议增加因果分析")
        
        # 基于分数的总体反馈
        if score >= 90:
            feedback.append("非常好！答案全面准确")
        elif score >= 80:
            feedback.append("良好，但仍有改进空间")
        elif score >= 60:
            feedback.append("及格，需要加强对知识点的理解")
        else:
            feedback.append("需要更多努力，建议重新学习相关内容")
        
        return '\n'.join(feedback)
    
    def batch_grade(self, submissions, answer_key=None):
        """批量评分"""
        results = []
        
        # 检测抄袭
        _, suspicious_pairs = self.similarity_checker.check_plagiarism(submissions)
        
        # 对每份提交评分
        for i, submission in enumerate(submissions):
            result = self.grade_submission(submission, answer_key)
            
            # 添加抄袭标记
            is_suspicious = any(
                (i == pair[0] or i == pair[1]) 
                for pair in suspicious_pairs
            )
            
            result['suspicious'] = is_suspicious
            
            results.append(result)
        
        return results, suspicious_pairs
```

### 2. 聊天Agent中的应用

```python
class EmotionalChatAgent:
    """
    情感细腻的聊天Agent实现
    """
    
    def __init__(self):
        self.emotion_analyzer = EmotionAnalyzer()
        self.context_manager = ContextManager()
        self.response_generator = ResponseGenerator()
        self.personality = PersonalityModule()
    
    class EmotionAnalyzer:
        """情感分析模块"""
        
        def __init__(self):
            # 情感词典
            self.emotion_lexicon = {
                '开心': ('positive', 0.8),
                '快乐': ('positive', 0.9),
                '高兴': ('positive', 0.7),
                '难过': ('negative', -0.8),
                '伤心': ('negative', -0.9),
                '生气': ('negative', -0.7),
                '担心': ('negative', -0.6),
                '期待': ('positive', 0.6),
                '失望': ('negative', -0.7),
                '感动': ('positive', 0.8),
                '焦虑': ('negative', -0.7),
                '平静': ('neutral', 0.1),
                '疲惫': ('negative', -0.5),
                '兴奋': ('positive', 0.9),
                '孤独': ('negative', -0.8)
            }
            
            # 情感状态
            self.emotion_categories = [
                'happy', 'sad', 'angry', 'fear', 
                'surprise', 'disgust', 'neutral'
            ]
        
        def analyze_emotion(self, text):
            """
            分析文本情感
            返回情感类别和强度
            """
            # 初始化情感分数
            emotion_scores = {
                'positive': 0,
                'negative': 0,
                'neutral': 0
            }
            
            # 基于词典的情感分析
            word_count = 0
            for word in text:
                if word in self.emotion_lexicon:
                    category, score = self.emotion_lexicon[word]
                    emotion_scores[category] += score
                    word_count += 1
            
            # 归一化
            if word_count > 0:
                for key in emotion_scores:
                    emotion_scores[key] /= word_count
            
            # 计算主导情感
            dominant_emotion = max(emotion_scores, key=emotion_scores.get)
            intensity = abs(emotion_scores[dominant_emotion])
            
            # 更细粒度的情感分类
            fine_emotion = self._classify_fine_emotion(text, dominant_emotion, intensity)
            
            return {
                'dominant': dominant_emotion,
                'fine_emotion': fine_emotion,
                'intensity': intensity,
                'scores': emotion_scores
            }
        
        def _classify_fine_emotion(self, text, dominant, intensity):
            """细粒度情感分类"""
            if dominant == 'positive':
                if intensity > 0.7:
                    return 'happy'
                else:
                    return 'content'
            elif dominant == 'negative':
                if '生气' in text or '愤怒' in text:
                    return 'angry'
                elif '害怕' in text or '恐惧' in text:
                    return 'fear'
                elif intensity > 0.7:
                    return 'sad'
                else:
                    return 'worried'
            else:
                return 'neutral'
        
        def track_emotion_trajectory(self, conversation_history):
            """
            跟踪对话中的情感轨迹
            用于理解情感变化
            """
            trajectory = []
            
            for utterance in conversation_history:
                emotion = self.analyze_emotion(utterance)
                trajectory.append(emotion)
            
            # 分析情感趋势
            if len(trajectory) >= 2:
                trend = self._analyze_trend(trajectory)
                return trajectory, trend
            
            return trajectory, 'stable'
        
        def _analyze_trend(self, trajectory):
            """分析情感趋势"""
            # 简化版：比较最近的情感变化
            recent_scores = [t['scores']['positive'] - t['scores']['negative'] 
                           for t in trajectory[-3:]]
            
            if len(recent_scores) >= 2:
                diff = recent_scores[-1] - recent_scores[0]
                if diff > 0.3:
                    return 'improving'
                elif diff < -0.3:
                    return 'deteriorating'
            
            return 'stable'
    
    class ContextManager:
        """上下文管理模块"""
        
        def __init__(self, max_history=10):
            self.max_history = max_history
            self.conversation_history = []
            self.user_profile = {
                'interests': [],
                'emotional_state': 'neutral',
                'personality_traits': [],
                'conversation_style': 'casual'
            }
            self.topic_stack = []
        
        def update_context(self, user_input, bot_response):
            """更新对话上下文"""
            # 添加到历史
            self.conversation_history.append({
                'user': user_input,
                'bot': bot_response,
                'timestamp': self._get_timestamp()
            })
            
            # 限制历史长度
            if len(self.conversation_history) > self.max_history:
                self.conversation_history.pop(0)
            
            # 更新用户画像
            self._update_user_profile(user_input)
            
            # 更新话题栈
            self._update_topic_stack(user_input)
        
        def _get_timestamp(self):
            """获取时间戳"""
            import time
            return time.time()
        
        def _update_user_profile(self, user_input):
            """更新用户画像"""
            # 简化版：基于关键词提取兴趣
            interest_keywords = {
                '音乐': 'music',
                '电影': 'movie',
                '运动': 'sports',
                '美食': 'food',
                '旅行': 'travel',
                '工作': 'work',
                '学习': 'study'
            }
            
            for keyword, interest in interest_keywords.items():
                if keyword in user_input and interest not in self.user_profile['interests']:
                    self.user_profile['interests'].append(interest)
        
        def _update_topic_stack(self, user_input):
            """更新话题栈"""
            # 简化版：提取名词作为话题
            nouns = self._extract_topics(user_input)
            
            for noun in nouns:
                if noun not in self.topic_stack:
                    self.topic_stack.append(noun)
            
            # 限制栈大小
            if len(self.topic_stack) > 5:
                self.topic_stack = self.topic_stack[-5:]
        
        def _extract_topics(self, text):
            """提取话题（简化版）"""
            # 这里应该使用NLP工具提取名词
            # 简化实现：提取一些预定义的话题词
            topics = []
            topic_words = ['天气', '工作', '心情', '周末', '计划', '朋友', '家人']
            
            for word in topic_words:
                if word in text:
                    topics.append(word)
            
            return topics
        
        def get_relevant_context(self, current_input):
            """获取相关上下文"""
            context = {
                'recent_history': self.conversation_history[-3:],
                'user_profile': self.user_profile,
                'current_topics': self.topic_stack[-2:],
                'conversation_length': len(self.conversation_history)
            }
            
            return context
    
    class ResponseGenerator:
        """回复生成模块"""
        
        def __init__(self):
            self.response_templates = {
                'happy': [
                    "太好了！听到你{emotion}我也很开心呢～",
                    "哇，你的快乐都感染到我了！{topic}",
                    "真棒！{encouragement}"
                ],
                'sad': [
                    "我能感受到你的{emotion}，需要我陪你聊聊吗？",
                    "别难过，{comfort}",
                    "抱抱～一切都会好起来的"
                ],
                'angry': [
                    "我理解你的心情，{understanding}",
                    "深呼吸，让我们一起冷静下来",
                    "发生什么让你这么生气呢？"
                ],
                'neutral': [
                    "嗯嗯，{acknowledgment}",
                    "关于{topic}，我觉得{opinion}",
                    "说得对，{agreement}"
                ]
            }
            
            self.emotion_words = {
                'happy': ['开心', '快乐', '愉悦'],
                'sad': ['难过', '失落', '沮丧'],
                'angry': ['生气', '愤怒', '不满']
            }
        
        def generate_response(self, user_input, emotion, context):
            """
            生成情感化的回复
            """
            # 选择合适的模板
            templates = self.response_templates.get(
                emotion['fine_emotion'], 
                self.response_templates['neutral']
            )
            
            template = np.random.choice(templates)
            
            # 填充模板
            response = self._fill_template(
                template, 
                user_input, 
                emotion, 
                context
            )
            
            # 添加个性化元素
            response = self._add_personality(response, context)
            
            # 确保回复的连贯性
            response = self._ensure_coherence(response, context)
            
            return response
        
        def _fill_template(self, template, user_input, emotion, context):
            """填充回复模板"""
            filled = template
            
            # 替换情感词
            if '{emotion}' in filled:
                emotion_word = np.random.choice(
                    self.emotion_words.get(emotion['fine_emotion'], ['的心情'])
                )
                filled = filled.replace('{emotion}', emotion_word)
            
            # 替换话题
            if '{topic}' in filled:
                topics = context.get('current_topics', ['这件事'])
                topic = topics[0] if topics else '这件事'
                filled = filled.replace('{topic}', topic)
            
            # 替换其他占位符
            placeholders = {
                '{encouragement}': '继续保持这份快乐吧！',
                '{comfort}': '我在这里陪着你',
                '{understanding}': '有时候确实会让人很生气',
                '{acknowledgment}': '我明白你的意思',
                '{opinion}': '这确实值得思考',
                '{agreement}': '你说的很有道理'
            }
            
            for placeholder, value in placeholders.items():
                if placeholder in filled:
                    filled = filled.replace(placeholder, value)
            
            return filled
        
        def _add_personality(self, response, context):
            """添加个性化元素"""
            # 根据对话长度调整亲密度
            conversation_length = context.get('conversation_length', 0)
            
            if conversation_length > 10:
                # 长对话，更亲密
                response = response.replace('你', '你呀')
                if not response.endswith('～'):
                    response += '～'
            
            # 根据用户兴趣添加相关内容
            interests = context.get('user_profile', {}).get('interests', [])
            if interests and np.random.random() < 0.3:
                interest = np.random.choice(interests)
                interest_comments = {
                    'music': '对了，最近有听什么好听的歌吗？',
                    'movie': '说起来，最近有什么好看的电影推荐吗？',
                    'food': '聊着聊着都饿了呢，你今天吃了什么好吃的？'
                }
                
                if interest in interest_comments:
                    response += ' ' + interest_comments[interest]
            
            return response
        
        def _ensure_coherence(self, response, context):
            """确保回复的连贯性"""
            # 检查是否与最近的对话重复
            recent_history = context.get('recent_history', [])
            
            if recent_history:
                last_bot_response = recent_history[-1].get('bot', '')
                
                # 避免重复
                if response == last_bot_response:
                    alternatives = [
                        "嗯，还有呢？",
                        "继续说说看～",
                        "我在听着呢"
                    ]
                    response = np.random.choice(alternatives)
            
            return response
    
    class PersonalityModule:
        """个性化模块"""
        
        def __init__(self):
            self.personality_traits = {
                'warmth': 0.8,        # 温暖度
                'humor': 0.6,         # 幽默感
                'empathy': 0.9,       # 同理心
                'curiosity': 0.7,     # 好奇心
                'positivity': 0.8     # 积极性
            }
            
            self.speaking_style = {
                'emoji_usage': 0.7,   # 表情使用频率
                'exclamation': 0.5,   # 感叹句频率
                'question': 0.6       # 提问频率
            }
        
        def adjust_response(self, response, emotion):
            """根据个性调整回复"""
            # 添加表情
            if np.random.random() < self.speaking_style['emoji_usage']:
                response = self._add_emoji(response, emotion)
            
            # 调整语气
            if emotion['dominant'] == 'positive' and \
               np.random.random() < self.personality_traits['positivity']:
                response = self._make_more_positive(response)
            
            # 添加幽默元素
            if np.random.random() < self.personality_traits['humor'] * 0.3:
                response = self._add_humor(response)
            
            return response
        
        def _add_emoji(self, response, emotion):
            """添加表情符号"""
            emoji_map = {
                'happy': ['😊', '😄', '✨', '🎉'],
                'sad': ['😢', '😔', '💔', '🫂'],
                'angry': ['😤', '😠', '💢'],
                'neutral': ['🤔', '😌', '💭']
            }
            
            emojis = emoji_map.get(emotion['fine_emotion'], ['💬'])
            emoji = np.random.choice(emojis)
            
            # 随机决定表情位置
            if np.random.random() < 0.5:
                return response + ' ' + emoji
            else:
                return emoji + ' ' + response
        
        def _make_more_positive(self, response):
            """使回复更积极"""
            positive_additions = [
                '希望这能帮到你！',
                '一起加油吧！',
                '相信你一定可以的！',
                '期待听到你的好消息～'
            ]
            
            if np.random.random() < 0.4:
                response += ' ' + np.random.choice(positive_additions)
            
            return response
        
        def _add_humor(self, response):
            """添加幽默元素"""
            # 简化版：添加一些轻松的表达
            humor_elements = [
                '哈哈',
                '嘿嘿',
                '(偷笑)',
                '～(￣▽￣)～'
            ]
            
            if '？' not in response:  # 不在疑问句中添加
                response += ' ' + np.random.choice(humor_elements)
            
            return response
    
    def process_message(self, user_input):
        """
        处理用户消息并生成回复
        """
        # 1. 情感分析
        emotion = self.emotion_analyzer.analyze_emotion(user_input)
        
        # 2. 获取上下文
        context = self.context_manager.get_relevant_context(user_input)
        
        # 3. 生成基础回复
        response = self.response_generator.generate_response(
            user_input, emotion, context
        )
        
        # 4. 个性化调整
        response = self.personality.adjust_response(response, emotion)
        
        # 5. 更新上下文
        self.context_manager.update_context(user_input, response)
        
        # 6. 情感轨迹分析（用于长期优化）
        if len(self.context_manager.conversation_history) > 3:
            trajectory, trend = self.emotion_analyzer.track_emotion_trajectory(
                [h['user'] for h in self.context_manager.conversation_history]
            )
            
            # 如果情绪持续低落，主动关心
            if trend == 'deteriorating' and emotion['dominant'] == 'negative':
                response += " 我注意到你最近似乎心情不太好，需要聊聊吗？我一直都在的。"
        
        return {
            'response': response,
            'emotion': emotion,
            'context': context
        }
    
    def start_conversation(self):
        """开始对话"""
        greetings = [
            "你好呀！今天过得怎么样？😊",
            "嗨～很高兴见到你！有什么想聊的吗？",
            "你来啦！我正想着你呢～",
            "Hello! 今天的心情如何呀？"
        ]
        
        return np.random.choice(greetings)
```

### 3. 搜索引擎实现

```python
class SearchEngine:
    """
    搜索引擎核心算法实现
    """
    
    def __init__(self):
        self.indexer = InvertedIndexer()
        self.ranker = PageRanker()
        self.query_processor = QueryProcessor()
        self.crawler = WebCrawler()
        self.cache = SearchCache()
    
    class InvertedIndexer:
        """倒排索引实现"""
        
        def __init__(self):
            self.inverted_index = {}  # {term: [(doc_id, tf, positions), ...]}
            self.document_store = {}  # {doc_id: document_info}
            self.doc_count = 0
            self.term_doc_freq = {}  # {term: document_frequency}
        
        def index_document(self, doc_id, content, metadata=None):
            """
            为文档建立索引
            时间复杂度：O(n) n为文档词数
            """
            # 分词
            tokens = self._tokenize(content)
            
            # 统计词频和位置
            term_positions = {}
            for position, token in enumerate(tokens):
                if token not in term_positions:
                    term_positions[token] = []
                term_positions[token].append(position)
            
            # 更新倒排索引
            for term, positions in term_positions.items():
                tf = len(positions)  # 词频
                
                if term not in self.inverted_index:
                    self.inverted_index[term] = []
                    self.term_doc_freq[term] = 0
                
                # 添加文档信息
                self.inverted_index[term].append((doc_id, tf, positions))
                self.term_doc_freq[term] += 1
            
            # 存储文档信息
            self.document_store[doc_id] = {
                'content': content,
                'length': len(tokens),
                'metadata': metadata or {},
                'terms': list(term_positions.keys())
            }
            
            self.doc_count += 1
        
        def _tokenize(self, text):
            """
            分词（简化版）
            实际应用中应使用更复杂的分词器
            """
            # 转小写
            text = text.lower()
            
            # 简单分词：按空格和标点分割
            import re
            tokens = re.findall(r'\b\w+\b', text)
            
            # 去除停用词
            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}
            tokens = [t for t in tokens if t not in stop_words]
            
            return tokens
        
        def search(self, query):
            """
            搜索文档
            返回包含查询词的文档列表
            """
            query_tokens = self._tokenize(query)
            
            # 收集所有相关文档
            doc_scores = {}
            
            for token in query_tokens:
                if token in self.inverted_index:
                    for doc_id, tf, positions in self.inverted_index[token]:
                        if doc_id not in doc_scores:
                            doc_scores[doc_id] = 0
                        
                        # 计算TF-IDF分数
                        idf = self._calculate_idf(token)
                        doc_scores[doc_id] += tf * idf
            
            # 按分数排序
            sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
            
            return [(doc_id, score) for doc_id, score in sorted_docs]
        
        def _calculate_idf(self, term):
            """
            计算逆文档频率（IDF）
            IDF = log(总文档数 / 包含该词的文档数)
            """
            import math
            
            if term not in self.term_doc_freq:
                return 0
            
            df = self.term_doc_freq[term]
            if df == 0:
                return 0
            
            return math.log(self.doc_count / df)
        
        def get_document(self, doc_id):
            """获取文档内容"""
            return self.document_store.get(doc_id)
        
        def phrase_search(self, phrase):
            """
            短语搜索
            查找包含完整短语的文档
            """
            tokens = self._tokenize(phrase)
            if not tokens:
                return []
            
            # 获取包含第一个词的文档
            if tokens[0] not in self.inverted_index:
                return []
            
            candidate_docs = {}
            for doc_id, tf, positions in self.inverted_index[tokens[0]]:
                candidate_docs[doc_id] = positions
            
            # 验证短语在每个文档中的连续性
            valid_docs = []
            
            for doc_id, first_positions in candidate_docs.items():
                # 检查每个起始位置
                for start_pos in first_positions:
                    valid = True
                    
                    # 检查后续词是否在正确位置
                    for i, token in enumerate(tokens[1:], 1):
                        if token not in self.inverted_index:
                            valid = False
                            break
                        
                        # 查找该词在文档中的位置
                        found = False
                        for d_id, _, positions in self.inverted_index[token]:
                            if d_id == doc_id and (start_pos + i) in positions:
                                found = True
                                break
                        
                        if not found:
                            valid = False
                            break
                    
                    if valid:
                        valid_docs.append(doc_id)
                        break
            
            return valid_docs
    
    class PageRanker:
        """PageRank算法实现"""
        
        def __init__(self, damping_factor=0.85, max_iterations=100, tolerance=1e-6):
            self.damping_factor = damping_factor
            self.max_iterations = max_iterations
            self.tolerance = tolerance
            self.page_ranks = {}
        
        def calculate_pagerank(self, link_graph):
            """
            计算PageRank值
            link_graph: {page: [outgoing_links]}
            时间复杂度：O(iterations * edges)
            """
            # 获取所有页面
            all_pages = set(link_graph.keys())
            for links in link_graph.values():
                all_pages.update(links)
            
            n_pages = len(all_pages)
            if n_pages == 0:
                return {}
            
            # 初始化PageRank值
            initial_rank = 1.0 / n_pages
            self.page_ranks = {page: initial_rank for page in all_pages}
            
            # 构建入链表
            inbound_links = {page: [] for page in all_pages}
            for page, outlinks in link_graph.items():
                for outlink in outlinks:
                    if outlink in inbound_links:
                        inbound_links[outlink].append(page)
            
            # 迭代计算
            for iteration in range(self.max_iterations):
                new_ranks = {}
                rank_diff = 0
                
                for page in all_pages:
                    # 基础PageRank值（随机跳转）
                    rank = (1 - self.damping_factor) / n_pages
                    
                    # 从入链页面获得的PageRank值
                    for inbound_page in inbound_links[page]:
                        outlink_count = len(link_graph.get(inbound_page, []))
                        if outlink_count > 0:
                            rank += self.damping_factor * self.page_ranks[inbound_page] / outlink_count
                    
                    new_ranks[page] = rank
                    rank_diff += abs(new_ranks[page] - self.page_ranks[page])
                
                self.page_ranks = new_ranks
                
                # 检查收敛
                if rank_diff < self.tolerance:
                    break
            
            return self.page_ranks
        
        def calculate_hits(self, link_graph):
            """
            HITS算法（权威度和中心度）
            返回每个页面的authority和hub分数
            """
            # 初始化
            all_pages = set(link_graph.keys())
            for links in link_graph.values():
                all_pages.update(links)
            
            authority = {page: 1.0 for page in all_pages}
            hub = {page: 1.0 for page in all_pages}
            
            # 构建入链表
            inbound_links = {page: [] for page in all_pages}
            for page, outlinks in link_graph.items():
                for outlink in outlinks:
                    if outlink in inbound_links:
                        inbound_links[outlink].append(page)
            
            # 迭代更新
            for _ in range(self.max_iterations):
                # 更新authority分数
                new_authority = {}
                for page in all_pages:
                    score = 0
                    for inbound in inbound_links.get(page, []):
                        score += hub.get(inbound, 0)
                    new_authority[page] = score
                
                # 更新hub分数
                new_hub = {}
                for page in all_pages:
                    score = 0
                    for outbound in link_graph.get(page, []):
                        score += new_authority.get(outbound, 0)
                    new_hub[page] = score
                
                # 归一化
                auth_sum = sum(new_authority.values()) or 1
                hub_sum = sum(new_hub.values()) or 1
                
                authority = {p: s/auth_sum for p, s in new_authority.items()}
                hub = {p: s/hub_sum for p, s in new_hub.items()}
            
            return authority, hub
    
    class QueryProcessor:
        """查询处理器"""
        
        def __init__(self):
            self.query_expansion = QueryExpansion()
            self.spell_checker = SpellChecker()
        
        def process_query(self, query):
            """
            处理用户查询
            包括拼写纠正、查询扩展等
            """
            # 1. 拼写纠正
            corrected_query = self.spell_checker.correct(query)
            
            # 2. 查询解析
            parsed_query = self._parse_query(corrected_query)
            
            # 3. 查询扩展
            expanded_terms = self.query_expansion.expand(parsed_query['terms'])
            
            return {
                'original': query,
                'corrected': corrected_query,
                'parsed': parsed_query,
                'expanded': expanded_terms
            }
        
        def _parse_query(self, query):
            """
            解析查询
            识别布尔运算符、短语等
            """
            # 识别引号中的短语
            import re
            phrases = re.findall(r'"([^"]*)"', query)
            
            # 移除短语，处理剩余部分
            remaining = query
            for phrase in phrases:
                remaining = remaining.replace(f'"{phrase}"', '')
            
            # 识别布尔运算符
            and_terms = []
            or_terms = []
            not_terms = []
            
            # 简化处理：分割查询
            tokens = remaining.split()
            
            i = 0
            while i < len(tokens):
                if i + 2 < len(tokens):
                    if tokens[i + 1].upper() == 'AND':
                        and_terms.append((tokens[i], tokens[i + 2]))
                        i += 3
                        continue
                    elif tokens[i + 1].upper() == 'OR':
                        or_terms.append((tokens[i], tokens[i + 2]))
                        i += 3
                        continue
                
                if tokens[i].upper() == 'NOT' and i + 1 < len(tokens):
                    not_terms.append(tokens[i + 1])
                    i += 2
                    continue
                
                and_terms.append(tokens[i])
                i += 1
            
            return {
                'phrases': phrases,
                'and_terms': and_terms,
                'or_terms': or_terms,
                'not_terms': not_terms,
                'terms': tokens
            }
        
        class QueryExpansion:
            """查询扩展"""
            
            def __init__(self):
                # 同义词词典（简化版）
                self.synonyms = {
                    'search': ['find', 'lookup', 'query'],
                    'computer': ['pc', 'machine', 'system'],
                    'fast': ['quick', 'rapid', 'swift'],
                    'good': ['great', 'excellent', 'nice']
                }
            
            def expand(self, terms):
                """扩展查询词"""
                expanded = set(terms)
                
                for term in terms:
                    # 添加同义词
                    if term in self.synonyms:
                        expanded.update(self.synonyms[term])
                    
                    # 添加词干（简化版）
                    stem = self._simple_stem(term)
                    if stem != term:
                        expanded.add(stem)
                
                return list(expanded)
            
            def _simple_stem(self, word):
                """简单词干提取"""
                # 移除常见后缀
                suffixes = ['ing', 'ed', 'es', 's']
                for suffix in suffixes:
                    if word.endswith(suffix) and len(word) > len(suffix) + 2:
                        return word[:-len(suffix)]
                return word
        
        class SpellChecker:
            """拼写检查器"""
            
            def __init__(self):
                # 词典（简化版）
                self.dictionary = set([
                    'search', 'engine', 'algorithm', 'data', 'structure',
                    'computer', 'science', 'programming', 'python', 'code'
                ])
                
                # 构建字符级n-gram索引
                self.ngram_index = self._build_ngram_index()
            
            def _build_ngram_index(self):
                """构建n-gram索引用于快速查找相似词"""
                ngram_index = {}
                
                for word in self.dictionary:
                    # 生成2-gram
                    for i in range(len(word) - 1):
                        ngram = word[i:i+2]
                        if ngram not in ngram_index:
                            ngram_index[ngram] = set()
                        ngram_index[ngram].add(word)
                
                return ngram_index
            
            def correct(self, query):
                """纠正查询中的拼写错误"""
                words = query.split()
                corrected_words = []
                
                for word in words:
                    if word.lower() in self.dictionary:
                        corrected_words.append(word)
                    else:
                        # 寻找最相似的词
                        correction = self._find_correction(word.lower())
                        corrected_words.append(correction or word)
                
                return ' '.join(corrected_words)
            
            def _find_correction(self, word):
                """
                寻找拼写纠正
                使用编辑距离
                """
                min_distance = float('inf')
                best_correction = None
                
                # 获取候选词
                candidates = self._get_candidates(word)
                
                for candidate in candidates:
                    distance = self._edit_distance(word, candidate)
                    if distance < min_distance:
                        min_distance = distance
                        best_correction = candidate
                
                # 只在编辑距离较小时返回纠正
                if min_distance <= 2:
                    return best_correction
                
                return None
            
            def _get_candidates(self, word):
                """获取候选纠正词"""
                candidates = set()
                
                # 基于n-gram的候选
                for i in range(len(word) - 1):
                    ngram = word[i:i+2]
                    if ngram in self.ngram_index:
                        candidates.update(self.ngram_index[ngram])
                
                # 如果候选太少，使用所有词
                if len(candidates) < 5:
                    candidates = self.dictionary
                
                return candidates
            
            def _edit_distance(self, s1, s2):
                """计算编辑距离"""
                m, n = len(s1), len(s2)
                dp = [[0] * (n + 1) for _ in range(m + 1)]
                
                # 初始化
                for i in range(m + 1):
                    dp[i][0] = i
                for j in range(n + 1):
                    dp[0][j] = j
                
                # 动态规划
                for i in range(1, m + 1):
                    for j in range(1, n + 1):
                        if s1[i-1] == s2[j-1]:
                            dp[i][j] = dp[i-1][j-1]
                        else:
                            dp[i][j] = 1 + min(
                                dp[i-1][j],      # 删除
                                dp[i][j-1],      # 插入
                                dp[i-1][j-1]     # 替换
                            )
                
                return dp[m][n]
    
    class WebCrawler:
        """网络爬虫（模拟）"""
        
        def __init__(self):
            self.visited_urls = set()
            self.url_queue = []
            self.robots_cache = {}  # robots.txt缓存
            self.crawl_delay = 1.0  # 爬取延迟（秒）
        
        def crawl(self, seed_urls, max_pages=100):
            """
            爬取网页
            使用BFS策略
            """
            self.url_queue = list(seed_urls)
            pages_crawled = 0
            crawled_data = []
            
            while self.url_queue and pages_crawled < max_pages:
                url = self.url_queue.pop(0)
                
                if url in self.visited_urls:
                    continue
                
                # 检查robots.txt
                if not self._can_crawl(url):
                    continue
                
                # 模拟爬取页面
                page_data = self._fetch_page(url)
                if page_data:
                    self.visited_urls.add(url)
                    pages_crawled += 1
                    
                    # 提取链接
                    links = self._extract_links(page_data['content'])
                    for link in links:
                        if link not in self.visited_urls:
                            self.url_queue.append(link)
                    
                    crawled_data.append(page_data)
                
                # 延迟，避免过快爬取
                import time
                time.sleep(self.crawl_delay)
            
            return crawled_data
        
        def _can_crawl(self, url):
            """检查是否允许爬取（简化版）"""
            # 实际应该解析robots.txt
            return True
        
        def _fetch_page(self, url):
            """
            获取页面内容（模拟）
            实际应用中使用requests等库
            """
            # 模拟页面内容
            import hashlib
            
            content = f"This is the content of {url}. "
            content += "It contains some text about search engines, algorithms, and data structures. "
            content += f"Page ID: {hashlib.md5(url.encode()).hexdigest()[:8]}"
            
            return {
                'url': url,
                'content': content,
                'title': f"Page: {url.split('/')[-1]}",
                'timestamp': self._get_timestamp()
            }
        
        def _extract_links(self, content):
            """
            提取链接（模拟）
            实际应用中使用BeautifulSoup等解析HTML
            """
            # 模拟提取一些链接
            import random
            
            links = []
            base_urls = [
                'http://example.com/page',
                'http://example.com/article',
                'http://example.com/post'
            ]
            
            # 随机生成一些链接
            for _ in range(random.randint(3, 7)):
                base = random.choice(base_urls)
                link = f"{base}/{random.randint(1, 100)}"
                links.append(link)
            
            return links
        
        def _get_timestamp(self):
            """获取时间戳"""
            import time
            return time.time()
    
    class SearchCache:
        """搜索缓存"""
        
        def __init__(self, max_size=1000, ttl=3600):
            self.max_size = max_size
            self.ttl = ttl  # Time To Live (秒)
            self.cache = {}  # {query: (results, timestamp)}
            self.access_count = {}  # 访问计数
            self.lru_queue = []  # LRU队列
        
        def get(self, query):
            """获取缓存结果"""
            if query in self.cache:
                results, timestamp = self.cache[query]
                
                # 检查是否过期
                import time
                if time.time() - timestamp < self.ttl:
                    # 更新访问信息
                    self.access_count[query] = self.access_count.get(query, 0) + 1
                    self._update_lru(query)
                    return results
                else:
                    # 过期，删除
                    del self.cache[query]
            
            return None
        
        def put(self, query, results):
            """缓存结果"""
            import time
            
            # 如果缓存满了，移除最少使用的
            if len(self.cache) >= self.max_size:
                self._evict()
            
            self.cache[query] = (results, time.time())
            self.access_count[query] = 1
            self._update_lru(query)
        
        def _update_lru(self, query):
            """更新LRU队列"""
            if query in self.lru_queue:
                self.lru_queue.remove(query)
            self.lru_queue.append(query)
        
        def _evict(self):
            """移除最少使用的缓存项"""
            if self.lru_queue:
                # 移除最旧的
                victim = self.lru_queue.pop(0)
                del self.cache[victim]
                del self.access_count[victim]
        
        def get_stats(self):
            """获取缓存统计信息"""
            return {
                'size': len(self.cache),
                'total_accesses': sum(self.access_count.values()),
                'avg_accesses': sum(self.access_count.values()) / len(self.cache) if self.cache else 0,
                'most_accessed': max(self.access_count.items(), key=lambda x: x[1]) if self.access_count else None
            }
    
    def search(self, query):
        """
        执行搜索
        完整的搜索流程
        """
        # 1. 检查缓存
        cached_results = self.cache.get(query)
        if cached_results:
            return cached_results
        
        # 2. 处理查询
        processed_query = self.query_processor.process_query(query)
        
        # 3. 执行搜索
        search_results = self.indexer.search(processed_query['corrected'])
        
        # 4. 结合PageRank进行排序
        final_results = self._rank_results(search_results)
        
        # 5. 缓存结果
        self.cache.put(query, final_results)
        
        return final_results
    
    def _rank_results(self, search_results):
        """
        综合排序搜索结果
        结合文本相关性和PageRank
        """
        ranked_results = []
        
        for doc_id, text_score in search_results:
            # 获取PageRank分数
            pagerank_score = self.ranker.page_ranks.get(doc_id, 0.1)
            
            # 综合分数
            # 可以调整权重
            final_score = 0.7 * text_score + 0.3 * pagerank_score
            
            # 获取文档信息
            doc_info = self.indexer.get_document(doc_id)
            
            ranked_results.append({
                'doc_id': doc_id,
                'score': final_score,
                'title': doc_info.get('metadata', {}).get('title', 'Untitled'),
                'snippet': self._generate_snippet(doc_info['content'], 150),
                'url': doc_info.get('metadata', {}).get('url', '#')
            })
        
        # 按最终分数排序
        ranked_results.sort(key=lambda x: x['score'], reverse=True)
        
        return ranked_results
    
    def _generate_snippet(self, content, max_length):
        """生成搜索结果摘要"""
        if len(content) <= max_length:
            return content
        
        # 在合适的位置截断
        snippet = content[:max_length]
        last_space = snippet.rfind(' ')
        
        if last_space > max_length * 0.8:
            snippet = snippet[:last_space]
        
        return snippet + '...'
    
    def build_index(self, documents):
        """
        构建搜索索引
        documents: [(url, content, title), ...]
        """
        # 构建链接图
        link_graph = {}
        
        for i, (url, content, title) in enumerate(documents):
            doc_id = f"doc_{i}"
            
            # 索引文档
            self.indexer.index_document(
                doc_id, 
                content,
                {'url': url, 'title': title}
            )
            
            # 模拟链接关系（实际应从页面中提取）
            outlinks = self._extract_outlinks(content)
            link_graph[doc_id] = outlinks
        
        # 计算PageRank
        self.ranker.calculate_pagerank(link_graph)
        
        return len(documents)
    
    def _extract_outlinks(self, content):
        """提取出链（模拟）"""
        # 简化版：随机生成一些链接
        import random
        
        num_links = random.randint(0, 5)
        outlinks = []
        
        for _ in range(num_links):
            outlinks.append(f"doc_{random.randint(0, 100)}")
        
        return outlinks
```

### 4. 推荐系统算法

```python
class RecommendationSystem:
    """
    推荐系统算法实现
    """
    
    def __init__(self):
        self.collaborative_filter = CollaborativeFiltering()
        self.content_based = ContentBasedFiltering()
        self.matrix_factorization = MatrixFactorization()
        self.deep_recommender = DeepRecommender()
    
    class CollaborativeFiltering:
        """协同过滤算法"""
        
        def __init__(self):
            self.user_item_matrix = None
            self.user_similarity = None
            self.item_similarity = None
        
        def fit(self, user_item_interactions):
            """
            训练协同过滤模型
            user_item_interactions: {user_id: {item_id: rating}}
            """
            # 构建用户-物品矩阵
            users = list(user_item_interactions.keys())
            items = set()
            for user_items in user_item_interactions.values():
                items.update(user_items.keys())
            items = list(items)
            
            # 创建矩阵
            self.user_item_matrix = np.zeros((len(users), len(items)))
            self.user_to_idx = {user: idx for idx, user in enumerate(users)}
            self.item_to_idx = {item: idx for idx, item in enumerate(items)}
            self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}
            self.idx_to_item = {idx: item for item, idx in self.item_to_idx.items()}
            
            # 填充矩阵
            for user, items_ratings in user_item_interactions.items():
                user_idx = self.user_to_idx[user]
                for item, rating in items_ratings.items():
                    item_idx = self.item_to_idx[item]
                    self.user_item_matrix[user_idx, item_idx] = rating
            
            # 计算相似度矩阵
            self.user_similarity = self._calculate_similarity(self.user_item_matrix)
            self.item_similarity = self._calculate_similarity(self.user_item_matrix.T)
        
        def _calculate_similarity(self, matrix):
            """
            计算相似度矩阵
            使用余弦相似度
            """
            # 归一化
            norm = np.linalg.norm(matrix, axis=1, keepdims=True)
            norm[norm == 0] = 1  # 避免除零
            normalized = matrix / norm
            
            # 计算余弦相似度
            similarity = np.dot(normalized, normalized.T)
            
            # 将对角线设为0（自己与自己的相似度不考虑）
            np.fill_diagonal(similarity, 0)
            
            return similarity
        
        def recommend_user_based(self, user_id, n_recommendations=10):
            """
            基于用户的协同过滤推荐
            """
            if user_id not in self.user_to_idx:
                return []
            
            user_idx = self.user_to_idx[user_id]
            
            # 获取用户已经交互过的物品
            user_items = self.user_item_matrix[user_idx]
            interacted_items = np.where(user_items > 0)[0]
            
            # 预测评分
            predictions = np.zeros(len(self.item_to_idx))
            
            # 找到最相似的用户
            similar_users = np.argsort(self.user_similarity[user_idx])[::-1][:50]
            
            for item_idx in range(len(self.item_to_idx)):
                if item_idx in interacted_items:
                    continue
                
                # 基于相似用户的评分预测
                weighted_sum = 0
                similarity_sum = 0
                
                for similar_user_idx in similar_users:
                    if self.user_item_matrix[similar_user_idx, item_idx] > 0:
                        similarity = self.user_similarity[user_idx, similar_user_idx]
                        weighted_sum += similarity * self.user_item_matrix[similar_user_idx, item_idx]
                        similarity_sum += similarity
                
                if similarity_sum > 0:
                    predictions[item_idx] = weighted_sum / similarity_sum
            
            # 获取top-N推荐
            top_items = np.argsort(predictions)[::-1][:n_recommendations]
            
            recommendations = []
            for item_idx in top_items:
                if predictions[item_idx] > 0:
                    recommendations.append({
                        'item_id': self.idx_to_item[item_idx],
                        'score': predictions[item_idx]
                    })
            
            return recommendations
        
        def recommend_item_based(self, user_id, n_recommendations=10):
            """
            基于物品的协同过滤推荐
            """
            if user_id not in self.user_to_idx:
                return []
            
            user_idx = self.user_to_idx[user_id]
            user_items = self.user_item_matrix[user_idx]
            interacted_items = np.where(user_items > 0)[0]
            
            if len(interacted_items) == 0:
                return []
            
            # 预测评分
            predictions = np.zeros(len(self.item_to_idx))
            
            for item_idx in range(len(self.item_to_idx)):
                if item_idx in interacted_items:
                    continue
                
                # 基于物品相似度预测
                weighted_sum = 0
                similarity_sum = 0
                
                for interacted_item in interacted_items:
                    similarity = self.item_similarity[item_idx, interacted_item]
                    if similarity > 0:
                        weighted_sum += similarity * user_items[interacted_item]
                        similarity_sum += similarity
                
                if similarity_sum > 0:
                    predictions[item_idx] = weighted_sum / similarity_sum
            
            # 获取推荐
            top_items = np.argsort(predictions)[::-1][:n_recommendations]
            
            recommendations = []
            for item_idx in top_items:
                if predictions[item_idx] > 0:
                    recommendations.append({
                        'item_id': self.idx_to_item[item_idx],
                        'score': predictions[item_idx]
                    })
            
            return recommendations
    
    class ContentBasedFiltering:
        """基于内容的过滤"""
        
        def __init__(self):
            self.item_features = None
            self.user_profiles = {}
        
        def build_item_features(self, items_data):
            """
            构建物品特征
            items_data: {item_id: {'title': str, 'description': str, 'categories': list}}
            """
            from sklearn.feature_extraction.text import TfidfVectorizer
            
            # 准备文本数据
            item_ids = list(items_data.keys())
            texts = []
            
            for item_id in item_ids:
                item = items_data[item_id]
                # 合并所有文本特征
                text = f"{item.get('title', '')} {item.get('description', '')} "
                text += ' '.join(item.get('categories', []))
                texts.append(text)
            
            # TF-IDF特征提取
            vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            features = vectorizer.fit_transform(texts)
            
            self.item_features = {
                item_id: features[i].toarray().flatten()
                for i, item_id in enumerate(item_ids)
            }
            
            self.vectorizer = vectorizer
        
        def build_user_profile(self, user_id, user_interactions, ratings=None):
            """
            构建用户画像
            基于用户交互过的物品
            """
            if not user_interactions:
                return
            
            # 获取用户交互物品的特征
            item_features = []
            weights = []
            
            for i, item_id in enumerate(user_interactions):
                if item_id in self.item_features:
                    item_features.append(self.item_features[item_id])
                    # 如果有评分，使用评分作为权重
                    if ratings and i < len(ratings):
                        weights.append(ratings[i])
                    else:
                        weights.append(1.0)
            
            if not item_features:
                return
            
            # 加权平均构建用户画像
            item_features = np.array(item_features)
            weights = np.array(weights)
            weights = weights / weights.sum()
            
            user_profile = np.average(item_features, axis=0, weights=weights)
            self.user_profiles[user_id] = user_profile
        
        def recommend(self, user_id, candidate_items, n_recommendations=10):
            """
            基于内容的推荐
            """
            if user_id not in self.user_profiles:
                return []
            
            user_profile = self.user_profiles[user_id]
            scores = []
            
            for item_id in candidate_items:
                if item_id in self.item_features:
                    item_feature = self.item_features[item_id]
                    # 计算余弦相似度
                    similarity = np.dot(user_profile, item_feature) / (
                        np.linalg.norm(user_profile) * np.linalg.norm(item_feature) + 1e-8
                    )
                    scores.append((item_id, similarity))
            
            # 排序并返回top-N
            scores.sort(key=lambda x: x[1], reverse=True)
            
            recommendations = []
            for item_id, score in scores[:n_recommendations]:
                recommendations.append({
                    'item_id': item_id,
                    'score': score
                })
            
            return recommendations
    
    class MatrixFactorization:
        """矩阵分解算法（SVD++）"""
        
        def __init__(self, n_factors=50, n_epochs=20, learning_rate=0.01, reg=0.01):
            self.n_factors = n_factors
            self.n_epochs = n_epochs
            self.learning_rate = learning_rate
            self.reg = reg
            
            self.user_factors = None
            self.item_factors = None
            self.user_bias = None
            self.item_bias = None
            self.global_mean = None
        
        def fit(self, train_data):
            """
            训练模型
            train_data: [(user_id, item_id, rating)]
            """
            # 创建映射
            users = list(set(d[0] for d in train_data))
            items = list(set(d[1] for d in train_data))
            
            self.user_to_idx = {user: idx for idx, user in enumerate(users)}
            self.item_to_idx = {item: idx for idx, item in enumerate(items)}
            
            n_users = len(users)
            n_items = len(items)
            
            # 初始化参数
            self.user_factors = np.random.normal(0, 0.01, (n_users, self.n_factors))
            self.item_factors = np.random.normal(0, 0.01, (n_items, self.n_factors))
            self.user_bias = np.zeros(n_users)
            self.item_bias = np.zeros(n_items)
            
            # 计算全局平均值
            self.global_mean = np.mean([d[2] for d in train_data])
            
            # 训练
            for epoch in range(self.n_epochs):
                # 打乱数据
                np.random.shuffle(train_data)
                
                total_loss = 0
                for user, item, rating in train_data:
                    user_idx = self.user_to_idx[user]
                    item_idx = self.item_to_idx[item]
                    
                    # 预测
                    pred = self._predict_rating(user_idx, item_idx)
                    error = rating - pred
                    total_loss += error ** 2
                    
                    # 更新参数（SGD）
                    # 用户因子
                    self.user_factors[user_idx] += self.learning_rate * (
                        error * self.item_factors[item_idx] - 
                        self.reg * self.user_factors[user_idx]
                    )
                    
                    # 物品因子
                    self.item_factors[item_idx] += self.learning_rate * (
                        error * self.user_factors[user_idx] - 
                        self.reg * self.item_factors[item_idx]
                    )
                    
                    # 偏置
                    self.user_bias[user_idx] += self.learning_rate * (
                        error - self.reg * self.user_bias[user_idx]
                    )
                    self.item_bias[item_idx] += self.learning_rate * (
                        error - self.reg * self.item_bias[item_idx]
                    )
                
                # 打印进度
                if (epoch + 1) % 5 == 0:
                    rmse = np.sqrt(total_loss / len(train_data))
                    print(f"Epoch {epoch + 1}/{self.n_epochs}, RMSE: {rmse:.4f}")
        
        def _predict_rating(self, user_idx, item_idx):
            """预测评分"""
            pred = self.global_mean
            pred += self.user_bias[user_idx]
            pred += self.item_bias[item_idx]
            pred += np.dot(self.user_factors[user_idx], self.item_factors[item_idx])
            
            return pred
        
        def predict(self, user, item):
            """预测用户对物品的评分"""
            if user not in self.user_to_idx or item not in self.item_to_idx:
                return self.global_mean
            
            user_idx = self.user_to_idx[user]
            item_idx = self.item_to_idx[item]
            
            return self._predict_rating(user_idx, item_idx)
        
        def recommend(self, user, candidate_items, n_recommendations=10):
            """推荐物品"""
            if user not in self.user_to_idx:
                return []
            
            predictions = []
            for item in candidate_items:
                if item in self.item_to_idx:
                    score = self.predict(user, item)
                    predictions.append((item, score))
            
            # 排序
            predictions.sort(key=lambda x: x[1], reverse=True)
            
            recommendations = []
            for item, score in predictions[:n_recommendations]:
                recommendations.append({
                    'item_id': item,
                    'score': score
                })
            
            return recommendations
    
    class DeepRecommender:
        """深度学习推荐模型（简化版）"""
        
        def __init__(self, embedding_dim=50, hidden_units=[128, 64]):
            self.embedding_dim = embedding_dim
            self.hidden_units = hidden_units
            self.model = None
            
        def build_model(self, n_users, n_items):
            """
            构建神经网络模型
            使用双塔结构
            """
            self.user_embedding = np.random.normal(0, 0.01, (n_users, self.embedding_dim))
            self.item_embedding = np.random.normal(0, 0.01, (n_items, self.embedding_dim))
            
            # 简化的MLP
            self.user_tower = self._build_tower("user")
            self.item_tower = self._build_tower("item")
        
        def _build_tower(self, name):
            """构建塔结构"""
            layers = []
            
            input_dim = self.embedding_dim
            for hidden_dim in self.hidden_units:
                # 添加全连接层
                layer = {
                    'type': 'dense',
                    'weights': np.random.normal(0, 0.01, (input_dim, hidden_dim)),
                    'bias': np.zeros(hidden_dim),
                    'activation': 'relu'
                }
                layers.append(layer)
                input_dim = hidden_dim
            
            return layers
        
        def forward(self, user_idx, item_idx):
            """前向传播"""
            # 获取嵌入
            user_emb = self.user_embedding[user_idx]
            item_emb = self.item_embedding[item_idx]
            
            # 通过塔结构
            user_vec = self._tower_forward(user_emb, self.user_tower)
            item_vec = self._tower_forward(item_emb, self.item_tower)
            
            # 计算相似度（点积）
            score = np.dot(user_vec, item_vec)
            
            return self._sigmoid(score)
        
        def _tower_forward(self, input_vec, tower):
            """塔的前向传播"""
            x = input_vec
            
            for layer in tower:
                # 线性变换
                x = np.dot(x, layer['weights']) + layer['bias']
                
                # 激活函数
                if layer['activation'] == 'relu':
                    x = np.maximum(0, x)
            
            return x
        
        def _sigmoid(self, x):
            """Sigmoid函数"""
            return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
        
        def train(self, train_data, n_epochs=10, batch_size=256, learning_rate=0.001):
            """
            训练模型（简化版SGD）
            train_data: [(user_idx, item_idx, label)]
            """
            for epoch in range(n_epochs):
                # 打乱数据
                np.random.shuffle(train_data)
                
                total_loss = 0
                n_batches = 0
                
                # 批次训练
                for i in range(0, len(train_data), batch_size):
                    batch = train_data[i:i + batch_size]
                    
                    batch_loss = 0
                    for user_idx, item_idx, label in batch:
                        # 前向传播
                        pred = self.forward(user_idx, item_idx)
                        
                        # 计算损失（二元交叉熵）
                        loss = -label * np.log(pred + 1e-8) - (1 - label) * np.log(1 - pred + 1e-8)
                        batch_loss += loss
                        
                        # 反向传播（简化版）
                        error = pred - label
                        
                        # 更新嵌入（梯度下降）
                        self.user_embedding[user_idx] -= learning_rate * error * self.item_embedding[item_idx]
                        self.item_embedding[item_idx] -= learning_rate * error * self.user_embedding[user_idx]
                    
                    total_loss += batch_loss
                    n_batches += len(batch)
                
                # 打印进度
                avg_loss = total_loss / n_batches
                print(f"Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.4f}")
        
        def get_user_embedding(self, user_idx):
            """获取用户向量表示"""
            user_emb = self.user_embedding[user_idx]
            return self._tower_forward(user_emb, self.user_tower)
        
        def get_item_embedding(self, item_idx):
            """获取物品向量表示"""
            item_emb = self.item_embedding[item_idx]
            return self._tower_forward(item_emb, self.item_tower)
        
        def recommend_by_embedding(self, user_idx, all_item_indices, n_recommendations=10):
            """
            基于向量相似度推荐
            使用近似最近邻搜索
            """
            user_vec = self.get_user_embedding(user_idx)
            
            scores = []
            for item_idx in all_item_indices:
                item_vec = self.get_item_embedding(item_idx)
                # 计算相似度
                score = np.dot(user_vec, item_vec) / (
                    np.linalg.norm(user_vec) * np.linalg.norm(item_vec) + 1e-8
                )
                scores.append((item_idx, score))
            
            # 排序
            scores.sort(key=lambda x: x[1], reverse=True)
            
            return scores[:n_recommendations]
    
    class HybridRecommender:
        """混合推荐系统"""
        
        def __init__(self):
            self.cf = None
            self.cb = None
            self.mf = None
            self.weights = {
                'cf': 0.4,
                'cb': 0.3,
                'mf': 0.3
            }
        
        def set_models(self, cf_model, cb_model, mf_model):
            """设置子模型"""
            self.cf = cf_model
            self.cb = cb_model
            self.mf = mf_model
        
        def recommend(self, user_id, candidate_items, n_recommendations=10):
            """
            混合推荐
            结合多种推荐算法的结果
            """
            all_scores = {}
            
            # 协同过滤推荐
            if self.cf:
                cf_recs = self.cf.recommend_user_based(user_id, len(candidate_items))
                for rec in cf_recs:
                    item_id = rec['item_id']
                    if item_id in candidate_items:
                        if item_id not in all_scores:
                            all_scores[item_id] = 0
                        all_scores[item_id] += self.weights['cf'] * rec['score']
            
            # 基于内容推荐
            if self.cb:
                cb_recs = self.cb.recommend(user_id, candidate_items, len(candidate_items))
                for rec in cb_recs:
                    item_id = rec['item_id']
                    if item_id not in all_scores:
                        all_scores[item_id] = 0
                    all_scores[item_id] += self.weights['cb'] * rec['score']
            
            # 矩阵分解推荐
            if self.mf:
                mf_recs = self.mf.recommend(user_id, candidate_items, len(candidate_items))
                for rec in mf_recs:
                    item_id = rec['item_id']
                    if item_id not in all_scores:
                        all_scores[item_id] = 0
                    all_scores[item_id] += self.weights['mf'] * rec['score']
            
            # 排序并返回
            sorted_items = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)
            
            recommendations = []
            for item_id, score in sorted_items[:n_recommendations]:
                recommendations.append({
                    'item_id': item_id,
                    'score': score,
                    'source': 'hybrid'
                })
            
            return recommendations
        
        def explain_recommendation(self, user_id, item_id):
            """
            解释推荐原因
            """
            explanations = []
            
            # 从各个模型获取解释
            if self.cf:
                # 找到相似用户who也喜欢这个物品
                similar_users = self._find_similar_users_who_liked(user_id, item_id)
                if similar_users:
                    explanations.append(f"用户 {', '.join(similar_users[:3])} 也喜欢这个")
            
            if self.cb:
                # 基于内容的相似性
                similar_items = self._find_similar_items_user_liked(user_id, item_id)
                if similar_items:
                    explanations.append(f"因为你喜欢 {', '.join(similar_items[:3])}")
            
            if self.mf:
                # 潜在因子
                score = self.mf.predict(user_id, item_id)
                if score > self.mf.global_mean:
                    explanations.append("基于你的历史偏好预测你会喜欢")
            
            return explanations
        
        def _find_similar_users_who_liked(self, user_id, item_id):
            """找到也喜欢该物品的相似用户"""
            # 简化实现
            return ["User123", "User456"]
        
        def _find_similar_items_user_liked(self, user_id, item_id):
            """找到用户喜欢的相似物品"""
            # 简化实现
            return ["Item789", "Item012"]
    
    def evaluate_recommendations(self, test_data, recommendations):
        """
        评估推荐系统
        计算准确率、召回率、F1等指标
        """
        metrics = {
            'precision': 0,
            'recall': 0,
            'f1': 0,
            'coverage': 0,
            'diversity': 0
        }
        
        # 准确率和召回率
        true_positives = 0
        total_recommended = 0
        total_relevant = 0
        
        all_recommended_items = set()
        
        for user_id, actual_items in test_data.items():
            if user_id in recommendations:
                recommended_items = set(rec['item_id'] for rec in recommendations[user_id])
                actual_items_set = set(actual_items)
                
                # 统计
                true_positives += len(recommended_items & actual_items_set)
                total_recommended += len(recommended_items)
                total_relevant += len(actual_items_set)
                
                all_recommended_items.update(recommended_items)
        
        # 计算指标
        if total_recommended > 0:
            metrics['precision'] = true_positives / total_recommended
        
        if total_relevant > 0:
            metrics['recall'] = true_positives / total_relevant
        
        if metrics['precision'] + metrics['recall'] > 0:
            metrics['f1'] = 2 * metrics['precision'] * metrics['recall'] / (
                metrics['precision'] + metrics['recall']
            )
        
        # 覆盖率
        total_items = len(set(item for items in test_data.values() for item in items))
        if total_items > 0:
            metrics['coverage'] = len(all_recommended_items) / total_items
        
        # 多样性（简化版：推荐列表中物品的平均距离）
        metrics['diversity'] = self._calculate_diversity(recommendations)
        
        return metrics
    
    def _calculate_diversity(self, recommendations):
        """计算推荐的多样性"""
        # 简化实现：基于推荐列表中物品ID的差异
        diversities = []
        
        for user_recs in recommendations.values():
            if len(user_recs) > 1:
                # 计算成对距离
                items = [rec['item_id'] for rec in user_recs]
                n_items = len(items)
                
                if n_items > 1:
                    # 简化：使用ID差异作为距离
                    total_distance = 0
                    pairs = 0
                    
                    for i in range(n_items):
                        for j in range(i + 1, n_items):
                            # 实际应用中应使用物品特征计算距离
                            distance = abs(hash(items[i]) - hash(items[j])) / (2**32)
                            total_distance += distance
                            pairs += 1
                    
                    if pairs > 0:
                        diversities.append(total_distance / pairs)
        
        return np.mean(diversities) if diversities else 0
```

## 总结

通过这份完整的数据结构与算法学习指南，你已经掌握了从基础到高级的所有核心知识点。这些内容涵盖了：

1. **基础数据结构**：数组、链表、栈、队列、树、图等
2. **高级数据结构**：平衡树、B树、跳表、布隆过滤器等
3. **核心算法**：排序、查找、动态规划、贪心、回溯等
4. **图算法**：最短路径、最小生成树、网络流等
5. **字符串算法**：KMP、AC自动机、后缀数组等
6. **优化技巧**：时间复杂度优化、空间优化、并行化等
7. **机器学习算法**：梯度下降、聚类、决策树、神经网络等
8. **实际应用**：搜索引擎、推荐系统、AI改卷、聊天机器人等

### 学习建议

1. **循序渐进**：从基础数据结构开始，逐步深入到高级算法
2. **动手实践**：每个算法都要亲自实现一遍，加深理解
3. **分析复杂度**：养成分析时间和空间复杂度的习惯
4. **解决问题**：通过LeetCode等平台练习，提高解题能力
5. **项目应用**：将所学知识应用到实际项目中，如你的AI改卷系统和聊天Agent

### 进阶方向

1. **系统设计**：学习如何设计大规模分布式系统
2. **算法优化**：深入研究特定领域的算法优化技巧
3. **机器学习**：深入学习深度学习、强化学习等前沿技术
4. **工程实践**：关注算法的工程化实现和性能优化

```
记住，成为优秀的算法工程师需要持续学习和实践。保持好奇心，勇于挑战难题，相信你一定能在这条道路上走得更远！

这份文档完整地涵盖了数据结构与算法的所有重要知识点，每个部分都包含了详细的代码实现和注释。通过系统学习这些内容，你将能够：

1. 扎实掌握数据结构与算法的理论基础
2. 具备独立实现各种算法的能力
3. 能够分析和优化算法的性能
4. 将算法知识应用到实际项目开发中
5. 为成为高级算法工程师打下坚实基础

继续加油！相信通过努力学习和实践，你一定能实现成为优秀算法工程师的目标！
```